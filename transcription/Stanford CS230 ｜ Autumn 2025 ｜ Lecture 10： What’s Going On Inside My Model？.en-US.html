<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Stanford CS230 ｜ Autumn 2025 ｜ Lecture 10： What’s Going On Inside My Model？.en-US.html</title>
  <style>
    body{font-family:Inter, system-ui, -apple-system, Arial, sans-serif;line-height:1.6;padding:1rem;max-width:900px;margin:0 auto;color:#111}
    .meta{color:#666;font-size:0.95rem;margin-bottom:0.5rem}
    article{background:#fff;border-radius:8px;padding:1rem 1.2rem;box-shadow:0 6px 18px rgba(10,20,30,0.05)}
    p.cue{margin:0 0 0.6rem}
    span.time{color:#666;margin-right:8px;font-size:0.95rem}
  </style>
</head>
<body>
<article lang="en">
  <header>
    <h1>Stanford CS230 ｜ Autumn 2025 ｜ Lecture 10： What’s Going On Inside My Model？</h1>
    <p class="meta">Source: Stanford CS230 ｜ Autumn 2025 ｜ Lecture 10： What’s Going On Inside My Model？.en-US.srt</p>
  </header>
  <section class="transcript">
    <p class="cue"><span class="time">[00:05]</span>Welcome to lecture 9 already.</p>
    <p class="cue"><span class="time">[00:08]</span>I hope everybody had a good fall break.</p>
    <p class="cue"><span class="time">[00:14]</span>Today, we&#x27;re going to talk about neural networks,</p>
    <p class="cue"><span class="time">[00:19]</span>both convolutional neural networks and transformers.</p>
    <p class="cue"><span class="time">[00:23]</span>And we&#x27;re going to unpack it to see what&#x27;s going on inside.</p>
    <p class="cue"><span class="time">[00:27]</span>This lecture used to be called neural network interpretability,</p>
    <p class="cue"><span class="time">[00:32]</span>but I&#x27;ve broadened the scope because there is a section now</p>
    <p class="cue"><span class="time">[00:35]</span>where we talk more about frontier models.</p>
    <p class="cue"><span class="time">[00:39]</span>And the interpretability or visualization methods</p>
    <p class="cue"><span class="time">[00:43]</span>have not quite been figured out for most models</p>
    <p class="cue"><span class="time">[00:46]</span>that you play with out there.</p>
    <p class="cue"><span class="time">[00:48]</span>So think about this one as research areas,</p>
    <p class="cue"><span class="time">[00:52]</span>what we know from convolutions, and what</p>
    <p class="cue"><span class="time">[00:54]</span>we&#x27;re trying to figure out for frontier models.</p>
    <p class="cue"><span class="time">[00:58]</span>We&#x27;re going to start with a very packed agenda with a case</p>
    <p class="cue"><span class="time">[01:02]</span>study where I&#x27;m going to ask you a question</p>
    <p class="cue"><span class="time">[01:05]</span>and let you brainstorm a little bit all together</p>
    <p class="cue"><span class="time">[01:10]</span>on how you would try to understand what&#x27;s happening</p>
    <p class="cue"><span class="time">[01:15]</span>inside of a frontier model.</p>
    <p class="cue"><span class="time">[01:20]</span>In the second section, we&#x27;re going</p>
    <p class="cue"><span class="time">[01:21]</span>to look at the example of convolutions</p>
    <p class="cue"><span class="time">[01:24]</span>specifically and try to interpret everything</p>
    <p class="cue"><span class="time">[01:27]</span>possible about convolution.</p>
    <p class="cue"><span class="time">[01:29]</span>Meaning, we&#x27;re going to look at input/output relationship.</p>
    <p class="cue"><span class="time">[01:33]</span>We&#x27;re going to look at a specific neuron</p>
    <p class="cue"><span class="time">[01:35]</span>inside and try to interpret it.</p>
    <p class="cue"><span class="time">[01:37]</span>We&#x27;re going to look also at a specific feature maps</p>
    <p class="cue"><span class="time">[01:41]</span>and try to understand what they do.</p>
    <p class="cue"><span class="time">[01:43]</span>I will present many methods to do that.</p>
    <p class="cue"><span class="time">[01:45]</span>Those methods are real, and they&#x27;ve</p>
    <p class="cue"><span class="time">[01:47]</span>been used for convolutions.</p>
    <p class="cue"><span class="time">[01:50]</span>But again, they&#x27;re not the methods</p>
    <p class="cue"><span class="time">[01:51]</span>that you might see frontier labs use for today&#x27;s language</p>
    <p class="cue"><span class="time">[01:56]</span>or vision, large models.</p>
    <p class="cue"><span class="time">[02:00]</span>However, they&#x27;re going to bring you</p>
    <p class="cue"><span class="time">[02:02]</span>the skills that will allow you to understand</p>
    <p class="cue"><span class="time">[02:04]</span>the methods for frontier models as researchers</p>
    <p class="cue"><span class="time">[02:07]</span>are trying to figure them out.</p>
    <p class="cue"><span class="time">[02:09]</span>The second half of the lecture is</p>
    <p class="cue"><span class="time">[02:11]</span>going to focus more on the modern representation analysis.</p>
    <p class="cue"><span class="time">[02:16]</span>We&#x27;re going to talk about scaling laws, capability</p>
    <p class="cue"><span class="time">[02:19]</span>benchmarking, data diagnostics, and then I&#x27;ll</p>
    <p class="cue"><span class="time">[02:23]</span>end on a few closing remarks.</p>
    <p class="cue"><span class="time">[02:26]</span>Are we ready for this one?</p>
    <p class="cue"><span class="time">[02:29]</span>Lots of visualizations in this lecture.</p>
    <p class="cue"><span class="time">[02:31]</span>So first question for you all.</p>
    <p class="cue"><span class="time">[02:37]</span>Let&#x27;s say the case study is, you are a model trainer,</p>
    <p class="cue"><span class="time">[02:42]</span>and you&#x27;re working on a 200 billion parameters model</p>
    <p class="cue"><span class="time">[02:48]</span>at a frontier lab.</p>
    <p class="cue"><span class="time">[02:49]</span>And overnight, a new checkpoint passes training sanity check,</p>
    <p class="cue"><span class="time">[02:54]</span>but a few issues arise.</p>
    <p class="cue"><span class="time">[02:57]</span>Things like the model is getting worse on reasoning benchmarks,</p>
    <p class="cue"><span class="time">[03:03]</span>some safety evals are failing, and there&#x27;s</p>
    <p class="cue"><span class="time">[03:08]</span>a weird spike in, let&#x27;s say, latency for tool use</p>
    <p class="cue"><span class="time">[03:11]</span>when you actually use this model for an agentic workflow.</p>
    <p class="cue"><span class="time">[03:14]</span>Your VP is wondering what&#x27;s happening, and they ask,</p>
    <p class="cue"><span class="time">[03:18]</span>what is going on?</p>
    <p class="cue"><span class="time">[03:20]</span>And what are you going to look at first?</p>
    <p class="cue"><span class="time">[03:22]</span>So what I want you to discuss for a minute</p>
    <p class="cue"><span class="time">[03:26]</span>or so think about it first, and I&#x27;ll open up,</p>
    <p class="cue"><span class="time">[03:29]</span>is what are the type of evidences that you would look,</p>
    <p class="cue"><span class="time">[03:34]</span>want to inspect before even touching the code</p>
    <p class="cue"><span class="time">[03:38]</span>or retraining the model?</p>
    <p class="cue"><span class="time">[03:40]</span>What are the things that you want to look at?</p>
    <p class="cue"><span class="time">[03:45]</span>Jumping.</p>
    <p class="cue"><span class="time">[03:46]</span>There&#x27;s no single answer.</p>
    <p class="cue"><span class="time">[03:48]</span>So I want to everything you&#x27;re going to look at OK.</p>
    <p class="cue"><span class="time">[03:51]</span>So error analysis.</p>
    <p class="cue"><span class="time">[03:54]</span>You said, I will look at the reasoning benchmarks</p>
    <p class="cue"><span class="time">[03:58]</span>and find the examples where the model is failing.</p>
    <p class="cue"><span class="time">[04:01]</span>Specifically, try to find patterns</p>
    <p class="cue"><span class="time">[04:03]</span>in order to pinpoint what the issue might be.</p>
    <p class="cue"><span class="time">[04:05]</span>And then same thing on the safety</p>
    <p class="cue"><span class="time">[04:08]</span>evals where you want to see what type of safety issues</p>
    <p class="cue"><span class="time">[04:11]</span>are arising.</p>
    <p class="cue"><span class="time">[04:11]</span>Is it everywhere?</p>
    <p class="cue"><span class="time">[04:12]</span>Is it specific to something?</p>
    <p class="cue"><span class="time">[04:14]</span>Yeah, I agree.</p>
    <p class="cue"><span class="time">[04:16]</span>Error analysis in general.</p>
    <p class="cue"><span class="time">[04:17]</span>What else?</p>
    <p class="cue"><span class="time">[04:33]</span>Remember you&#x27;re the model trainer.</p>
    <p class="cue"><span class="time">[04:35]</span>So you&#x27;re training this model.</p>
    <p class="cue"><span class="time">[04:37]</span>You&#x27;re supposed to be watching certain things when</p>
    <p class="cue"><span class="time">[04:39]</span>you&#x27;re training.</p>
    <p class="cue"><span class="time">[04:41]</span>What can be interesting?</p>
    <p class="cue"><span class="time">[04:48]</span>Yeah.</p>
    <p class="cue"><span class="time">[04:49]</span>With sanity checks, you mean the loss in frequency.</p>
    <p class="cue"><span class="time">[04:53]</span>And all of this, right, it starts passing.</p>
    <p class="cue"><span class="time">[04:56]</span>Yeah.</p>
    <p class="cue"><span class="time">[04:56]</span>Let&#x27;s say not necessarily passing,</p>
    <p class="cue"><span class="time">[04:58]</span>but those are great examples.</p>
    <p class="cue"><span class="time">[04:59]</span>So you&#x27;re mentioning, yeah, as you&#x27;re the model trainer,</p>
    <p class="cue"><span class="time">[05:02]</span>you would be watching the training loss.</p>
    <p class="cue"><span class="time">[05:04]</span>And you want to see.</p>
    <p class="cue"><span class="time">[05:05]</span>What are you going to look for in that training loss?</p>
    <p class="cue"><span class="time">[05:09]</span>Convergence.</p>
    <p class="cue"><span class="time">[05:10]</span>OK.</p>
    <p class="cue"><span class="time">[05:10]</span>Convergence.</p>
    <p class="cue"><span class="time">[05:11]</span>You probably want to make sure that it&#x27;s smooth.</p>
    <p class="cue"><span class="time">[05:15]</span>You don&#x27;t want big spikes.</p>
    <p class="cue"><span class="time">[05:18]</span>How about the validation loss?</p>
    <p class="cue"><span class="time">[05:19]</span>What is your expectation on the validation loss?</p>
    <p class="cue"><span class="time">[05:25]</span>Should go up.</p>
    <p class="cue"><span class="time">[05:27]</span>Yeah, should probably follow the same curve as the training loss,</p>
    <p class="cue"><span class="time">[05:30]</span>but is likely slightly higher because you&#x27;re probably</p>
    <p class="cue"><span class="time">[05:33]</span>performing slightly less well on the validation set</p>
    <p class="cue"><span class="time">[05:36]</span>than on the training set.</p>
    <p class="cue"><span class="time">[05:38]</span>If you&#x27;re seeing spikes, it might</p>
    <p class="cue"><span class="time">[05:41]</span>mean there are some issues.</p>
    <p class="cue"><span class="time">[05:44]</span>What else are you looking at?</p>
    <p class="cue"><span class="time">[05:53]</span>Yeah.</p>
    <p class="cue"><span class="time">[05:54]</span>Take a look at this round of training data</p>
    <p class="cue"><span class="time">[05:56]</span>see how it&#x27;s performing.</p>
    <p class="cue"><span class="time">[05:57]</span>So this batch, you mean?</p>
    <p class="cue"><span class="time">[05:59]</span>Yeah, so you&#x27;re looking at this round of training data,</p>
    <p class="cue"><span class="time">[06:02]</span>maybe the last round of data that we trained on,</p>
    <p class="cue"><span class="time">[06:07]</span>there were some issues in that data.</p>
    <p class="cue"><span class="time">[06:09]</span>Maybe that data was probably poisoned or biased</p>
    <p class="cue"><span class="time">[06:15]</span>toward a certain category of data that we&#x27;re failing on.</p>
    <p class="cue"><span class="time">[06:18]</span>You&#x27;re totally right.</p>
    <p class="cue"><span class="time">[06:20]</span>Yeah.</p>
    <p class="cue"><span class="time">[06:21]</span>Maybe that specific checkpoint is doing poorly compared</p>
    <p class="cue"><span class="time">[06:24]</span>to the previous checkpoint.</p>
    <p class="cue"><span class="time">[06:25]</span>And so you pinpoint where the issue arises</p>
    <p class="cue"><span class="time">[06:28]</span>during the training.</p>
    <p class="cue"><span class="time">[06:31]</span>What else are you looking at?</p>
    <p class="cue"><span class="time">[06:43]</span>Yeah.</p>
    <p class="cue"><span class="time">[06:44]</span>I&#x27;m worried about the overnight thing.</p>
    <p class="cue"><span class="time">[06:46]</span>It&#x27;s pretty fast.</p>
    <p class="cue"><span class="time">[06:46]</span>I wonder if this is in line with a hardware issue there.</p>
    <p class="cue"><span class="time">[06:49]</span>OK.</p>
    <p class="cue"><span class="time">[06:49]</span>Because it&#x27;s overnight and it seemed</p>
    <p class="cue"><span class="time">[06:52]</span>everything was good up to yesterday</p>
    <p class="cue"><span class="time">[06:53]</span>and now there&#x27;s an issue, maybe you&#x27;re</p>
    <p class="cue"><span class="time">[06:55]</span>saying there&#x27;s a hardware issue.</p>
    <p class="cue"><span class="time">[06:57]</span>Yeah, we could check actually is--</p>
    <p class="cue"><span class="time">[07:00]</span>yeah, latency has been pointed out.</p>
    <p class="cue"><span class="time">[07:04]</span>So maybe the hardware has failed.</p>
    <p class="cue"><span class="time">[07:06]</span>Yeah, you&#x27;re right.</p>
    <p class="cue"><span class="time">[07:11]</span>What else?</p>
    <p class="cue"><span class="time">[07:19]</span>So a lot of the answers are global answers.</p>
    <p class="cue"><span class="time">[07:22]</span>You&#x27;re looking at the model in general.</p>
    <p class="cue"><span class="time">[07:24]</span>You&#x27;re not looking at specific portions of the model.</p>
    <p class="cue"><span class="time">[07:26]</span>What would if you were to inspect the model more precisely</p>
    <p class="cue"><span class="time">[07:31]</span>from the inside?</p>
    <p class="cue"><span class="time">[07:37]</span>And this one&#x27;s a language model.</p>
    <p class="cue"><span class="time">[07:39]</span>So you can think about the fact that it&#x27;s a language model.</p>
    <p class="cue"><span class="time">[07:47]</span>Yeah.</p>
    <p class="cue"><span class="time">[07:47]</span>I mean, it&#x27;s something I would do is just recently</p>
    <p class="cue"><span class="time">[07:50]</span>examine differential equations, look at what has happened</p>
    <p class="cue"><span class="time">[07:54]</span>over the past 10 points before this one</p>
    <p class="cue"><span class="time">[07:57]</span>to see the model getting to perform better or was</p>
    <p class="cue"><span class="time">[08:02]</span>it not, just to see if there was hardware issue</p>
    <p class="cue"><span class="time">[08:05]</span>or there would be a problem.</p>
    <p class="cue"><span class="time">[08:07]</span>Yeah, you&#x27;re right.</p>
    <p class="cue"><span class="time">[08:07]</span>You want to look at different checkpoints</p>
    <p class="cue"><span class="time">[08:10]</span>and see where did we fail and might</p>
    <p class="cue"><span class="time">[08:14]</span>be able to trace back to that moment</p>
    <p class="cue"><span class="time">[08:16]</span>and figure out what the issue was?</p>
    <p class="cue"><span class="time">[08:17]</span>So, for example, maybe your initialization was actually</p>
    <p class="cue"><span class="time">[08:21]</span>pretty good and the first checkpoints were doing well,</p>
    <p class="cue"><span class="time">[08:25]</span>but suddenly at some points, the model</p>
    <p class="cue"><span class="time">[08:29]</span>saturated in a certain way.</p>
    <p class="cue"><span class="time">[08:30]</span>Maybe you&#x27;re seeing exploding gradients or vanishing</p>
    <p class="cue"><span class="time">[08:33]</span>gradients in certain moments, and you want to pinpoint that.</p>
    <p class="cue"><span class="time">[08:37]</span>Yeah.</p>
    <p class="cue"><span class="time">[08:38]</span>What else?</p>
    <p class="cue"><span class="time">[08:40]</span>We&#x27;re adding so many methods right now,</p>
    <p class="cue"><span class="time">[08:42]</span>but I want to hear what else you have for language models.</p>
    <p class="cue"><span class="time">[08:47]</span>What other things can you visualize</p>
    <p class="cue"><span class="time">[08:49]</span>for language models that might mean something&#x27;s going wrong?</p>
    <p class="cue"><span class="time">[08:59]</span>Yeah.</p>
    <p class="cue"><span class="time">[09:00]</span>And if you really want to go deep into it,</p>
    <p class="cue"><span class="time">[09:02]</span>you can actually plot the attention maps</p>
    <p class="cue"><span class="time">[09:05]</span>The attention maps.</p>
    <p class="cue"><span class="time">[09:08]</span>Yeah, yeah.</p>
    <p class="cue"><span class="time">[09:09]</span>Fair enough.</p>
    <p class="cue"><span class="time">[09:09]</span>You&#x27;ve learned about transformers</p>
    <p class="cue"><span class="time">[09:11]</span>in the online videos, the attention maps, which</p>
    <p class="cue"><span class="time">[09:15]</span>are representative of the relationship</p>
    <p class="cue"><span class="time">[09:18]</span>between different tokens.</p>
    <p class="cue"><span class="time">[09:19]</span>They might not make sense to you.</p>
    <p class="cue"><span class="time">[09:21]</span>You might actually be plotting certain attention maps</p>
    <p class="cue"><span class="time">[09:23]</span>and be like, this token has nothing to do with that one,</p>
    <p class="cue"><span class="time">[09:27]</span>but the model seems to think it has.</p>
    <p class="cue"><span class="time">[09:28]</span>And you might be able to identify certain issues</p>
    <p class="cue"><span class="time">[09:33]</span>with the attention maps.</p>
    <p class="cue"><span class="time">[09:35]</span>What else beyond the attention maps?</p>
    <p class="cue"><span class="time">[09:42]</span>What?</p>
    <p class="cue"><span class="time">[09:43]</span>Yeah.</p>
    <p class="cue"><span class="time">[09:44]</span>I don&#x27;t know myself, but running a sensitivity analysis</p>
    <p class="cue"><span class="time">[09:48]</span>might be helpful to see where with what</p>
    <p class="cue"><span class="time">[09:52]</span>parameters are [INAUDIBLE]</p>
    <p class="cue"><span class="time">[09:56]</span>So you mean-- tell me more about the sensitivity analysis.</p>
    <p class="cue"><span class="time">[09:59]</span>What would you fix, for example, and what would you change?</p>
    <p class="cue"><span class="time">[10:05]</span>Probably the parameters.</p>
    <p class="cue"><span class="time">[10:07]</span>Honestly, right now I don&#x27;t what parameters to touch</p>
    <p class="cue"><span class="time">[10:10]</span>and how to that, but it seems logical to access the analysis</p>
    <p class="cue"><span class="time">[10:15]</span>so you realize what is happening.</p>
    <p class="cue"><span class="time">[10:20]</span>How the parameters actually [INAUDIBLE]</p>
    <p class="cue"><span class="time">[10:27]</span>OK.</p>
    <p class="cue"><span class="time">[10:27]</span>Yeah.</p>
    <p class="cue"><span class="time">[10:28]</span>But I like the idea of sensitivity analysis.</p>
    <p class="cue"><span class="time">[10:31]</span>You might try to figure out which</p>
    <p class="cue"><span class="time">[10:32]</span>hyper parameter went wrong.</p>
    <p class="cue"><span class="time">[10:35]</span>Is there something wrong with our optimizer?</p>
    <p class="cue"><span class="time">[10:37]</span>Is our learning rate schedule poorly tuned?</p>
    <p class="cue"><span class="time">[10:42]</span>Maybe scaling laws.</p>
    <p class="cue"><span class="time">[10:43]</span>That we can play with compute.</p>
    <p class="cue"><span class="time">[10:46]</span>We can play with data.</p>
    <p class="cue"><span class="time">[10:47]</span>We can play with model size.</p>
    <p class="cue"><span class="time">[10:48]</span>And one of those might be going wrong.</p>
    <p class="cue"><span class="time">[10:51]</span>Maybe an analysis would allow us to identify the model is fine.</p>
    <p class="cue"><span class="time">[10:55]</span>It just needs to be trained longer</p>
    <p class="cue"><span class="time">[10:57]</span>or the model is actually too small for the amount</p>
    <p class="cue"><span class="time">[10:59]</span>of data we&#x27;re giving it.</p>
    <p class="cue"><span class="time">[11:01]</span>That type of stuff would come with either doing a sensitivity</p>
    <p class="cue"><span class="time">[11:05]</span>analysis or comparing what we&#x27;re doing to the scaling laws</p>
    <p class="cue"><span class="time">[11:08]</span>that we from other models.</p>
    <p class="cue"><span class="time">[11:11]</span>We&#x27;re going to look into that.</p>
    <p class="cue"><span class="time">[11:13]</span>OK.</p>
    <p class="cue"><span class="time">[11:13]</span>Any other ideas?</p>
    <p class="cue"><span class="time">[11:15]</span>I have a question.</p>
    <p class="cue"><span class="time">[11:17]</span>So these 200 billion parameters, where does the number come from?</p>
    <p class="cue"><span class="time">[11:22]</span>Probably these parameters, we don&#x27;t need them.</p>
    <p class="cue"><span class="time">[11:25]</span>Might be.</p>
    <p class="cue"><span class="time">[11:26]</span>So you&#x27;re saying I gave you 200 billion parameters, which</p>
    <p class="cue"><span class="time">[11:29]</span>is a very large model even as of today.</p>
    <p class="cue"><span class="time">[11:32]</span>It might be overparameterized.</p>
    <p class="cue"><span class="time">[11:34]</span>That&#x27;s a good question because it</p>
    <p class="cue"><span class="time">[11:35]</span>depends on what it&#x27;s been trained on, how much data</p>
    <p class="cue"><span class="time">[11:37]</span>we&#x27;re feeding it, how much compute.</p>
    <p class="cue"><span class="time">[11:39]</span>It&#x27;s all relative to each other.</p>
    <p class="cue"><span class="time">[11:40]</span>But yeah, it&#x27;s a large model.</p>
    <p class="cue"><span class="time">[11:42]</span>So I would expect a lot of compute</p>
    <p class="cue"><span class="time">[11:43]</span>and a lot of data along with it.</p>
    <p class="cue"><span class="time">[11:46]</span>In fact, a lot of these models might be</p>
    <p class="cue"><span class="time">[11:48]</span>built as a mixture of experts.</p>
    <p class="cue"><span class="time">[11:49]</span>You&#x27;ve heard about mixture of experts.</p>
    <p class="cue"><span class="time">[11:52]</span>One thing that could happen is that some of the experts</p>
    <p class="cue"><span class="time">[11:55]</span>are failing, and you might be inspecting if experts</p>
    <p class="cue"><span class="time">[12:00]</span>are in fact failing or the routing module is always</p>
    <p class="cue"><span class="time">[12:04]</span>selecting the same expert because it&#x27;s just</p>
    <p class="cue"><span class="time">[12:06]</span>found an expert that is really good and generalized</p>
    <p class="cue"><span class="time">[12:09]</span>and the other experts are not being used.</p>
    <p class="cue"><span class="time">[12:12]</span>That might be another issue as well</p>
    <p class="cue"><span class="time">[12:14]</span>that might be related to the model capacity.</p>
    <p class="cue"><span class="time">[12:17]</span>Because if the model is not using all its experts,</p>
    <p class="cue"><span class="time">[12:20]</span>it&#x27;s probably not actually operating as a 200 billion</p>
    <p class="cue"><span class="time">[12:23]</span>parameter model.</p>
    <p class="cue"><span class="time">[12:24]</span>It&#x27;s operating as a smaller model.</p>
    <p class="cue"><span class="time">[12:27]</span>So generally, this is to motivate the lecture.</p>
    <p class="cue"><span class="time">[12:31]</span>We&#x27;re going to look into all of these together today.</p>
    <p class="cue"><span class="time">[12:34]</span>And we&#x27;ll start with convolutions</p>
    <p class="cue"><span class="time">[12:36]</span>because they&#x27;re very visual.</p>
    <p class="cue"><span class="time">[12:38]</span>For the convolutional part, we&#x27;re going to go super deep.</p>
    <p class="cue"><span class="time">[12:42]</span>But then for the frontier models,</p>
    <p class="cue"><span class="time">[12:44]</span>I&#x27;m just going to get broader and give you</p>
    <p class="cue"><span class="time">[12:45]</span>the areas of research.</p>
    <p class="cue"><span class="time">[12:47]</span>So the answer to the question I asked typically</p>
    <p class="cue"><span class="time">[12:49]</span>would fall under four buckets, every solution</p>
    <p class="cue"><span class="time">[12:51]</span>that we looked into together.</p>
    <p class="cue"><span class="time">[12:53]</span>One is training and scaling.</p>
    <p class="cue"><span class="time">[12:54]</span>So people are looking at loss curves at things gradients,</p>
    <p class="cue"><span class="time">[13:00]</span>learning rates, mixture of experts, routing, scaling laws.</p>
    <p class="cue"><span class="time">[13:04]</span>We&#x27;re going to talk about all these.</p>
    <p class="cue"><span class="time">[13:06]</span>The second category is representation</p>
    <p class="cue"><span class="time">[13:08]</span>and internal aspect of the model.</p>
    <p class="cue"><span class="time">[13:11]</span>You mentioned. attention heads and maps, embeddings,</p>
    <p class="cue"><span class="time">[13:14]</span>nobody mentioned embeddings but you could actually</p>
    <p class="cue"><span class="time">[13:16]</span>visualize embeddings and see, does it</p>
    <p class="cue"><span class="time">[13:18]</span>make sense to you or these tokens close to each other</p>
    <p class="cue"><span class="time">[13:22]</span>as you would expect?</p>
    <p class="cue"><span class="time">[13:23]</span>Meaning the model&#x27;s mental understanding of language</p>
    <p class="cue"><span class="time">[13:27]</span>is correct.</p>
    <p class="cue"><span class="time">[13:30]</span>And then neuron level behaviors.</p>
    <p class="cue"><span class="time">[13:32]</span>Although that&#x27;s really hard with a large model.</p>
    <p class="cue"><span class="time">[13:35]</span>And nobody has quite figured it out yet.</p>
    <p class="cue"><span class="time">[13:38]</span>And then the other category might be data and distribution.</p>
    <p class="cue"><span class="time">[13:41]</span>Maybe the actual benchmark that we&#x27;re looking at</p>
    <p class="cue"><span class="time">[13:48]</span>has been contaminated.</p>
    <p class="cue"><span class="time">[13:49]</span>Meaning the model either it&#x27;s doing too well on that benchmark</p>
    <p class="cue"><span class="time">[13:54]</span>or it doesn&#x27;t mean anything, or it&#x27;s</p>
    <p class="cue"><span class="time">[13:56]</span>doing poorly for a certain reason</p>
    <p class="cue"><span class="time">[13:58]</span>because the data distribution used in the test set</p>
    <p class="cue"><span class="time">[14:02]</span>is completely different from the training or validation set.</p>
    <p class="cue"><span class="time">[14:05]</span>And then it might be failing at different levels.</p>
    <p class="cue"><span class="time">[14:08]</span>You can run benchmarks on the language model.</p>
    <p class="cue"><span class="time">[14:11]</span>You can run benchmarks on the agentic workflow that</p>
    <p class="cue"><span class="time">[14:14]</span>is using that language model.</p>
    <p class="cue"><span class="time">[14:16]</span>And because you want the language model</p>
    <p class="cue"><span class="time">[14:18]</span>to be used in agentic workflow, those</p>
    <p class="cue"><span class="time">[14:19]</span>are two levels that you need to inspect.</p>
    <p class="cue"><span class="time">[14:22]</span>So, for example, when a frontier lab</p>
    <p class="cue"><span class="time">[14:24]</span>says our model is doing really well for tool use,</p>
    <p class="cue"><span class="time">[14:28]</span>what they mean is the language model</p>
    <p class="cue"><span class="time">[14:30]</span>has been tested on upstream tasks in a workflow,</p>
    <p class="cue"><span class="time">[14:34]</span>and it&#x27;s actually good at tool use against their benchmarks.</p>
    <p class="cue"><span class="time">[14:37]</span>So those are different levels of capability analysis.</p>
    <p class="cue"><span class="time">[14:42]</span>So let&#x27;s talk about convolutions.</p>
    <p class="cue"><span class="time">[14:45]</span>We&#x27;re going to dive deep inside convolutions.</p>
    <p class="cue"><span class="time">[14:47]</span>And then we&#x27;ll go back up and look at frontier models.</p>
    <p class="cue"><span class="time">[14:51]</span>So first case study for convolutions.</p>
    <p class="cue"><span class="time">[14:57]</span>Let&#x27;s say that you have built an animal classifier for a zoo.</p>
    <p class="cue"><span class="time">[15:02]</span>And they are very reluctant to use your model</p>
    <p class="cue"><span class="time">[15:06]</span>without any human supervising because they</p>
    <p class="cue"><span class="time">[15:08]</span>don&#x27;t understand the decision making process of the model.</p>
    <p class="cue"><span class="time">[15:12]</span>How can you alleviate their concerns?</p>
    <p class="cue"><span class="time">[15:14]</span>How can you give them intuition about the decision making</p>
    <p class="cue"><span class="time">[15:17]</span>process of the model so that they</p>
    <p class="cue"><span class="time">[15:19]</span>feel like the models doing things</p>
    <p class="cue"><span class="time">[15:23]</span>that feel natural and human?</p>
    <p class="cue"><span class="time">[15:30]</span>Just to simplify, let&#x27;s say you have</p>
    <p class="cue"><span class="time">[15:32]</span>a convolutional neural network, and there&#x27;s a softmax layer,</p>
    <p class="cue"><span class="time">[15:36]</span>and it&#x27;s supposed to identify animals.</p>
    <p class="cue"><span class="time">[15:38]</span>So the number of classes or many animals.</p>
    <p class="cue"><span class="time">[15:41]</span>Yeah.</p>
    <p class="cue"><span class="time">[15:56]</span>If you were to write a quick Python</p>
    <p class="cue"><span class="time">[15:57]</span>code to give them some intuition, how would you do it?</p>
    <p class="cue"><span class="time">[16:01]</span>Yeah.</p>
    <p class="cue"><span class="time">[16:01]</span>Thanks very much.</p>
    <p class="cue"><span class="time">[16:02]</span>First, with the softmax is how we&#x27;re</p>
    <p class="cue"><span class="time">[16:05]</span>going to eventually get at the end result,</p>
    <p class="cue"><span class="time">[16:07]</span>probabilities what the animal is.</p>
    <p class="cue"><span class="time">[16:10]</span>And then the next thing I will explain is how with the CNN,</p>
    <p class="cue"><span class="time">[16:14]</span>each layer of our CNN is getting more in depth,</p>
    <p class="cue"><span class="time">[16:18]</span>I guess, features of the image of the animals are showing.</p>
    <p class="cue"><span class="time">[16:23]</span>And then maybe if I have time, I can try and use different images</p>
    <p class="cue"><span class="time">[16:29]</span>and try to figure out what each layer [INAUDIBLE]</p>
    <p class="cue"><span class="time">[16:33]</span>OK.</p>
    <p class="cue"><span class="time">[16:35]</span>Good.</p>
    <p class="cue"><span class="time">[16:36]</span>So just to recap, the zoo is not I native.</p>
    <p class="cue"><span class="time">[16:39]</span>So you have to explain certain things.</p>
    <p class="cue"><span class="time">[16:41]</span>You&#x27;re going to tell them what softmax is.</p>
    <p class="cue"><span class="time">[16:42]</span>So we&#x27;re going to have a probability for each animal</p>
    <p class="cue"><span class="time">[16:45]</span>classes.</p>
    <p class="cue"><span class="time">[16:46]</span>That&#x27;s how it works.</p>
    <p class="cue"><span class="time">[16:47]</span>And on top of that, you also mentioned</p>
    <p class="cue"><span class="time">[16:48]</span>you might talk about convolutions</p>
    <p class="cue"><span class="time">[16:50]</span>and say here are how features are identified,</p>
    <p class="cue"><span class="time">[16:53]</span>here is how a filter scans through the image.</p>
    <p class="cue"><span class="time">[16:56]</span>And we&#x27;re expecting this to learn.</p>
    <p class="cue"><span class="time">[16:58]</span>So you&#x27;re going to educate them first.</p>
    <p class="cue"><span class="time">[16:59]</span>That&#x27;s totally right.</p>
    <p class="cue"><span class="time">[17:00]</span>The second thing you mentioned is maybe</p>
    <p class="cue"><span class="time">[17:02]</span>you run a data set search.</p>
    <p class="cue"><span class="time">[17:04]</span>So you can try to build their intuition</p>
    <p class="cue"><span class="time">[17:06]</span>by showing them animal pictures and showing</p>
    <p class="cue"><span class="time">[17:08]</span>that the model is doing well.</p>
    <p class="cue"><span class="time">[17:10]</span>And yeah, I agree those are good approaches.</p>
    <p class="cue"><span class="time">[17:12]</span>We&#x27;re going to see how to do a proper data set</p>
    <p class="cue"><span class="time">[17:15]</span>search large scale.</p>
    <p class="cue"><span class="time">[17:17]</span>But what else can you do that&#x27;s going to give a little bit</p>
    <p class="cue"><span class="time">[17:20]</span>more confidence?</p>
    <p class="cue"><span class="time">[17:21]</span>Because this is explanation, but it&#x27;s not proof</p>
    <p class="cue"><span class="time">[17:23]</span>that the model is looking at the right place systematically.</p>
    <p class="cue"><span class="time">[17:27]</span>Yeah.</p>
    <p class="cue"><span class="time">[17:27]</span>You display some of the hurdles and demonstrate [INAUDIBLE],</p>
    <p class="cue"><span class="time">[17:36]</span>and show all the small features that [INAUDIBLE].</p>
    <p class="cue"><span class="time">[17:41]</span>So you say, ideally, you would give them</p>
    <p class="cue"><span class="time">[17:43]</span>intuition at a filter level.</p>
    <p class="cue"><span class="time">[17:46]</span>This filter we know it&#x27;s responsible for finding</p>
    <p class="cue"><span class="time">[17:49]</span>the legs of an animal.</p>
    <p class="cue"><span class="time">[17:50]</span>That&#x27;s what you&#x27;re saying.</p>
    <p class="cue"><span class="time">[17:51]</span>So how would you do that?</p>
    <p class="cue"><span class="time">[17:54]</span>Well, maybe I don&#x27;t know enough but it&#x27;s not supposed</p>
    <p class="cue"><span class="time">[17:57]</span>to bring out the [INAUDIBLE]</p>
    <p class="cue"><span class="time">[18:03]</span>Good intuition.</p>
    <p class="cue"><span class="time">[18:04]</span>You&#x27;re asking, is it as simple as just printing out</p>
    <p class="cue"><span class="time">[18:07]</span>the weights that are identified or the feature map</p>
    <p class="cue"><span class="time">[18:10]</span>that results of that filter?</p>
    <p class="cue"><span class="time">[18:13]</span>Unfortunately, not usually, because that</p>
    <p class="cue"><span class="time">[18:15]</span>might be true for the first layer.</p>
    <p class="cue"><span class="time">[18:18]</span>But as you get deeper, things mix up</p>
    <p class="cue"><span class="time">[18:20]</span>so much that if you were just to print the filter,</p>
    <p class="cue"><span class="time">[18:25]</span>it wouldn&#x27;t make any sense.</p>
    <p class="cue"><span class="time">[18:27]</span>Pretty much.</p>
    <p class="cue"><span class="time">[18:29]</span>But there are other methods that we&#x27;re going to see.</p>
    <p class="cue"><span class="time">[18:31]</span>So your intuition is right.</p>
    <p class="cue"><span class="time">[18:32]</span>We&#x27;re going to try to give them that.</p>
    <p class="cue"><span class="time">[18:33]</span>Something simpler, input/output relationship.</p>
    <p class="cue"><span class="time">[18:37]</span>How would you show that the output is actually</p>
    <p class="cue"><span class="time">[18:42]</span>related to the right portions of the inputs for this dog,</p>
    <p class="cue"><span class="time">[18:46]</span>for example?</p>
    <p class="cue"><span class="time">[18:48]</span>Yeah.</p>
    <p class="cue"><span class="time">[18:49]</span>Recall a confusion matrix.</p>
    <p class="cue"><span class="time">[18:52]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[18:56]</span>Confusion matrix across a lot of data.</p>
    <p class="cue"><span class="time">[18:58]</span>You would find true positives, false, et cetera.</p>
    <p class="cue"><span class="time">[19:01]</span>Yeah.</p>
    <p class="cue"><span class="time">[19:01]</span>Correct.</p>
    <p class="cue"><span class="time">[19:02]</span>Something else.</p>
    <p class="cue"><span class="time">[19:03]</span>You have a critical layer of your network</p>
    <p class="cue"><span class="time">[19:12]</span>and then you show how it completes over different layers</p>
    <p class="cue"><span class="time">[19:17]</span>to show how from the first layer is taken.</p>
    <p class="cue"><span class="time">[19:21]</span>That doesn&#x27;t give us [INAUDIBLE]</p>
    <p class="cue"><span class="time">[19:24]</span>So similar to what he said, you want</p>
    <p class="cue"><span class="time">[19:27]</span>to give them intuition from the inner workings of the network.</p>
    <p class="cue"><span class="time">[19:30]</span>And you&#x27;re saying, how about we mask</p>
    <p class="cue"><span class="time">[19:31]</span>the latter parts of the network and we</p>
    <p class="cue"><span class="time">[19:34]</span>treat every intermediary layer as an output,</p>
    <p class="cue"><span class="time">[19:37]</span>and analyzing the output makes sense.</p>
    <p class="cue"><span class="time">[19:39]</span>Yeah, we&#x27;re going to look at that actually.</p>
    <p class="cue"><span class="time">[19:42]</span>Yeah those are more advanced.</p>
    <p class="cue"><span class="time">[19:43]</span>What I was looking for is even much more basic.</p>
    <p class="cue"><span class="time">[19:46]</span>If you want to show the relationship between an input</p>
    <p class="cue"><span class="time">[19:50]</span>and an output of a CNN or any vision model,</p>
    <p class="cue"><span class="time">[19:55]</span>you might take the score of the dog in the output layer.</p>
    <p class="cue"><span class="time">[19:59]</span>And what is exactly this quantity?</p>
    <p class="cue"><span class="time">[20:03]</span>What is your intuition for what this quantity means?</p>
    <p class="cue"><span class="time">[20:12]</span>If you take the derivative of the score of an animal class</p>
    <p class="cue"><span class="time">[20:16]</span>with respect to x, with x being the input image--</p>
    <p class="cue"><span class="time">[20:25]</span>yeah.</p>
    <p class="cue"><span class="time">[20:26]</span>How does the score of dog vary when</p>
    <p class="cue"><span class="time">[20:30]</span>you change things around some?</p>
    <p class="cue"><span class="time">[20:32]</span>How does the score of dog change when you move pixels around?</p>
    <p class="cue"><span class="time">[20:37]</span>Which is what you want.</p>
    <p class="cue"><span class="time">[20:38]</span>You want to be able to-- if you can do that, you would indicate</p>
    <p class="cue"><span class="time">[20:41]</span>that which are the pixels of the image that if we change them,</p>
    <p class="cue"><span class="time">[20:45]</span>it changes the score of dog.</p>
    <p class="cue"><span class="time">[20:47]</span>If you can print that, then you would</p>
    <p class="cue"><span class="time">[20:49]</span>be able to show this is where the model is looking</p>
    <p class="cue"><span class="time">[20:51]</span>at when it&#x27;s predicting a dog.</p>
    <p class="cue"><span class="time">[20:54]</span>So yeah, if you actually calculate this derivative,</p>
    <p class="cue"><span class="time">[20:59]</span>you would get something like that where some of the pixels</p>
    <p class="cue"><span class="time">[21:02]</span>are going to be brighter, meaning their gradient is higher</p>
    <p class="cue"><span class="time">[21:05]</span>and some of the pixels are going to be darker,</p>
    <p class="cue"><span class="time">[21:07]</span>meaning we move that pixel and it didn&#x27;t</p>
    <p class="cue"><span class="time">[21:09]</span>modify the score of dog at all.</p>
    <p class="cue"><span class="time">[21:12]</span>That&#x27;s a very quick way to look at which pixels in the input</p>
    <p class="cue"><span class="time">[21:16]</span>were relevant for the score of dog.</p>
    <p class="cue"><span class="time">[21:20]</span>Now why should we select the score of dog pre-softmax</p>
    <p class="cue"><span class="time">[21:25]</span>versus post-softmax?</p>
    <p class="cue"><span class="time">[21:30]</span>It&#x27;s usually a very common misconception.</p>
    <p class="cue"><span class="time">[21:34]</span>Yeah.</p>
    <p class="cue"><span class="time">[21:35]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[21:41]</span>So what&#x27;s the issue with the scaled version?</p>
    <p class="cue"><span class="time">[21:46]</span>It&#x27;s more representative of the actual score.</p>
    <p class="cue"><span class="time">[21:50]</span>Class of dog.</p>
    <p class="cue"><span class="time">[21:50]</span>So what you said is the post-softmax score</p>
    <p class="cue"><span class="time">[21:55]</span>is not only dependent on dog; it&#x27;s also</p>
    <p class="cue"><span class="time">[21:57]</span>dependent on all the other scores.</p>
    <p class="cue"><span class="time">[21:59]</span>So you could actually take a pixel, move it,</p>
    <p class="cue"><span class="time">[22:02]</span>and it happens to modify the score of a panda</p>
    <p class="cue"><span class="time">[22:06]</span>because there&#x27;s a panda in the background or something.</p>
    <p class="cue"><span class="time">[22:08]</span>And it would influence what you&#x27;re trying to show.</p>
    <p class="cue"><span class="time">[22:11]</span>But you&#x27;re only looking at dog.</p>
    <p class="cue"><span class="time">[22:12]</span>You just want the score of dog to be influenced.</p>
    <p class="cue"><span class="time">[22:15]</span>So that&#x27;s why in this method called saliency maps,</p>
    <p class="cue"><span class="time">[22:19]</span>we use the pre-softmax scores that</p>
    <p class="cue"><span class="time">[22:21]</span>is only representative of the class at hand</p>
    <p class="cue"><span class="time">[22:24]</span>that you&#x27;re analyzing.</p>
    <p class="cue"><span class="time">[22:26]</span>OK.</p>
    <p class="cue"><span class="time">[22:26]</span>So you could do that.</p>
    <p class="cue"><span class="time">[22:27]</span>And actually if you were to, in the past, not anymore,</p>
    <p class="cue"><span class="time">[22:30]</span>but you could use that for a quick segmentation sanity check</p>
    <p class="cue"><span class="time">[22:34]</span>because the pixels that are brighter,</p>
    <p class="cue"><span class="time">[22:35]</span>the gradients that are brighter are</p>
    <p class="cue"><span class="time">[22:37]</span>representatives of the pixels that</p>
    <p class="cue"><span class="time">[22:38]</span>should be overlaid on the dog.</p>
    <p class="cue"><span class="time">[22:41]</span>And in fact, if you do the saliency maps</p>
    <p class="cue"><span class="time">[22:42]</span>and you realize that the pixels that are bright when you compute</p>
    <p class="cue"><span class="time">[22:46]</span>that gradient are all over the place,</p>
    <p class="cue"><span class="time">[22:47]</span>it&#x27;s probably that the model is not even</p>
    <p class="cue"><span class="time">[22:49]</span>looking at the right place.</p>
    <p class="cue"><span class="time">[22:50]</span>It&#x27;s just getting lucky.</p>
    <p class="cue"><span class="time">[22:52]</span>OK.</p>
    <p class="cue"><span class="time">[22:53]</span>So this first method, saliency maps,</p>
    <p class="cue"><span class="time">[22:56]</span>now have that in your toolkit.</p>
    <p class="cue"><span class="time">[22:58]</span>Very easy to implement.</p>
    <p class="cue"><span class="time">[23:00]</span>You just write a Python script.</p>
    <p class="cue"><span class="time">[23:01]</span>You perform the gradient calculation.</p>
    <p class="cue"><span class="time">[23:04]</span>You print it.</p>
    <p class="cue"><span class="time">[23:04]</span>It&#x27;s a matrix of pixels that are brighter or darker,</p>
    <p class="cue"><span class="time">[23:08]</span>and you&#x27;re done.</p>
    <p class="cue"><span class="time">[23:10]</span>One of the main issues with saliency maps</p>
    <p class="cue"><span class="time">[23:13]</span>is that it&#x27;s looking at just a pixel level, which</p>
    <p class="cue"><span class="time">[23:17]</span>doesn&#x27;t make too much sense if you</p>
    <p class="cue"><span class="time">[23:19]</span>want to interpret semantically where the model is looking at.</p>
    <p class="cue"><span class="time">[23:22]</span>The model will never see a cat or a dog</p>
    <p class="cue"><span class="time">[23:25]</span>with one pixel being different than the rest.</p>
    <p class="cue"><span class="time">[23:29]</span>It would be too discontinuous.</p>
    <p class="cue"><span class="time">[23:30]</span>So instead, there&#x27;s another method,</p>
    <p class="cue"><span class="time">[23:32]</span>I&#x27;m not going to go into the detail,</p>
    <p class="cue"><span class="time">[23:33]</span>but I linked the paper, which is way more common,</p>
    <p class="cue"><span class="time">[23:36]</span>called integrated gradients.</p>
    <p class="cue"><span class="time">[23:38]</span>And integrated gradients, the idea</p>
    <p class="cue"><span class="time">[23:41]</span>is that instead of doing that directly by taking the ds of dog</p>
    <p class="cue"><span class="time">[23:45]</span>over dx, we&#x27;re going to take an image of the animal,</p>
    <p class="cue"><span class="time">[23:49]</span>and we&#x27;re going to generate many pictures that</p>
    <p class="cue"><span class="time">[23:54]</span>are taking a dark, completely black zero&#x27;s pixel all the way</p>
    <p class="cue"><span class="time">[24:00]</span>to the animal, the final image.</p>
    <p class="cue"><span class="time">[24:03]</span>And then we&#x27;re going to look at the path of gradients</p>
    <p class="cue"><span class="time">[24:06]</span>across all of these updates.</p>
    <p class="cue"><span class="time">[24:08]</span>And it&#x27;s going to be way more interpretive.</p>
    <p class="cue"><span class="time">[24:11]</span>I&#x27;m not going to go into the details.</p>
    <p class="cue"><span class="time">[24:12]</span>But integrated gradients is just an extension of saliency maps</p>
    <p class="cue"><span class="time">[24:15]</span>that happens to use a different formula with an integration</p>
    <p class="cue"><span class="time">[24:19]</span>and is way more common.</p>
    <p class="cue"><span class="time">[24:21]</span>If you look at it practically, this</p>
    <p class="cue"><span class="time">[24:22]</span>is an example from the medical field.</p>
    <p class="cue"><span class="time">[24:24]</span>Here is an image of a retina.</p>
    <p class="cue"><span class="time">[24:27]</span>And if you perform the integrated gradients,</p>
    <p class="cue"><span class="time">[24:30]</span>you would see that the original image, the annotation</p>
    <p class="cue"><span class="time">[24:37]</span>for the lesions are exactly where the model is looking</p>
    <p class="cue"><span class="time">[24:40]</span>at when it&#x27;s giving you a probability</p>
    <p class="cue"><span class="time">[24:43]</span>that there is a lesion.</p>
    <p class="cue"><span class="time">[24:46]</span>So the second method called integrated gradients.</p>
    <p class="cue"><span class="time">[24:50]</span>Let&#x27;s push it a little further.</p>
    <p class="cue"><span class="time">[24:53]</span>The next case study is that you want to now tell them</p>
    <p class="cue"><span class="time">[25:01]</span>a little more about the decision process of the model with--</p>
    <p class="cue"><span class="time">[25:10]</span>I guess let me rephrase.</p>
    <p class="cue"><span class="time">[25:12]</span>The saliency maps looked at the pixel level.</p>
    <p class="cue"><span class="time">[25:16]</span>What you can do in order to give a better intuition, which</p>
    <p class="cue"><span class="time">[25:20]</span>was mentioned earlier, is another approach</p>
    <p class="cue"><span class="time">[25:24]</span>called occlusion sensitivity, which is actually</p>
    <p class="cue"><span class="time">[25:27]</span>way more intuitive and simple, where you could actually</p>
    <p class="cue"><span class="time">[25:32]</span>take the dog image and paste it into the CNN,</p>
    <p class="cue"><span class="time">[25:35]</span>and you would get a score of a dog.</p>
    <p class="cue"><span class="time">[25:38]</span>You could also overlay a dark square, so zero out or mask</p>
    <p class="cue"><span class="time">[25:42]</span>partially the input image and give it to the same CNN</p>
    <p class="cue"><span class="time">[25:47]</span>and track the modifications on the score of dog</p>
    <p class="cue"><span class="time">[25:51]</span>that you&#x27;re tracking.</p>
    <p class="cue"><span class="time">[25:53]</span>If you actually do that, you can plot a probability map</p>
    <p class="cue"><span class="time">[25:57]</span>of how is the score of dog changing</p>
    <p class="cue"><span class="time">[26:00]</span>as I move the dark square through the image?</p>
    <p class="cue"><span class="time">[26:05]</span>So let&#x27;s do it together.</p>
    <p class="cue"><span class="time">[26:06]</span>I&#x27;m going to say that this one, when you actually</p>
    <p class="cue"><span class="time">[26:09]</span>put the dark square on the top left of the image, the score</p>
    <p class="cue"><span class="time">[26:12]</span>of dog is unchanged.</p>
    <p class="cue"><span class="time">[26:13]</span>It&#x27;s still very high.</p>
    <p class="cue"><span class="time">[26:14]</span>Now you move the square a little bit to the right,</p>
    <p class="cue"><span class="time">[26:18]</span>and you see that it&#x27;s still very high, the score of dog.</p>
    <p class="cue"><span class="time">[26:22]</span>You do it again, still very high.</p>
    <p class="cue"><span class="time">[26:24]</span>Now, the square is partially occluding the face of the dog,</p>
    <p class="cue"><span class="time">[26:29]</span>and you should see the score of dog drop</p>
    <p class="cue"><span class="time">[26:32]</span>if the model is, in fact, looking at the dog.</p>
    <p class="cue"><span class="time">[26:35]</span>And you perform that many times.</p>
    <p class="cue"><span class="time">[26:37]</span>So you scan through the image with your dark square,</p>
    <p class="cue"><span class="time">[26:40]</span>and you plot what we call the probability</p>
    <p class="cue"><span class="time">[26:45]</span>map of the true class for different positions</p>
    <p class="cue"><span class="time">[26:47]</span>of the gray square.</p>
    <p class="cue"><span class="time">[26:50]</span>Does that make sense?</p>
    <p class="cue"><span class="time">[26:51]</span>So pretty simple, computationally expensive</p>
    <p class="cue"><span class="time">[26:54]</span>though.</p>
    <p class="cue"><span class="time">[26:55]</span>Just have to rerun the image so many times through the model.</p>
    <p class="cue"><span class="time">[26:59]</span>Here are practical examples to look at.</p>
    <p class="cue"><span class="time">[27:03]</span>The first one, the true label is a Pomeranian cute dog.</p>
    <p class="cue"><span class="time">[27:09]</span>And you see that the model is failing</p>
    <p class="cue"><span class="time">[27:12]</span>to recognize the true class when the square is overlapping</p>
    <p class="cue"><span class="time">[27:16]</span>with the center of the face, which makes sense</p>
    <p class="cue"><span class="time">[27:19]</span>because here the true class that we&#x27;re tracking is not dog.</p>
    <p class="cue"><span class="time">[27:22]</span>It&#x27;s Pomeranian.</p>
    <p class="cue"><span class="time">[27:23]</span>And I could see how if you occlude the face,</p>
    <p class="cue"><span class="time">[27:27]</span>it&#x27;s hard to get the breed of the dog.</p>
    <p class="cue"><span class="time">[27:30]</span>The second example, the true label is a car wheel-- sorry,</p>
    <p class="cue"><span class="time">[27:34]</span>I hadn&#x27;t shown you that.</p>
    <p class="cue"><span class="time">[27:35]</span>The true label is a car wheel.</p>
    <p class="cue"><span class="time">[27:37]</span>And you can see that when the square is on the wheel,</p>
    <p class="cue"><span class="time">[27:41]</span>it is in fact dropping in terms of the true class probability.</p>
    <p class="cue"><span class="time">[27:46]</span>And then finally the Afghan hound.</p>
    <p class="cue"><span class="time">[27:48]</span>What&#x27;s interesting about that third example is the probability</p>
    <p class="cue"><span class="time">[27:52]</span>is dropping when the square is on the dog,</p>
    <p class="cue"><span class="time">[27:54]</span>but it&#x27;s also increasing when the square is</p>
    <p class="cue"><span class="time">[27:57]</span>on the face of the human on the left, which</p>
    <p class="cue"><span class="time">[28:01]</span>means that if you actually occlude the face of the human,</p>
    <p class="cue"><span class="time">[28:03]</span>the model thinks even more that the true class is</p>
    <p class="cue"><span class="time">[28:07]</span>in fact an Afghan hound.</p>
    <p class="cue"><span class="time">[28:10]</span>You&#x27;re just removing additional unnecessary information for it</p>
    <p class="cue"><span class="time">[28:13]</span>to discover the true class.</p>
    <p class="cue"><span class="time">[28:15]</span>So this model seems to be doing well.</p>
    <p class="cue"><span class="time">[28:17]</span>It seems to be looking in the right place.</p>
    <p class="cue"><span class="time">[28:20]</span>We call that occlusion sensitivity.</p>
    <p class="cue"><span class="time">[28:23]</span>Pretty simple, another tool with saliency map</p>
    <p class="cue"><span class="time">[28:25]</span>and integrated gradients in your toolkit.</p>
    <p class="cue"><span class="time">[28:30]</span>Let&#x27;s push it slightly further.</p>
    <p class="cue"><span class="time">[28:37]</span>Here we&#x27;re given, along with the classification output,</p>
    <p class="cue"><span class="time">[28:45]</span>the zoo wants a real time visualization of the model&#x27;s</p>
    <p class="cue"><span class="time">[28:49]</span>decision process.</p>
    <p class="cue"><span class="time">[28:51]</span>And you have one day to show that.</p>
    <p class="cue"><span class="time">[28:53]</span>And we&#x27;re talking about convolutions again.</p>
    <p class="cue"><span class="time">[28:55]</span>What do you do?</p>
    <p class="cue"><span class="time">[28:56]</span>So the important part is to know the methods that we&#x27;ve</p>
    <p class="cue"><span class="time">[29:00]</span>seen so far are post methods where you analyze the output</p>
    <p class="cue"><span class="time">[29:06]</span>or you show something.</p>
    <p class="cue"><span class="time">[29:07]</span>Here we&#x27;re looking at ideally a module</p>
    <p class="cue"><span class="time">[29:11]</span>that we could plug in our network that would constantly</p>
    <p class="cue"><span class="time">[29:13]</span>give us the decision making process of the network,</p>
    <p class="cue"><span class="time">[29:16]</span>or at least where it&#x27;s looking at.</p>
    <p class="cue"><span class="time">[29:19]</span>How would you do this?</p>
    <p class="cue"><span class="time">[29:26]</span>This is our network, by the way.</p>
    <p class="cue"><span class="time">[29:28]</span>We&#x27;re taking an input.</p>
    <p class="cue"><span class="time">[29:29]</span>We&#x27;re adding zero padding, and we have a series</p>
    <p class="cue"><span class="time">[29:32]</span>of conv ReLU max pool blocks.</p>
    <p class="cue"><span class="time">[29:34]</span>And then at the end, we flatten.</p>
    <p class="cue"><span class="time">[29:36]</span>We have a triple fully connected layer, a softmax,</p>
    <p class="cue"><span class="time">[29:40]</span>and we get our probability output for classification.</p>
    <p class="cue"><span class="time">[29:45]</span>So first question, where do you think</p>
    <p class="cue"><span class="time">[29:49]</span>is the weakness of this network when</p>
    <p class="cue"><span class="time">[29:51]</span>it comes to interpreting where the model is looking</p>
    <p class="cue"><span class="time">[29:54]</span>at on a picture?</p>
    <p class="cue"><span class="time">[30:04]</span>A part of this architecture is very mixed,</p>
    <p class="cue"><span class="time">[30:08]</span>interpreting the network way harder.</p>
    <p class="cue"><span class="time">[30:10]</span>Yeah.</p>
    <p class="cue"><span class="time">[30:12]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[30:12]</span>Why?</p>
    <p class="cue"><span class="time">[30:13]</span>Because of you look at all the pixels at once, I guess,</p>
    <p class="cue"><span class="time">[30:19]</span>over the last month, there have been three of them.</p>
    <p class="cue"><span class="time">[30:23]</span>So it&#x27;s three layers of abstraction from the last layer</p>
    <p class="cue"><span class="time">[30:26]</span>all the way to what you get.</p>
    <p class="cue"><span class="time">[30:29]</span>Yeah, totally right.</p>
    <p class="cue"><span class="time">[30:30]</span>They&#x27;re fully connected layers.</p>
    <p class="cue"><span class="time">[30:32]</span>You&#x27;re looking at all the pixels at the same time.</p>
    <p class="cue"><span class="time">[30:34]</span>You&#x27;re mixing everything, and you&#x27;re doing it three times.</p>
    <p class="cue"><span class="time">[30:37]</span>So by the end of those three layers,</p>
    <p class="cue"><span class="time">[30:39]</span>the information has been mixed together, essentially.</p>
    <p class="cue"><span class="time">[30:42]</span>You do not find the localized information</p>
    <p class="cue"><span class="time">[30:44]</span>that you had pre that with the maxpool and the conv layers.</p>
    <p class="cue"><span class="time">[30:48]</span>So how could you change that layer in order to avoid that?</p>
    <p class="cue"><span class="time">[30:52]</span>How would you modify your network</p>
    <p class="cue"><span class="time">[30:53]</span>if you wanted to retain maybe the performance of the model</p>
    <p class="cue"><span class="time">[30:57]</span>but not lose that localized information?</p>
    <p class="cue"><span class="time">[31:01]</span>I guess, could you do one layer.</p>
    <p class="cue"><span class="time">[31:05]</span>I think it&#x27;s huge.</p>
    <p class="cue"><span class="time">[31:06]</span>I don&#x27;t it know.</p>
    <p class="cue"><span class="time">[31:06]</span>But it might be--</p>
    <p class="cue"><span class="time">[31:07]</span>I don&#x27;t actually know how many times larger than.</p>
    <p class="cue"><span class="time">[31:10]</span>Yeah, good idea.</p>
    <p class="cue"><span class="time">[31:12]</span>Instead of doing three, can we do one?</p>
    <p class="cue"><span class="time">[31:14]</span>Can we still have a layer that makes the interpretation easy.</p>
    <p class="cue"><span class="time">[31:19]</span>Actually, there&#x27;s another trick which we&#x27;re going to see,</p>
    <p class="cue"><span class="time">[31:22]</span>but it&#x27;s similar to what you described.</p>
    <p class="cue"><span class="time">[31:24]</span>Let&#x27;s say we convert this network</p>
    <p class="cue"><span class="time">[31:27]</span>into something where the flattening of the pixels</p>
    <p class="cue"><span class="time">[31:31]</span>and the fully connected layers are converted</p>
    <p class="cue"><span class="time">[31:33]</span>into a single global average pooling layer</p>
    <p class="cue"><span class="time">[31:37]</span>and a fully connected layer.</p>
    <p class="cue"><span class="time">[31:40]</span>So here we reduce from 3 to 1, the fully connected layers.</p>
    <p class="cue"><span class="time">[31:44]</span>We still need our fully connected layers and our softmax</p>
    <p class="cue"><span class="time">[31:46]</span>because it&#x27;s a classification task,</p>
    <p class="cue"><span class="time">[31:48]</span>and we want a good decision engine at the end.</p>
    <p class="cue"><span class="time">[31:50]</span>But we converted.</p>
    <p class="cue"><span class="time">[31:52]</span>We added a global average pooling.</p>
    <p class="cue"><span class="time">[31:53]</span>So let me explain why this is better.</p>
    <p class="cue"><span class="time">[31:57]</span>So the last conv block essentially</p>
    <p class="cue"><span class="time">[32:01]</span>is giving us a volume.</p>
    <p class="cue"><span class="time">[32:03]</span>For the sake of simplicity, let&#x27;s say that volume</p>
    <p class="cue"><span class="time">[32:06]</span>is a 4 by 4 with six channels.</p>
    <p class="cue"><span class="time">[32:10]</span>And I color-coded them for simplicity.</p>
    <p class="cue"><span class="time">[32:14]</span>So each of these channels is a feature map</p>
    <p class="cue"><span class="time">[32:18]</span>that is resulting from a filter being scanned</p>
    <p class="cue"><span class="time">[32:21]</span>through the previous input.</p>
    <p class="cue"><span class="time">[32:23]</span>Everybody&#x27;s clear on that?</p>
    <p class="cue"><span class="time">[32:27]</span>So global average pooling is going</p>
    <p class="cue"><span class="time">[32:30]</span>to take each of these channels, feature maps,</p>
    <p class="cue"><span class="time">[32:34]</span>and is going to average them in a single number.</p>
    <p class="cue"><span class="time">[32:38]</span>So if you take the orange matrix and you average it,</p>
    <p class="cue"><span class="time">[32:42]</span>it gives you 104.7.</p>
    <p class="cue"><span class="time">[32:45]</span>You do the same thing with the green one, the blue one, all six</p>
    <p class="cue"><span class="time">[32:48]</span>of them, and you get a volume or call</p>
    <p class="cue"><span class="time">[32:52]</span>it a vector of size 6, 1, 1, 6.</p>
    <p class="cue"><span class="time">[32:56]</span>So why is that interesting?</p>
    <p class="cue"><span class="time">[32:58]</span>Because we actually did not lose the localized information.</p>
    <p class="cue"><span class="time">[33:02]</span>We did not mix things up.</p>
    <p class="cue"><span class="time">[33:03]</span>We just assigned a single number to a feature map</p>
    <p class="cue"><span class="time">[33:08]</span>that we retained, so the localized information is still</p>
    <p class="cue"><span class="time">[33:12]</span>there on the previous volume.</p>
    <p class="cue"><span class="time">[33:15]</span>And now we can treat that as a vector that</p>
    <p class="cue"><span class="time">[33:17]</span>goes through a decision engine or a fully connected layer that</p>
    <p class="cue"><span class="time">[33:20]</span>ultimately goes through our softmax</p>
    <p class="cue"><span class="time">[33:22]</span>and gives us the probabilities.</p>
    <p class="cue"><span class="time">[33:24]</span>So this architecture is easier to trace back</p>
    <p class="cue"><span class="time">[33:28]</span>to localized information in the input space</p>
    <p class="cue"><span class="time">[33:31]</span>because you can actually look at, let&#x27;s say,</p>
    <p class="cue"><span class="time">[33:33]</span>one of the score of dog.</p>
    <p class="cue"><span class="time">[33:35]</span>And you can look at the weights of each of these edges that</p>
    <p class="cue"><span class="time">[33:41]</span>tell you how much has the feature map from the volume</p>
    <p class="cue"><span class="time">[33:45]</span>before contributed to that score.</p>
    <p class="cue"><span class="time">[33:49]</span>So in other words, if I had to summarize,</p>
    <p class="cue"><span class="time">[33:51]</span>let&#x27;s say the feature map looks like this.</p>
    <p class="cue"><span class="time">[33:53]</span>So this feature map is very high, has somehow</p>
    <p class="cue"><span class="time">[33:56]</span>activated heavily in some portion of the input image.</p>
    <p class="cue"><span class="time">[34:00]</span>The others similarly have activated two other things.</p>
    <p class="cue"><span class="time">[34:04]</span>You&#x27;re taking the weights from your fully connected layer.</p>
    <p class="cue"><span class="time">[34:07]</span>By the way, you have to retrain that layer.</p>
    <p class="cue"><span class="time">[34:09]</span>You have to just train that layer, that last one, and then</p>
    <p class="cue"><span class="time">[34:12]</span>you sum all of them, and it gives you</p>
    <p class="cue"><span class="time">[34:14]</span>what we call a class activation map for the class</p>
    <p class="cue"><span class="time">[34:17]</span>that you&#x27;re visualizing.</p>
    <p class="cue"><span class="time">[34:21]</span>So you&#x27;re overlaying those last six feature maps,</p>
    <p class="cue"><span class="time">[34:24]</span>and you&#x27;re weighing them with the weights of the last fully</p>
    <p class="cue"><span class="time">[34:27]</span>connected layer.</p>
    <p class="cue"><span class="time">[34:28]</span>You&#x27;re not losing information.</p>
    <p class="cue"><span class="time">[34:29]</span>You&#x27;re not mixing three fully connected layers</p>
    <p class="cue"><span class="time">[34:31]</span>that are impossible to trace back to the input space.</p>
    <p class="cue"><span class="time">[34:39]</span>OK.</p>
    <p class="cue"><span class="time">[34:40]</span>So if you now give it an input image,</p>
    <p class="cue"><span class="time">[34:42]</span>and you overlay the class activation</p>
    <p class="cue"><span class="time">[34:44]</span>map for the score of dog, which you can do for other classes,</p>
    <p class="cue"><span class="time">[34:47]</span>you can do the same thing for the class of cat,</p>
    <p class="cue"><span class="time">[34:49]</span>look at the different weights, the feature maps,</p>
    <p class="cue"><span class="time">[34:51]</span>and maybe for the class of cat, the weights</p>
    <p class="cue"><span class="time">[34:53]</span>will certainly be different.</p>
    <p class="cue"><span class="time">[34:55]</span>So the contribution of each feature map will be different.</p>
    <p class="cue"><span class="time">[34:59]</span>Yeah.</p>
    <p class="cue"><span class="time">[34:59]</span>And this is what you get.</p>
    <p class="cue"><span class="time">[35:00]</span>This is called class activation map.</p>
    <p class="cue"><span class="time">[35:04]</span>And it&#x27;s from folks over at Berkeley.</p>
    <p class="cue"><span class="time">[35:08]</span>And so here&#x27;s a video that describes it.</p>
    <p class="cue"><span class="time">[35:10]</span>It runs really quickly.</p>
    <p class="cue"><span class="time">[35:11]</span>You can think of it as a slight modification to a vision network</p>
    <p class="cue"><span class="time">[35:16]</span>that can allow you to unpack what&#x27;s happening inside</p>
    <p class="cue"><span class="time">[35:19]</span>and what&#x27;s the decision process.</p>
    <p class="cue"><span class="time">[35:21]</span>There&#x27;s also an improvement to the CAM or Class Activation Map</p>
    <p class="cue"><span class="time">[35:27]</span>algorithm called Grad-CAM, which enhances that method.</p>
    <p class="cue"><span class="time">[35:38]</span>Any questions on class activation maps?</p>
    <p class="cue"><span class="time">[35:45]</span>So we&#x27;re getting to know convolutions a little better.</p>
    <p class="cue"><span class="time">[35:48]</span>Yeah.</p>
    <p class="cue"><span class="time">[35:48]</span>I have a question.</p>
    <p class="cue"><span class="time">[35:49]</span>In the video, it seems like it has hypermobility</p>
    <p class="cue"><span class="time">[35:52]</span>on unrelated things all the time,</p>
    <p class="cue"><span class="time">[35:54]</span>like [INAUDIBLE] of the models.</p>
    <p class="cue"><span class="time">[35:56]</span>Yeah.</p>
    <p class="cue"><span class="time">[35:57]</span>So you were saying in the video, it</p>
    <p class="cue"><span class="time">[35:58]</span>seems like the model sometimes is looking</p>
    <p class="cue"><span class="time">[36:00]</span>at the meaningless things.</p>
    <p class="cue"><span class="time">[36:02]</span>Yeah.</p>
    <p class="cue"><span class="time">[36:03]</span>I mean, it&#x27;s not surprising, frankly.</p>
    <p class="cue"><span class="time">[36:04]</span>This is the previous generation of models.</p>
    <p class="cue"><span class="time">[36:07]</span>And on top of that, you&#x27;re looking on a video.</p>
    <p class="cue"><span class="time">[36:10]</span>The model is a classification network.</p>
    <p class="cue"><span class="time">[36:12]</span>So it might look sometimes at things</p>
    <p class="cue"><span class="time">[36:15]</span>that are not even labeled.</p>
    <p class="cue"><span class="time">[36:17]</span>And so it has to find the closest one.</p>
    <p class="cue"><span class="time">[36:19]</span>It might not make sense at all.</p>
    <p class="cue"><span class="time">[36:21]</span>That&#x27;s why you build that type of model</p>
    <p class="cue"><span class="time">[36:23]</span>to visualize and understand the network</p>
    <p class="cue"><span class="time">[36:26]</span>is actually not working that well.</p>
    <p class="cue"><span class="time">[36:31]</span>But maybe on the main objects that you actually want</p>
    <p class="cue"><span class="time">[36:33]</span>for your task, let&#x27;s say the zoo wants to do very well with cats</p>
    <p class="cue"><span class="time">[36:36]</span>and dogs, you can verify that when a cat is moving, even</p>
    <p class="cue"><span class="time">[36:38]</span>at fast speed, the model is quickly looking at it.</p>
    <p class="cue"><span class="time">[36:44]</span>Super.</p>
    <p class="cue"><span class="time">[36:45]</span>Let&#x27;s do a couple more methods because it&#x27;s</p>
    <p class="cue"><span class="time">[36:47]</span>going to build our intuition for frontier models.</p>
    <p class="cue"><span class="time">[36:52]</span>So now the zoo trusts you.</p>
    <p class="cue"><span class="time">[36:55]</span>It trusts that the model correctly locates animals,</p>
    <p class="cue"><span class="time">[36:58]</span>but they get of scared and they wonder if the model understands</p>
    <p class="cue"><span class="time">[37:03]</span>what a dog is.</p>
    <p class="cue"><span class="time">[37:05]</span>Does it understand actually what a dog is,</p>
    <p class="cue"><span class="time">[37:08]</span>or is it just like pattern matching random things?</p>
    <p class="cue"><span class="time">[37:13]</span>How could you take this ConvNet and query what</p>
    <p class="cue"><span class="time">[37:21]</span>the model thinks the dog is?</p>
    <p class="cue"><span class="time">[37:23]</span>How would you do that?</p>
    <p class="cue"><span class="time">[37:27]</span>How could you ask the model, what&#x27;s your best</p>
    <p class="cue"><span class="time">[37:29]</span>representation of a dog?</p>
    <p class="cue"><span class="time">[37:44]</span>You are trying to reverse-engineer or get</p>
    <p class="cue"><span class="time">[37:48]</span>an image that maximizes the probability of dog.</p>
    <p class="cue"><span class="time">[37:55]</span>OK.</p>
    <p class="cue"><span class="time">[37:55]</span>Yeah.</p>
    <p class="cue"><span class="time">[37:56]</span>You did say two things.</p>
    <p class="cue"><span class="time">[37:57]</span>So get an image, so a forged image that maximizes</p>
    <p class="cue"><span class="time">[38:02]</span>the probability of dog.</p>
    <p class="cue"><span class="time">[38:03]</span>Yeah, let&#x27;s do that actually.</p>
    <p class="cue"><span class="time">[38:04]</span>And then on your second point about reverse engineering,</p>
    <p class="cue"><span class="time">[38:10]</span>we&#x27;re going to look at the method there as well.</p>
    <p class="cue"><span class="time">[38:12]</span>But, yeah, I agree you could.</p>
    <p class="cue"><span class="time">[38:14]</span>So how would you concretely do that?</p>
    <p class="cue"><span class="time">[38:16]</span>What would you maximize?</p>
    <p class="cue"><span class="time">[38:19]</span>The softmax</p>
    <p class="cue"><span class="time">[38:21]</span>OK.</p>
    <p class="cue"><span class="time">[38:22]</span>Actually, what we said earlier, but I</p>
    <p class="cue"><span class="time">[38:24]</span>think you came right after that is we would not take the softmax</p>
    <p class="cue"><span class="time">[38:28]</span>output because the softmax output is</p>
    <p class="cue"><span class="time">[38:30]</span>dependent on other classes.</p>
    <p class="cue"><span class="time">[38:32]</span>You divide by the sum of the exponentials of other classes.</p>
    <p class="cue"><span class="time">[38:35]</span>And so you could actually maximize the softmax output</p>
    <p class="cue"><span class="time">[38:38]</span>by not maximizing the class you want</p>
    <p class="cue"><span class="time">[38:40]</span>but by minimizing the other classes, which is</p>
    <p class="cue"><span class="time">[38:43]</span>different than what you want.</p>
    <p class="cue"><span class="time">[38:45]</span>So here&#x27;s what we&#x27;ll do.</p>
    <p class="cue"><span class="time">[38:47]</span>We&#x27;ll define a loss function where</p>
    <p class="cue"><span class="time">[38:48]</span>we take the pre-softmax score of dog,</p>
    <p class="cue"><span class="time">[38:51]</span>so the thing right before the softmax, which</p>
    <p class="cue"><span class="time">[38:53]</span>is only dependent on that specific class.</p>
    <p class="cue"><span class="time">[38:55]</span>And we might also regularize it to make sure it looks natural.</p>
    <p class="cue"><span class="time">[38:59]</span>The reason we want the regularization term</p>
    <p class="cue"><span class="time">[39:01]</span>is because pixels need to be between 0 and 255, roughly.</p>
    <p class="cue"><span class="time">[39:06]</span>And so you don&#x27;t want to run an optimization</p>
    <p class="cue"><span class="time">[39:10]</span>problem where pixels can have values</p>
    <p class="cue"><span class="time">[39:12]</span>that go all over the place.</p>
    <p class="cue"><span class="time">[39:14]</span>It&#x27;s just not going to look good to the human eye.</p>
    <p class="cue"><span class="time">[39:18]</span>And so we&#x27;re going to do that.</p>
    <p class="cue"><span class="time">[39:20]</span>We&#x27;re going to run a gradient ascent algorithm.</p>
    <p class="cue"><span class="time">[39:22]</span>So similar to what we&#x27;ve seen in some of the previous classes</p>
    <p class="cue"><span class="time">[39:26]</span>where we&#x27;re going to update the pixels of an input</p>
    <p class="cue"><span class="time">[39:29]</span>image, a completely random input image</p>
    <p class="cue"><span class="time">[39:32]</span>until we can maximize the loss function we defined.</p>
    <p class="cue"><span class="time">[39:36]</span>So we forward propagated the random image,</p>
    <p class="cue"><span class="time">[39:38]</span>we compute the objective, we back propagate all the way</p>
    <p class="cue"><span class="time">[39:41]</span>back to the pixels, and then we update the pixels</p>
    <p class="cue"><span class="time">[39:44]</span>to maximize that objective.</p>
    <p class="cue"><span class="time">[39:46]</span>And we do that many times until we end up with something</p>
    <p class="cue"><span class="time">[39:50]</span>that might look like this.</p>
    <p class="cue"><span class="time">[39:52]</span>So let&#x27;s say we take the score of a Dalmatian.</p>
    <p class="cue"><span class="time">[39:58]</span>Here researchers, and this is work from Jason Yosinski,</p>
    <p class="cue"><span class="time">[40:06]</span>shows that you can start seeing the model.</p>
    <p class="cue"><span class="time">[40:11]</span>If you ask the model what is a Dalmatian,</p>
    <p class="cue"><span class="time">[40:13]</span>it will tell you it&#x27;s something with black dots</p>
    <p class="cue"><span class="time">[40:16]</span>on a white background, roughly.</p>
    <p class="cue"><span class="time">[40:20]</span>So actually it might not understand fully</p>
    <p class="cue"><span class="time">[40:22]</span>what the dog is, but that&#x27;s what it thinks it is.</p>
    <p class="cue"><span class="time">[40:26]</span>So we just unpacked it a little bit and query that.</p>
    <p class="cue"><span class="time">[40:29]</span>Another interesting one is if you look at the goose,</p>
    <p class="cue"><span class="time">[40:34]</span>so here, the top left label goose for the model</p>
    <p class="cue"><span class="time">[40:41]</span>is many of them.</p>
    <p class="cue"><span class="time">[40:44]</span>What does that mean?</p>
    <p class="cue"><span class="time">[40:44]</span>It means probably the model has seen a bunch of geese</p>
    <p class="cue"><span class="time">[40:48]</span>all the time together and has rarely seen a single one.</p>
    <p class="cue"><span class="time">[40:52]</span>And maybe the labeled data was labeling that as goose</p>
    <p class="cue"><span class="time">[40:56]</span>when it was geese.</p>
    <p class="cue"><span class="time">[40:57]</span>And so the model actually doesn&#x27;t understand</p>
    <p class="cue"><span class="time">[40:59]</span>that it&#x27;s a single one.</p>
    <p class="cue"><span class="time">[41:00]</span>It thinks that all of them are the label.</p>
    <p class="cue"><span class="time">[41:03]</span>Does that make sense?</p>
    <p class="cue"><span class="time">[41:06]</span>OK.</p>
    <p class="cue"><span class="time">[41:08]</span>Super.</p>
    <p class="cue"><span class="time">[41:08]</span>So that&#x27;s called class model visualization.</p>
    <p class="cue"><span class="time">[41:10]</span>You can actually-- oh, sorry, I wasn&#x27;t showing</p>
    <p class="cue"><span class="time">[41:13]</span>what I was talking about.</p>
    <p class="cue"><span class="time">[41:14]</span>No, I was showing.</p>
    <p class="cue"><span class="time">[41:18]</span>The way to improve those visualization</p>
    <p class="cue"><span class="time">[41:20]</span>is just to change some of the regularization methods.</p>
    <p class="cue"><span class="time">[41:22]</span>So the researchers have shown that you can actually</p>
    <p class="cue"><span class="time">[41:26]</span>add more color by regularizing better so it looks better</p>
    <p class="cue"><span class="time">[41:29]</span>to the human eye.</p>
    <p class="cue"><span class="time">[41:30]</span>And then it becomes easier to query</p>
    <p class="cue"><span class="time">[41:32]</span>the model for a variety of classes just</p>
    <p class="cue"><span class="time">[41:34]</span>to make sure that it understood those classes.</p>
    <p class="cue"><span class="time">[41:37]</span>And so same with flamingos, actually, the label flamingo</p>
    <p class="cue"><span class="time">[41:42]</span>to the model feels like many flamingos,</p>
    <p class="cue"><span class="time">[41:46]</span>just something you can observe.</p>
    <p class="cue"><span class="time">[41:51]</span>Any questions on class model visualization?</p>
    <p class="cue"><span class="time">[41:55]</span>Nothing&#x27;s super new, just another tool in your kit.</p>
    <p class="cue"><span class="time">[42:01]</span>It turns out you can apply the same type of method</p>
    <p class="cue"><span class="time">[42:05]</span>as class model visualization.</p>
    <p class="cue"><span class="time">[42:08]</span>But instead of doing it at the class level,</p>
    <p class="cue"><span class="time">[42:11]</span>you do it in an intermediary activation.</p>
    <p class="cue"><span class="time">[42:15]</span>So you could actually do the same exercise,</p>
    <p class="cue"><span class="time">[42:17]</span>sort of what you were saying earlier</p>
    <p class="cue"><span class="time">[42:19]</span>with the masking of the later layer</p>
    <p class="cue"><span class="time">[42:21]</span>and just looking inside the network.</p>
    <p class="cue"><span class="time">[42:23]</span>You could pick an activation in the network,</p>
    <p class="cue"><span class="time">[42:26]</span>create an objective function with a regularization</p>
    <p class="cue"><span class="time">[42:29]</span>and say, hey, show me the input picture</p>
    <p class="cue"><span class="time">[42:32]</span>that maximizes this activation.</p>
    <p class="cue"><span class="time">[42:35]</span>And that should tell you what is the input that maximizes</p>
    <p class="cue"><span class="time">[42:41]</span>activation the most.</p>
    <p class="cue"><span class="time">[42:47]</span>So that&#x27;s class model visualization</p>
    <p class="cue"><span class="time">[42:50]</span>which can also be applied with gradient ascent</p>
    <p class="cue"><span class="time">[42:53]</span>anywhere inside the network at any neuron.</p>
    <p class="cue"><span class="time">[42:56]</span>And that already gives you some of a method</p>
    <p class="cue"><span class="time">[42:59]</span>to look at the neuron level and say, hey,</p>
    <p class="cue"><span class="time">[43:01]</span>what&#x27;s the input that maximizes the fake input</p>
    <p class="cue"><span class="time">[43:04]</span>that theoretically you could generate</p>
    <p class="cue"><span class="time">[43:05]</span>that maximizes that activation.</p>
    <p class="cue"><span class="time">[43:10]</span>The next method is actually the most commonly used today</p>
    <p class="cue"><span class="time">[43:15]</span>because it&#x27;s so simple and intuitive.</p>
    <p class="cue"><span class="time">[43:18]</span>It&#x27;s a data set search.</p>
    <p class="cue"><span class="time">[43:20]</span>So what you could actually do is to pick a filter.</p>
    <p class="cue"><span class="time">[43:24]</span>You just pick one filter, you pick its feature map among--</p>
    <p class="cue"><span class="time">[43:29]</span>I guess, you pick one feature map</p>
    <p class="cue"><span class="time">[43:32]</span>at some point in the network, such as at after this max</p>
    <p class="cue"><span class="time">[43:36]</span>pooling layer.</p>
    <p class="cue"><span class="time">[43:38]</span>And so let&#x27;s say you have 256 filters in that convolution</p>
    <p class="cue"><span class="time">[43:42]</span>layer.</p>
    <p class="cue"><span class="time">[43:43]</span>So you have 256 feature maps of size 5 by 5.</p>
    <p class="cue"><span class="time">[43:49]</span>And you find across all your data,</p>
    <p class="cue"><span class="time">[43:54]</span>your validation set the top five image</p>
    <p class="cue"><span class="time">[43:58]</span>that maximize this feature map.</p>
    <p class="cue"><span class="time">[44:03]</span>So you just track the activations in that feature map.</p>
    <p class="cue"><span class="time">[44:06]</span>You find the highest activation across all your data,</p>
    <p class="cue"><span class="time">[44:10]</span>and you find the top five images.</p>
    <p class="cue"><span class="time">[44:13]</span>And you can do that.</p>
    <p class="cue"><span class="time">[44:14]</span>Again, you would say, this seems that the filter that produced</p>
    <p class="cue"><span class="time">[44:19]</span>that feature map has learned to detect shirts,</p>
    <p class="cue"><span class="time">[44:22]</span>because if you find the top five images that activated</p>
    <p class="cue"><span class="time">[44:25]</span>that feature map the most, that filter the most,</p>
    <p class="cue"><span class="time">[44:28]</span>it&#x27;s all images of shirts.</p>
    <p class="cue"><span class="time">[44:32]</span>If you were to find something like this, you would say.</p>
    <p class="cue"><span class="time">[44:35]</span>It seems that the filter has learned to detect edges.</p>
    <p class="cue"><span class="time">[44:38]</span>And you could do that across every feature map</p>
    <p class="cue"><span class="time">[44:41]</span>to interpret your filters.</p>
    <p class="cue"><span class="time">[44:48]</span>Simple data set search that can allow</p>
    <p class="cue"><span class="time">[44:53]</span>you to interpret if a filter is reacting to something</p>
    <p class="cue"><span class="time">[44:58]</span>meaningful.</p>
    <p class="cue"><span class="time">[45:01]</span>So if you look at these pictures that I</p>
    <p class="cue"><span class="time">[45:03]</span>printed at the bottom of the slide, they&#x27;re all cropped.</p>
    <p class="cue"><span class="time">[45:07]</span>So why are they cropped?</p>
    <p class="cue"><span class="time">[45:12]</span>They don&#x27;t look like images from the data set that the image is</p>
    <p class="cue"><span class="time">[45:15]</span>probably bigger than that.</p>
    <p class="cue"><span class="time">[45:25]</span>The body.</p>
    <p class="cue"><span class="time">[45:28]</span>The what?</p>
    <p class="cue"><span class="time">[45:30]</span>The body.</p>
    <p class="cue"><span class="time">[45:31]</span>Like [INAUDIBLE] on the bottom, [INAUDIBLE]</p>
    <p class="cue"><span class="time">[45:39]</span>So we took the input image.</p>
    <p class="cue"><span class="time">[45:41]</span>We send it through the conv ReLU blocks.</p>
    <p class="cue"><span class="time">[45:45]</span>And then we pick a feature map in the fifth block,</p>
    <p class="cue"><span class="time">[45:49]</span>let&#x27;s say, what is this feature map looking at?</p>
    <p class="cue"><span class="time">[45:52]</span>Is it looking at the whole image or no?</p>
    <p class="cue"><span class="time">[45:55]</span>Sorry.</p>
    <p class="cue"><span class="time">[45:57]</span>So we pick a feature map.</p>
    <p class="cue"><span class="time">[45:58]</span>And in that feature map, we find the activation</p>
    <p class="cue"><span class="time">[46:01]</span>that&#x27;s the highest.</p>
    <p class="cue"><span class="time">[46:02]</span>So let&#x27;s say the activation is the row number</p>
    <p class="cue"><span class="time">[46:05]</span>5, column number 3, if you pick that activation</p>
    <p class="cue"><span class="time">[46:10]</span>does it have access to the entire input image or not?</p>
    <p class="cue"><span class="time">[46:15]</span>Not necessarily.</p>
    <p class="cue"><span class="time">[46:16]</span>But it is more focused on what is actually--</p>
    <p class="cue"><span class="time">[46:20]</span>it&#x27;s closer to what it&#x27;s actually predicting.</p>
    <p class="cue"><span class="time">[46:23]</span>So you&#x27;re closer to actually getting to the right answer.</p>
    <p class="cue"><span class="time">[46:28]</span>So that&#x27;s why you&#x27;re basically seeing where the shape</p>
    <p class="cue"><span class="time">[46:33]</span>itself is.</p>
    <p class="cue"><span class="time">[46:34]</span>Not necessarily.</p>
    <p class="cue"><span class="time">[46:35]</span>Yeah.</p>
    <p class="cue"><span class="time">[46:36]</span>So you don&#x27;t necessarily have access to the entire image.</p>
    <p class="cue"><span class="time">[46:38]</span>The best way to visualize it is that the first layer.</p>
    <p class="cue"><span class="time">[46:41]</span>Let&#x27;s say on the first layer, you take the input image,</p>
    <p class="cue"><span class="time">[46:43]</span>you take a filter, and you run it through.</p>
    <p class="cue"><span class="time">[46:47]</span>Well, that activation in the feature map of the first layer</p>
    <p class="cue"><span class="time">[46:50]</span>is only going to see what the filter sees.</p>
    <p class="cue"><span class="time">[46:54]</span>When you go deeper in the network,</p>
    <p class="cue"><span class="time">[46:55]</span>do you see more or less on average of the image?</p>
    <p class="cue"><span class="time">[47:01]</span>A single activation, does it have access</p>
    <p class="cue"><span class="time">[47:03]</span>to more or less parts of the image?</p>
    <p class="cue"><span class="time">[47:12]</span>You&#x27;re saying more?</p>
    <p class="cue"><span class="time">[47:16]</span>Yeah, it&#x27;s more.</p>
    <p class="cue"><span class="time">[47:17]</span>Let&#x27;s look at it.</p>
    <p class="cue"><span class="time">[47:18]</span>So here&#x27;s a picture 64 by 64 by 3, let&#x27;s say.</p>
    <p class="cue"><span class="time">[47:22]</span>We have a conv network, five layers.</p>
    <p class="cue"><span class="time">[47:26]</span>And after five layers, the last conv has 13 filters</p>
    <p class="cue"><span class="time">[47:31]</span>and leads to a 13 by 13-- sorry.</p>
    <p class="cue"><span class="time">[47:33]</span>It has 256 filters.</p>
    <p class="cue"><span class="time">[47:35]</span>That leads to a 13 by 13 feature maps.</p>
    <p class="cue"><span class="time">[47:41]</span>If I look at this feature map, let&#x27;s</p>
    <p class="cue"><span class="time">[47:44]</span>say that&#x27;s the most activated, I trace back to the input space.</p>
    <p class="cue"><span class="time">[47:50]</span>It will have access to this part of the image, let&#x27;s say.</p>
    <p class="cue"><span class="time">[47:54]</span>Now if there was another conv ReLU block,</p>
    <p class="cue"><span class="time">[47:58]</span>and I was looking at a feature map,</p>
    <p class="cue"><span class="time">[48:00]</span>it would have even more abstraction of multiple portions</p>
    <p class="cue"><span class="time">[48:03]</span>of these squares.</p>
    <p class="cue"><span class="time">[48:04]</span>So it would actually see slightly more</p>
    <p class="cue"><span class="time">[48:06]</span>from the input image.</p>
    <p class="cue"><span class="time">[48:07]</span>Does that make sense?</p>
    <p class="cue"><span class="time">[48:10]</span>So that&#x27;s how you would think about it.</p>
    <p class="cue"><span class="time">[48:13]</span>And it makes sense because at the end of it,</p>
    <p class="cue"><span class="time">[48:16]</span>the last output has access to the entire image</p>
    <p class="cue"><span class="time">[48:19]</span>because all these things are adding up to the prediction.</p>
    <p class="cue"><span class="time">[48:27]</span>So the deeper the activation, the more it sees from the image.</p>
    <p class="cue"><span class="time">[48:31]</span>And that&#x27;s why the images were cropped.</p>
    <p class="cue"><span class="time">[48:33]</span>They were just cropped based on tracing back</p>
    <p class="cue"><span class="time">[48:35]</span>what that activation was looking at in the input image, which</p>
    <p class="cue"><span class="time">[48:38]</span>you can do very simply computationally.</p>
    <p class="cue"><span class="time">[48:44]</span>So now we&#x27;re going to look at our last method</p>
    <p class="cue"><span class="time">[48:47]</span>for convs, which has to do with reverse engineering conv.</p>
    <p class="cue"><span class="time">[48:51]</span>And then we&#x27;ll move to the frontier models.</p>
    <p class="cue"><span class="time">[48:55]</span>So remember this slide from when we introduced Generative</p>
    <p class="cue"><span class="time">[49:01]</span>Adversarial networks, GANs.</p>
    <p class="cue"><span class="time">[49:04]</span>I didn&#x27;t talk too much about the generator architecture.</p>
    <p class="cue"><span class="time">[49:08]</span>I just said it was a neural network.</p>
    <p class="cue"><span class="time">[49:10]</span>But I did mention that something&#x27;s</p>
    <p class="cue"><span class="time">[49:12]</span>weird about that network, which is that the input is way smaller</p>
    <p class="cue"><span class="time">[49:16]</span>than its output.</p>
    <p class="cue"><span class="time">[49:18]</span>The input is a vector z.</p>
    <p class="cue"><span class="time">[49:19]</span>The output is an image of more dimensions.</p>
    <p class="cue"><span class="time">[49:24]</span>It is very common that such a network needs to upsample</p>
    <p class="cue"><span class="time">[49:27]</span>and thus would use deconvolution.</p>
    <p class="cue"><span class="time">[49:31]</span>Sometimes in the literature, you&#x27;re</p>
    <p class="cue"><span class="time">[49:32]</span>going to see dimensions of deconvolutions</p>
    <p class="cue"><span class="time">[49:35]</span>as an upsampling network where the input is</p>
    <p class="cue"><span class="time">[49:40]</span>smaller than the output.</p>
    <p class="cue"><span class="time">[49:43]</span>Sometimes those are called transposed convolutions,</p>
    <p class="cue"><span class="time">[49:45]</span>but we&#x27;re going to talk about why.</p>
    <p class="cue"><span class="time">[49:49]</span>Another example where you might run into upsampling</p>
    <p class="cue"><span class="time">[49:52]</span>is when you have an encoder/decoder type networks</p>
    <p class="cue"><span class="time">[49:55]</span>such as for segmentation.</p>
    <p class="cue"><span class="time">[49:57]</span>So let&#x27;s say you&#x27;re given an image of a cellular set of cells</p>
    <p class="cue"><span class="time">[50:02]</span>like this, and then you want to label segments</p>
    <p class="cue"><span class="time">[50:06]</span>the pixels that belong to a cell just</p>
    <p class="cue"><span class="time">[50:07]</span>to find the different cells.</p>
    <p class="cue"><span class="time">[50:09]</span>Typically, you would use a set of convolutions that reduces</p>
    <p class="cue"><span class="time">[50:13]</span>the volume in height and width.</p>
    <p class="cue"><span class="time">[50:16]</span>And then you&#x27;ll get information encoded in a dense format</p>
    <p class="cue"><span class="time">[50:21]</span>that you will then upsample because your output should</p>
    <p class="cue"><span class="time">[50:24]</span>be of the size of the input minus the number of channels.</p>
    <p class="cue"><span class="time">[50:27]</span>But at least every pixel should have its own class.</p>
    <p class="cue"><span class="time">[50:32]</span>And so typically that would be a set of convolutions</p>
    <p class="cue"><span class="time">[50:35]</span>followed by deconvolutions.</p>
    <p class="cue"><span class="time">[50:38]</span>So you downsample, you upsample.</p>
    <p class="cue"><span class="time">[50:43]</span>Why am I talking about deconvolutions?</p>
    <p class="cue"><span class="time">[50:45]</span>Because we&#x27;re going to try to reverse-engineer conv networks</p>
    <p class="cue"><span class="time">[50:51]</span>by adding a deconvolutional module that</p>
    <p class="cue"><span class="time">[50:56]</span>will take a specific activation and will reverse-engineer</p>
    <p class="cue"><span class="time">[51:00]</span>the trace to verify what was the reason this activation was high.</p>
    <p class="cue"><span class="time">[51:07]</span>This idea is key not only for convs</p>
    <p class="cue"><span class="time">[51:10]</span>but for any network you&#x27;ll think about in the future</p>
    <p class="cue"><span class="time">[51:13]</span>when you work on it if you want to actually reverse-engineer</p>
    <p class="cue"><span class="time">[51:17]</span>the reason a specific neuron has been active.</p>
    <p class="cue"><span class="time">[51:20]</span>So let&#x27;s take the example of a 1D convolution.</p>
    <p class="cue"><span class="time">[51:24]</span>This is the most basic example just</p>
    <p class="cue"><span class="time">[51:28]</span>for the sake of understanding the math.</p>
    <p class="cue"><span class="time">[51:31]</span>And I give you an input x, which has</p>
    <p class="cue"><span class="time">[51:36]</span>some padding with two zeros at the top,</p>
    <p class="cue"><span class="time">[51:38]</span>two zeros at the bottom, and then x1 through x8 values.</p>
    <p class="cue"><span class="time">[51:43]</span>And I send that input to a 1D convolution,</p>
    <p class="cue"><span class="time">[51:46]</span>which has one single filter of size 4 with a stride of two.</p>
    <p class="cue"><span class="time">[51:52]</span>What&#x27;s the size of my output y?</p>
    <p class="cue"><span class="time">[52:01]</span>Remember the formula.</p>
    <p class="cue"><span class="time">[52:08]</span>What?</p>
    <p class="cue"><span class="time">[52:09]</span>Five.</p>
    <p class="cue"><span class="time">[52:10]</span>Correct.</p>
    <p class="cue"><span class="time">[52:11]</span>Yes.</p>
    <p class="cue"><span class="time">[52:12]</span>I assume you did this.</p>
    <p class="cue"><span class="time">[52:16]</span>So you took an x, you applied the formula and you floored it.</p>
    <p class="cue"><span class="time">[52:27]</span>You didn&#x27;t forget to add 1.</p>
    <p class="cue"><span class="time">[52:30]</span>And then you ended up with 5.</p>
    <p class="cue"><span class="time">[52:32]</span>Yeah.</p>
    <p class="cue"><span class="time">[52:33]</span>Correct.</p>
    <p class="cue"><span class="time">[52:37]</span>Super.</p>
    <p class="cue"><span class="time">[52:39]</span>So we have our output of 5.</p>
    <p class="cue"><span class="time">[52:43]</span>And let&#x27;s say we define our filter size for w1, w2, w3, w4.</p>
    <p class="cue"><span class="time">[52:48]</span>It&#x27;s actually easy to see that the conv1d can be written</p>
    <p class="cue"><span class="time">[52:53]</span>as a system of equations where y1</p>
    <p class="cue"><span class="time">[52:57]</span>equals w1 times 0 plus w2 times 0, because of the padding,</p>
    <p class="cue"><span class="time">[53:02]</span>plus w3 times x1 plus w4 times x2.</p>
    <p class="cue"><span class="time">[53:08]</span>You&#x27;re just overlaying the filter on top of the first four</p>
    <p class="cue"><span class="time">[53:15]</span>indices of the inputs, and you&#x27;re doing a dot product.</p>
    <p class="cue"><span class="time">[53:20]</span>Same thing with the second one, third one,</p>
    <p class="cue"><span class="time">[53:22]</span>all the way to the fifth one.</p>
    <p class="cue"><span class="time">[53:24]</span>And that&#x27;s your system of equations</p>
    <p class="cue"><span class="time">[53:26]</span>that describes this conv1d.</p>
    <p class="cue"><span class="time">[53:30]</span>Now, because it&#x27;s a system of equations,</p>
    <p class="cue"><span class="time">[53:33]</span>you could actually write it as a matrix multiplication.</p>
    <p class="cue"><span class="time">[53:37]</span>So you could say the conv1d is literally just a weight matrix</p>
    <p class="cue"><span class="time">[53:42]</span>that we multiply by the input.</p>
    <p class="cue"><span class="time">[53:44]</span>So the inputs and the output sizes we know, 5, 1 and 12, 1.</p>
    <p class="cue"><span class="time">[53:50]</span>So the weight matrix is necessarily</p>
    <p class="cue"><span class="time">[53:53]</span>a 5 by 12 weight matrix.</p>
    <p class="cue"><span class="time">[53:58]</span>So we just rewrote the conv1d as a single weight matrix</p>
    <p class="cue"><span class="time">[54:04]</span>that you multiply by the input, you get the output.</p>
    <p class="cue"><span class="time">[54:08]</span>If you were to draw this matrix, this is what it would look like.</p>
    <p class="cue"><span class="time">[54:13]</span>So it would be a matrix with values</p>
    <p class="cue"><span class="time">[54:16]</span>all along the diagonal and the rest are zeros.</p>
    <p class="cue"><span class="time">[54:27]</span>So that&#x27;s our conclusion.</p>
    <p class="cue"><span class="time">[54:29]</span>Conv1d can be rewritten as a matrix vector multiplication.</p>
    <p class="cue"><span class="time">[54:34]</span>Everybody follows?</p>
    <p class="cue"><span class="time">[54:42]</span>So if you can write it as a matrix multiplication,</p>
    <p class="cue"><span class="time">[54:45]</span>remember we&#x27;re talking about reverse engineering,</p>
    <p class="cue"><span class="time">[54:48]</span>then I could say deconv is possible.</p>
    <p class="cue"><span class="time">[54:53]</span>It&#x27;s possible to reverse-engineer that.</p>
    <p class="cue"><span class="time">[54:56]</span>And in fact, I&#x27;m going to make a very big assumption that</p>
    <p class="cue"><span class="time">[55:00]</span>is not always true.</p>
    <p class="cue"><span class="time">[55:01]</span>Sometimes it&#x27;s true, but for practical reasons,</p>
    <p class="cue"><span class="time">[55:03]</span>we&#x27;re in deep learning.</p>
    <p class="cue"><span class="time">[55:04]</span>It&#x27;s an engineering field.</p>
    <p class="cue"><span class="time">[55:06]</span>We&#x27;re going to assume that W is invertible.</p>
    <p class="cue"><span class="time">[55:10]</span>And so you can find a matrix H that</p>
    <p class="cue"><span class="time">[55:12]</span>is equal to the inverse of W such</p>
    <p class="cue"><span class="time">[55:16]</span>that x equals Hy so that you&#x27;re able to reverse-engineer</p>
    <p class="cue"><span class="time">[55:22]</span>the signal.</p>
    <p class="cue"><span class="time">[55:23]</span>I&#x27;m going to make a second assumption in the sizes I</p>
    <p class="cue"><span class="time">[55:28]</span>printed, which is even bigger, is that W is not</p>
    <p class="cue"><span class="time">[55:31]</span>only invertible, it&#x27;s also orthogonal,</p>
    <p class="cue"><span class="time">[55:34]</span>meaning that its inverse is its transpose.</p>
    <p class="cue"><span class="time">[55:40]</span>It happens that it&#x27;s sometimes true.</p>
    <p class="cue"><span class="time">[55:43]</span>And in fact, if you think about an edge detector.</p>
    <p class="cue"><span class="time">[55:46]</span>So let&#x27;s say our filter is minus 1, 0, 0, 0, 1.</p>
    <p class="cue"><span class="time">[55:50]</span>It&#x27;s an edge detector.</p>
    <p class="cue"><span class="time">[55:52]</span>So I have one too many zeros.</p>
    <p class="cue"><span class="time">[55:54]</span>But it&#x27;s an edge detector.</p>
    <p class="cue"><span class="time">[55:56]</span>And it&#x27;s actually invertible, and its inverse</p>
    <p class="cue"><span class="time">[56:02]</span>is its transpose.</p>
    <p class="cue"><span class="time">[56:06]</span>And so that simplifies our reverse engineering</p>
    <p class="cue"><span class="time">[56:09]</span>because we have a conv1d.</p>
    <p class="cue"><span class="time">[56:12]</span>And we know that we can write it as a matrix vector</p>
    <p class="cue"><span class="time">[56:15]</span>multiplication.</p>
    <p class="cue"><span class="time">[56:16]</span>And we can transpose that matrix to reverse it.</p>
    <p class="cue"><span class="time">[56:20]</span>And maybe it&#x27;s not always true, but it&#x27;s</p>
    <p class="cue"><span class="time">[56:23]</span>true enough for it to work in deep learning.</p>
    <p class="cue"><span class="time">[56:26]</span>Pretty much.</p>
    <p class="cue"><span class="time">[56:27]</span>You&#x27;re going to do that so many times.</p>
    <p class="cue"><span class="time">[56:31]</span>That&#x27;s why in the literature, oftentimes deconvolutions are</p>
    <p class="cue"><span class="time">[56:35]</span>called transpose convolutions.</p>
    <p class="cue"><span class="time">[56:39]</span>I give you the 1D example.</p>
    <p class="cue"><span class="time">[56:41]</span>The 2D example is similar.</p>
    <p class="cue"><span class="time">[56:42]</span>It&#x27;s just more complicated.</p>
    <p class="cue"><span class="time">[56:44]</span>There&#x27;s more math, things mix up, but same idea.</p>
    <p class="cue"><span class="time">[56:50]</span>Now, there is a trick that makes it simpler</p>
    <p class="cue"><span class="time">[56:54]</span>to code the deconvolution.</p>
    <p class="cue"><span class="time">[56:58]</span>And to see that trick, I just drew x equals W transpose y.</p>
    <p class="cue"><span class="time">[57:07]</span>So you have your x, which is a vector of size 12,</p>
    <p class="cue"><span class="time">[57:10]</span>although there&#x27;s two padding at the top or at the bottom.</p>
    <p class="cue"><span class="time">[57:14]</span>And then I transpose the W matrix that I was showing you.</p>
    <p class="cue"><span class="time">[57:19]</span>And then I multiply that by my vector y of size 5.</p>
    <p class="cue"><span class="time">[57:25]</span>This is actually a transpose convolution with stride 2 is</p>
    <p class="cue"><span class="time">[57:31]</span>equivalent to something slightly different,</p>
    <p class="cue"><span class="time">[57:34]</span>which is a sub pixel convolution of stride 1/2.</p>
    <p class="cue"><span class="time">[57:38]</span>It&#x27;s a mathematical trick.</p>
    <p class="cue"><span class="time">[57:41]</span>You can do it at home, but you would</p>
    <p class="cue"><span class="time">[57:44]</span>see that these two operations are equivalent,</p>
    <p class="cue"><span class="time">[57:48]</span>meaning you can actually flip the filter.</p>
    <p class="cue"><span class="time">[57:52]</span>So you see in the left side of the screen,</p>
    <p class="cue"><span class="time">[57:55]</span>the filters are flipped.</p>
    <p class="cue"><span class="time">[57:56]</span>So if you look at the first row of my matrix,</p>
    <p class="cue"><span class="time">[58:00]</span>it&#x27;s not w1 through w4.</p>
    <p class="cue"><span class="time">[58:02]</span>It&#x27;s w4 through w1.</p>
    <p class="cue"><span class="time">[58:05]</span>So I flipped the filter, and I scanned it all the way</p>
    <p class="cue"><span class="time">[58:09]</span>through the diagonal.</p>
    <p class="cue"><span class="time">[58:12]</span>I also used another trick, which is my y vector.</p>
    <p class="cue"><span class="time">[58:15]</span>I inserted zeros rows in between the values.</p>
    <p class="cue"><span class="time">[58:20]</span>It&#x27;s called sub-pixel.</p>
    <p class="cue"><span class="time">[58:22]</span>So I inserted zeros, and I also added some padding.</p>
    <p class="cue"><span class="time">[58:26]</span>So a couple of tricks but no need to remember it by heart.</p>
    <p class="cue"><span class="time">[58:31]</span>If there&#x27;s anything you can remember,</p>
    <p class="cue"><span class="time">[58:33]</span>it&#x27;s that implementing a deconvolution</p>
    <p class="cue"><span class="time">[58:36]</span>in the sub-pixel version I was describing</p>
    <p class="cue"><span class="time">[58:38]</span>is similar to a convolution.</p>
    <p class="cue"><span class="time">[58:40]</span>But what you do is you create a sub-pixel version of the input</p>
    <p class="cue"><span class="time">[58:44]</span>by adding zeros in between the values and padding it.</p>
    <p class="cue"><span class="time">[58:48]</span>You flip the filters, and you divide the stride by 2.</p>
    <p class="cue"><span class="time">[58:54]</span>And that&#x27;s what a deconvolution is.</p>
    <p class="cue"><span class="time">[58:56]</span>So if you have a convolutional neural network</p>
    <p class="cue"><span class="time">[59:00]</span>and you want to reverse-engineer it, you take the filters.</p>
    <p class="cue"><span class="time">[59:04]</span>You flip them.</p>
    <p class="cue"><span class="time">[59:06]</span>You create a sub-pixel version of the input.</p>
    <p class="cue"><span class="time">[59:10]</span>You divide the stride by 2, and you run the process.</p>
    <p class="cue"><span class="time">[59:13]</span>You will have reversed that convolution.</p>
    <p class="cue"><span class="time">[59:16]</span>The reason we&#x27;re doing that is because we&#x27;re just</p>
    <p class="cue"><span class="time">[59:20]</span>rewriting the convolution as another convolution.</p>
    <p class="cue"><span class="time">[59:22]</span>But the hyperparameters are different.</p>
    <p class="cue"><span class="time">[59:24]</span>But it&#x27;s easy to code.</p>
    <p class="cue"><span class="time">[59:27]</span>You&#x27;re just reusing the same code pretty much.</p>
    <p class="cue"><span class="time">[59:32]</span>Anyway, let&#x27;s get back to our example.</p>
    <p class="cue"><span class="time">[59:35]</span>Here, we have an image of a dog.</p>
    <p class="cue"><span class="time">[59:39]</span>We run it through ConvNet.</p>
    <p class="cue"><span class="time">[59:44]</span>And we pick at some point in that ConvNet a feature map.</p>
    <p class="cue"><span class="time">[59:49]</span>We pick one feature map only among the 256 possible feature</p>
    <p class="cue"><span class="time">[59:55]</span>maps right here.</p>
    <p class="cue"><span class="time">[59:56]</span>And we&#x27;re going to look at the max activation of that feature</p>
    <p class="cue"><span class="time">[60:00]</span>map.</p>
    <p class="cue"><span class="time">[60:01]</span>So we find the max.</p>
    <p class="cue"><span class="time">[60:02]</span>Let&#x27;s say it&#x27;s this one.</p>
    <p class="cue"><span class="time">[60:04]</span>So row 2, column 3 is the maximum number</p>
    <p class="cue"><span class="time">[60:07]</span>of that feature map.</p>
    <p class="cue"><span class="time">[60:09]</span>What does it mean?</p>
    <p class="cue"><span class="time">[60:11]</span>It means the filter that led to that feature map</p>
    <p class="cue"><span class="time">[60:14]</span>when it looked at its input, it was maximal in that location.</p>
    <p class="cue"><span class="time">[60:19]</span>It maximally activated in that location.</p>
    <p class="cue"><span class="time">[60:22]</span>We zero out every other entries of this matrix.</p>
    <p class="cue"><span class="time">[60:33]</span>And then we reverse the network.</p>
    <p class="cue"><span class="time">[60:35]</span>So we max-pooled; we unpooled.</p>
    <p class="cue"><span class="time">[60:38]</span>We ReLU; we do the reverse.</p>
    <p class="cue"><span class="time">[60:40]</span>We do a deconv instead of the conv,</p>
    <p class="cue"><span class="time">[60:41]</span>which is a transpose convolution sub-pixel version,</p>
    <p class="cue"><span class="time">[60:45]</span>flip the filter, divide the stride by 2.</p>
    <p class="cue"><span class="time">[60:49]</span>And we do that how many times?</p>
    <p class="cue"><span class="time">[60:50]</span>Three times because we had three blocks.</p>
    <p class="cue"><span class="time">[60:53]</span>And then we should be able to reconstruct what this activation</p>
    <p class="cue"><span class="time">[60:59]</span>was maximally activated for.</p>
    <p class="cue"><span class="time">[61:01]</span>And we get a cropped version as we learned,</p>
    <p class="cue"><span class="time">[61:03]</span>the cropped part of the image that this activation was</p>
    <p class="cue"><span class="time">[61:06]</span>looking at, and exactly the pixels that maximized its value.</p>
    <p class="cue"><span class="time">[61:13]</span>Does that make sense?</p>
    <p class="cue"><span class="time">[61:15]</span>It&#x27;s pretty complex, but it&#x27;s important to know these methods</p>
    <p class="cue"><span class="time">[61:19]</span>because you might run into something similar in the future</p>
    <p class="cue"><span class="time">[61:22]</span>or be asked to interpret certain feature maps, certain activation</p>
    <p class="cue"><span class="time">[61:27]</span>maps, et cetera.</p>
    <p class="cue"><span class="time">[61:29]</span>So some additional details that we&#x27;ll cover is what is unpooled</p>
    <p class="cue"><span class="time">[61:35]</span>and why do we do some ReLU in there.</p>
    <p class="cue"><span class="time">[61:38]</span>So very simply, let&#x27;s say I take the maxpooling layer.</p>
    <p class="cue"><span class="time">[61:43]</span>I maxpool this filter size 2 by 2 stride of 2.</p>
    <p class="cue"><span class="time">[61:51]</span>If you wanted to unpool this, how would you do it?</p>
    <p class="cue"><span class="time">[62:03]</span>Our pooling layers, maxpooling layers invertible?</p>
    <p class="cue"><span class="time">[62:10]</span>No?</p>
    <p class="cue"><span class="time">[62:11]</span>Why?</p>
    <p class="cue"><span class="time">[62:21]</span>Yeah.</p>
    <p class="cue"><span class="time">[62:21]</span>There&#x27;s no way of knowing where the layer came from.</p>
    <p class="cue"><span class="time">[62:24]</span>Yeah, exactly.</p>
    <p class="cue"><span class="time">[62:25]</span>It&#x27;s not invertible, because if you pick the 6 here</p>
    <p class="cue"><span class="time">[62:29]</span>on the top left, you can tell that the 6 was</p>
    <p class="cue"><span class="time">[62:32]</span>in one of these four, but you don&#x27;t where it was.</p>
    <p class="cue"><span class="time">[62:35]</span>So you can&#x27;t invert.</p>
    <p class="cue"><span class="time">[62:36]</span>And it&#x27;s very important to where it was.</p>
    <p class="cue"><span class="time">[62:41]</span>So it&#x27;s not invertible, but you could actually</p>
    <p class="cue"><span class="time">[62:43]</span>use a trick to make it invertible,</p>
    <p class="cue"><span class="time">[62:46]</span>which is passing what we call switches.</p>
    <p class="cue"><span class="time">[62:50]</span>So during the forward propagation,</p>
    <p class="cue"><span class="time">[62:52]</span>you look at all your maxpooling.</p>
    <p class="cue"><span class="time">[62:55]</span>And you remember with the binary matrix, so very lightweight</p>
    <p class="cue"><span class="time">[62:58]</span>matrix, where the pooling happened,</p>
    <p class="cue"><span class="time">[63:00]</span>where the maxpooling happened.</p>
    <p class="cue"><span class="time">[63:02]</span>And then when you&#x27;re doing the unpooling,</p>
    <p class="cue"><span class="time">[63:05]</span>you remember those switches, so you keep them in memory,</p>
    <p class="cue"><span class="time">[63:07]</span>and you pass them back.</p>
    <p class="cue"><span class="time">[63:09]</span>And that should tell you where the value came from.</p>
    <p class="cue"><span class="time">[63:13]</span>So that&#x27;s what we mean by unpooling.</p>
    <p class="cue"><span class="time">[63:16]</span>So I go back to my previous map.</p>
    <p class="cue"><span class="time">[63:18]</span>The only thing I need to change to be able to reverse-engineer</p>
    <p class="cue"><span class="time">[63:21]</span>my network is to pass the switches and the filters,</p>
    <p class="cue"><span class="time">[63:25]</span>by the way, because the deconv is just</p>
    <p class="cue"><span class="time">[63:27]</span>the flipped version of the filter with sub-pixel and stride</p>
    <p class="cue"><span class="time">[63:31]</span>divided by 2.</p>
    <p class="cue"><span class="time">[63:33]</span>And so I do that.</p>
    <p class="cue"><span class="time">[63:35]</span>So you can see you can literally invert your network here</p>
    <p class="cue"><span class="time">[63:38]</span>and trace back from one activation to the input space.</p>
    <p class="cue"><span class="time">[63:43]</span>And then for ReLU is a little odd.</p>
    <p class="cue"><span class="time">[63:44]</span>I&#x27;m not going to spend too much time on it because it&#x27;s</p>
    <p class="cue"><span class="time">[63:46]</span>more empirical than nothing.</p>
    <p class="cue"><span class="time">[63:48]</span>But ReLU forward is essentially zeroing out</p>
    <p class="cue"><span class="time">[63:52]</span>every value that is negative during the forward pass.</p>
    <p class="cue"><span class="time">[63:56]</span>Technically, a ReLU backward is impossible</p>
    <p class="cue"><span class="time">[63:59]</span>unless you have also the switches.</p>
    <p class="cue"><span class="time">[64:01]</span>If you have the switches, you could actually, pass linearly</p>
    <p class="cue"><span class="time">[64:07]</span>back whatever was kept because it&#x27;s the identity function.</p>
    <p class="cue"><span class="time">[64:12]</span>But actually that would kill your positive signal</p>
    <p class="cue"><span class="time">[64:16]</span>coming back.</p>
    <p class="cue"><span class="time">[64:17]</span>So instead, you just reuse ReLU.</p>
    <p class="cue"><span class="time">[64:20]</span>Basically, you use ReLU because you</p>
    <p class="cue"><span class="time">[64:23]</span>want to start from the activation that</p>
    <p class="cue"><span class="time">[64:25]</span>is the highest on your feature map</p>
    <p class="cue"><span class="time">[64:27]</span>and to keep passing the positive signal back to the input space.</p>
    <p class="cue"><span class="time">[64:31]</span>Don&#x27;t worry too much about it.</p>
    <p class="cue"><span class="time">[64:32]</span>It&#x27;s just that ReLU is just passed as ReLU</p>
    <p class="cue"><span class="time">[64:35]</span>during the reconstruction process, not as a proper ReLU</p>
    <p class="cue"><span class="time">[64:38]</span>backward.</p>
    <p class="cue"><span class="time">[64:40]</span>OK.</p>
    <p class="cue"><span class="time">[64:41]</span>So here we go.</p>
    <p class="cue"><span class="time">[64:42]</span>We send our dog through the network.</p>
    <p class="cue"><span class="time">[64:46]</span>We look at a specific maxpool output.</p>
    <p class="cue"><span class="time">[64:50]</span>We take the feature map.</p>
    <p class="cue"><span class="time">[64:51]</span>We find the activation that is the highest in that feature map.</p>
    <p class="cue"><span class="time">[64:54]</span>We zero out all the rest.</p>
    <p class="cue"><span class="time">[64:56]</span>We reverse-engineer our network.</p>
    <p class="cue"><span class="time">[64:58]</span>We find the cropped part of this dog</p>
    <p class="cue"><span class="time">[65:00]</span>with the pixels that led to that specific feature map.</p>
    <p class="cue"><span class="time">[65:04]</span>We are interpreting the filter that led that feature map,</p>
    <p class="cue"><span class="time">[65:08]</span>and you can do that anywhere across the network.</p>
    <p class="cue"><span class="time">[65:13]</span>But of course, if you&#x27;re earlier,</p>
    <p class="cue"><span class="time">[65:15]</span>the crop is going to be even smaller.</p>
    <p class="cue"><span class="time">[65:17]</span>If you&#x27;re later, generally bigger.</p>
    <p class="cue"><span class="time">[65:25]</span>So you learned deconvs/transpose convs.</p>
    <p class="cue"><span class="time">[65:30]</span>Now, let&#x27;s look at some practical visualizations</p>
    <p class="cue"><span class="time">[65:34]</span>from Matthew Zeiler and Rob Fergus.</p>
    <p class="cue"><span class="time">[65:37]</span>These are great researchers in the space of visualizations.</p>
    <p class="cue"><span class="time">[65:41]</span>They&#x27;ve been making so much progress.</p>
    <p class="cue"><span class="time">[65:44]</span>So they train the network.</p>
    <p class="cue"><span class="time">[65:47]</span>They looked at results on a validation set of 50,000 images.</p>
    <p class="cue"><span class="time">[65:55]</span>So what you&#x27;re seeing is the first layer and specifically</p>
    <p class="cue"><span class="time">[65:59]</span>the patches.</p>
    <p class="cue"><span class="time">[66:01]</span>What the patches are, they&#x27;re the top 9 strongest activation</p>
    <p class="cue"><span class="time">[66:05]</span>per filter.</p>
    <p class="cue"><span class="time">[66:08]</span>So for each filter in the first layer,</p>
    <p class="cue"><span class="time">[66:10]</span>they look at the top 9 strongest activation.</p>
    <p class="cue"><span class="time">[66:14]</span>And they remember the data points that was leading to that.</p>
    <p class="cue"><span class="time">[66:18]</span>So that&#x27;s the data set search method that we saw together.</p>
    <p class="cue"><span class="time">[66:21]</span>What are the 9 images that led to that maximum feature</p>
    <p class="cue"><span class="time">[66:29]</span>map activating the most?</p>
    <p class="cue"><span class="time">[66:31]</span>Print them.</p>
    <p class="cue"><span class="time">[66:32]</span>Those are the patches for each filter.</p>
    <p class="cue"><span class="time">[66:34]</span>If you do that, you can already interpret some of the filters</p>
    <p class="cue"><span class="time">[66:41]</span>by seeing that, oh, this one reacts</p>
    <p class="cue"><span class="time">[66:43]</span>to edges that are diagonal, or this one</p>
    <p class="cue"><span class="time">[66:45]</span>reacts to edges that are straight, for example.</p>
    <p class="cue"><span class="time">[66:50]</span>On the bottom-right, we actually print the filters raw.</p>
    <p class="cue"><span class="time">[66:53]</span>And of course, because it&#x27;s the first layer,</p>
    <p class="cue"><span class="time">[66:56]</span>it is interpretable.</p>
    <p class="cue"><span class="time">[66:57]</span>So if in fact you have an edge detector,</p>
    <p class="cue"><span class="time">[66:59]</span>you should see when you print that matrix that it</p>
    <p class="cue"><span class="time">[67:01]</span>looks like an edge detector.</p>
    <p class="cue"><span class="time">[67:04]</span>That doesn&#x27;t work for layers beyond one.</p>
    <p class="cue"><span class="time">[67:08]</span>So now let&#x27;s go a little deeper.</p>
    <p class="cue"><span class="time">[67:10]</span>Now, we&#x27;re going layer 2.</p>
    <p class="cue"><span class="time">[67:12]</span>And we&#x27;re looking at the deconvs.</p>
    <p class="cue"><span class="time">[67:14]</span>So what are they doing?</p>
    <p class="cue"><span class="time">[67:20]</span>They&#x27;re essentially looking at the top 1 strongest</p>
    <p class="cue"><span class="time">[67:24]</span>activation per feature in the second layer.</p>
    <p class="cue"><span class="time">[67:27]</span>So the second layer has 256 feature maps.</p>
    <p class="cue"><span class="time">[67:31]</span>They&#x27;re presented here.</p>
    <p class="cue"><span class="time">[67:34]</span>You pick one feature map.</p>
    <p class="cue"><span class="time">[67:36]</span>You look across all these 50,000 validation images.</p>
    <p class="cue"><span class="time">[67:41]</span>You find the maximum feature map.</p>
    <p class="cue"><span class="time">[67:44]</span>You take the specific portion of that feature</p>
    <p class="cue"><span class="time">[67:46]</span>map, the specific entry that&#x27;s maximally activated.</p>
    <p class="cue"><span class="time">[67:50]</span>You zero out the rest.</p>
    <p class="cue"><span class="time">[67:52]</span>You do your deconv.</p>
    <p class="cue"><span class="time">[67:53]</span>You pass the switches, blah, blah, blah,</p>
    <p class="cue"><span class="time">[67:55]</span>and you get the cropped part of the image that represents</p>
    <p class="cue"><span class="time">[67:58]</span>why it was activated.</p>
    <p class="cue"><span class="time">[67:59]</span>And this is printed all over here.</p>
    <p class="cue"><span class="time">[68:01]</span>And you can see you can start interpreting that</p>
    <p class="cue"><span class="time">[68:04]</span>by doing the top 1, or you can do the top 9.</p>
    <p class="cue"><span class="time">[68:07]</span>And if you actually do the top 9,</p>
    <p class="cue"><span class="time">[68:09]</span>you would start seeing that in fact a certain filter have</p>
    <p class="cue"><span class="time">[68:14]</span>very clear purposes.</p>
    <p class="cue"><span class="time">[68:15]</span>Some filters detect circles.</p>
    <p class="cue"><span class="time">[68:17]</span>Some filters detect odd shapes.</p>
    <p class="cue"><span class="time">[68:26]</span>If you keep doing that in layer 3,</p>
    <p class="cue"><span class="time">[68:30]</span>you would start seeing with the deconv method</p>
    <p class="cue"><span class="time">[68:33]</span>that the filters are capturing more complex information.</p>
    <p class="cue"><span class="time">[68:36]</span>Remember, in the first lecture, we did together.</p>
    <p class="cue"><span class="time">[68:38]</span>I said that the deeper you go in the network,</p>
    <p class="cue"><span class="time">[68:40]</span>the more the information adds up,</p>
    <p class="cue"><span class="time">[68:44]</span>and you get more complex features later.</p>
    <p class="cue"><span class="time">[68:46]</span>This is a proof of that, pretty much.</p>
    <p class="cue"><span class="time">[68:51]</span>Now if you go to layer 3, and you can do all of it.</p>
    <p class="cue"><span class="time">[68:55]</span>You can do the top 9 patches where</p>
    <p class="cue"><span class="time">[68:58]</span>if the nine patches look very similar,</p>
    <p class="cue"><span class="time">[69:00]</span>you can probably safely say that this filter was</p>
    <p class="cue"><span class="time">[69:05]</span>responsible for this type of shape or color</p>
    <p class="cue"><span class="time">[69:09]</span>or salient feature.</p>
    <p class="cue"><span class="time">[69:13]</span>And then you can do the deconv as well, essentially.</p>
    <p class="cue"><span class="time">[69:18]</span>Let&#x27;s watch together a very short video</p>
    <p class="cue"><span class="time">[69:20]</span>of Jason Yosinski that shows a little bit of everything we&#x27;ve</p>
    <p class="cue"><span class="time">[69:25]</span>learned together.</p>
    <p class="cue"><span class="time">[69:26]</span>In school buses and zebras, you can</p>
    <p class="cue"><span class="time">[69:29]</span>tell the difference between Maltese terriers and Yorkshire</p>
    <p class="cue"><span class="time">[69:31]</span>terriers.</p>
    <p class="cue"><span class="time">[69:33]</span>We now what it takes to train these neural networks well,</p>
    <p class="cue"><span class="time">[69:35]</span>but we don&#x27;t know so much about how they&#x27;re actually</p>
    <p class="cue"><span class="time">[69:37]</span>computing their final answers.</p>
    <p class="cue"><span class="time">[69:39]</span>We developed this interactive, deep visualization toolbox</p>
    <p class="cue"><span class="time">[69:42]</span>to shine light into these black boxes,</p>
    <p class="cue"><span class="time">[69:44]</span>showing what happens inside of neural nets.</p>
    <p class="cue"><span class="time">[69:47]</span>In the top left corner, we show the input</p>
    <p class="cue"><span class="time">[69:49]</span>to the network, which can be a still image</p>
    <p class="cue"><span class="time">[69:51]</span>or video from a webcam.</p>
    <p class="cue"><span class="time">[69:53]</span>These black squares in the middle</p>
    <p class="cue"><span class="time">[69:54]</span>show the activations on a single layer of a network,</p>
    <p class="cue"><span class="time">[69:57]</span>in this case, the popular deep neural network called AlexNet,</p>
    <p class="cue"><span class="time">[69:59]</span>running in cafe.</p>
    <p class="cue"><span class="time">[70:01]</span>By interacting with the network, we</p>
    <p class="cue"><span class="time">[70:03]</span>can see what some of the neurons are doing.</p>
    <p class="cue"><span class="time">[70:06]</span>For example, on this first layer, a unit in the center</p>
    <p class="cue"><span class="time">[70:09]</span>responds strongly to light to dark edges.</p>
    <p class="cue"><span class="time">[70:13]</span>Its neighbor, one neuron over, responds</p>
    <p class="cue"><span class="time">[70:15]</span>to edges in the opposite direction, dark to light.</p>
    <p class="cue"><span class="time">[70:20]</span>Using optimization, we can synthetically</p>
    <p class="cue"><span class="time">[70:22]</span>produce images that light up each neuron in this layer</p>
    <p class="cue"><span class="time">[70:24]</span>to see what each neuron is looking for.</p>
    <p class="cue"><span class="time">[70:26]</span>We can scroll through every layer--</p>
    <p class="cue"><span class="time">[70:28]</span>We&#x27;ve seen that method class activation.</p>
    <p class="cue"><span class="time">[70:30]</span>Including convolution, pooling, and normalization layers.</p>
    <p class="cue"><span class="time">[70:34]</span>We can switch back and forth between showing</p>
    <p class="cue"><span class="time">[70:36]</span>the actual activations and showing images synthesized</p>
    <p class="cue"><span class="time">[70:39]</span>to produce high activation.</p>
    <p class="cue"><span class="time">[70:41]</span>This is a class model visualization method.</p>
    <p class="cue"><span class="time">[70:44]</span>By the time you get to the fifth convolutional layer,</p>
    <p class="cue"><span class="time">[70:46]</span>the features being computed represent abstract concepts.</p>
    <p class="cue"><span class="time">[70:51]</span>For example, this neuron seems to respond to faces.</p>
    <p class="cue"><span class="time">[70:54]</span>We can further investigate this neuron</p>
    <p class="cue"><span class="time">[70:56]</span>by showing a few different types of information.</p>
    <p class="cue"><span class="time">[70:58]</span>First, we can artificially create optimized images</p>
    <p class="cue"><span class="time">[71:00]</span>using new regularization techniques that</p>
    <p class="cue"><span class="time">[71:02]</span>are described in our paper.</p>
    <p class="cue"><span class="time">[71:04]</span>That&#x27;s the class model visualization.</p>
    <p class="cue"><span class="time">[71:06]</span>Respond to a face and shoulders.</p>
    <p class="cue"><span class="time">[71:08]</span>We can also plot the images from--</p>
    <p class="cue"><span class="time">[71:10]</span>That&#x27;s the data set search.</p>
    <p class="cue"><span class="time">[71:12]</span>As well pixels from those images most responsible for the high</p>
    <p class="cue"><span class="time">[71:15]</span>activations.</p>
    <p class="cue"><span class="time">[71:16]</span>And that&#x27;s the deconv--</p>
    <p class="cue"><span class="time">[71:17]</span>Deconvolution technique.</p>
    <p class="cue"><span class="time">[71:19]</span>This feature responds to multiple faces</p>
    <p class="cue"><span class="time">[71:20]</span>in different locations.</p>
    <p class="cue"><span class="time">[71:22]</span>And by looking at the deconv, we can</p>
    <p class="cue"><span class="time">[71:25]</span>see that it would respond more strongly if we had even darker</p>
    <p class="cue"><span class="time">[71:28]</span>eyes and rosier lips.</p>
    <p class="cue"><span class="time">[71:30]</span>We can also confirm that it cares</p>
    <p class="cue"><span class="time">[71:31]</span>about the head and shoulders that ignores the arms and torso.</p>
    <p class="cue"><span class="time">[71:35]</span>We can even see that it fires to some extent for cat faces.</p>
    <p class="cue"><span class="time">[71:39]</span>Using backprop or deconv, we can see</p>
    <p class="cue"><span class="time">[71:42]</span>that this unit depends most strongly</p>
    <p class="cue"><span class="time">[71:44]</span>on a couple units in the previous layer conv4,</p>
    <p class="cue"><span class="time">[71:47]</span>and on about a dozen or so in conv3.</p>
    <p class="cue"><span class="time">[71:50]</span>So because of deconv, you can trace back the entire layers</p>
    <p class="cue"><span class="time">[71:53]</span>before where--</p>
    <p class="cue"><span class="time">[71:55]</span>The top 9 images.</p>
    <p class="cue"><span class="time">[71:56]</span>OK, I&#x27;m going to leave it to you, but you get the idea.</p>
    <p class="cue"><span class="time">[71:59]</span>These researchers built a toolkit</p>
    <p class="cue"><span class="time">[72:02]</span>that essentially reproduces some of the methods we&#x27;ve</p>
    <p class="cue"><span class="time">[72:04]</span>seen together, although we&#x27;ve seen more methods than what&#x27;s</p>
    <p class="cue"><span class="time">[72:06]</span>in the toolkit.</p>
    <p class="cue"><span class="time">[72:07]</span>And so your kit is now able to answer many questions</p>
    <p class="cue"><span class="time">[72:12]</span>about convolution, such, hey, what part of the input</p>
    <p class="cue"><span class="time">[72:15]</span>is responsible for the output?</p>
    <p class="cue"><span class="time">[72:16]</span>We now that we can use occlusion sensitivity or class activation</p>
    <p class="cue"><span class="time">[72:20]</span>maps.</p>
    <p class="cue"><span class="time">[72:21]</span>What is the role of a neuron filter layer?</p>
    <p class="cue"><span class="time">[72:25]</span>We have many methods that can allow us to do that.</p>
    <p class="cue"><span class="time">[72:27]</span>Can we check what the network focuses</p>
    <p class="cue"><span class="time">[72:29]</span>on given the input image?</p>
    <p class="cue"><span class="time">[72:30]</span>We have methods to do that.</p>
    <p class="cue"><span class="time">[72:32]</span>And how does the neural network see our world?</p>
    <p class="cue"><span class="time">[72:35]</span>We have the gradient ascent class</p>
    <p class="cue"><span class="time">[72:37]</span>model visualization method that allow us to maximize an input</p>
    <p class="cue"><span class="time">[72:42]</span>image with respect-- sorry-- find the input image that</p>
    <p class="cue"><span class="time">[72:45]</span>maximizes a certain activation.</p>
    <p class="cue"><span class="time">[72:48]</span>Super.</p>
    <p class="cue"><span class="time">[72:48]</span>So that was the first part.</p>
    <p class="cue"><span class="time">[72:51]</span>And then we&#x27;re going to move toward frontier ideas.</p>
    <p class="cue"><span class="time">[72:57]</span>Any questions on CNNs?</p>
    <p class="cue"><span class="time">[72:59]</span>Do you feel like you have a better idea</p>
    <p class="cue"><span class="time">[73:01]</span>of how to look inside a CNN?</p>
    <p class="cue"><span class="time">[73:07]</span>Good.</p>
    <p class="cue"><span class="time">[73:08]</span>So let me start by comparing CNNs to more modern frontier</p>
    <p class="cue"><span class="time">[73:17]</span>networks.</p>
    <p class="cue"><span class="time">[73:20]</span>The core distinction is going to be that CNNs deal with localized</p>
    <p class="cue"><span class="time">[73:27]</span>information.</p>
    <p class="cue"><span class="time">[73:28]</span>They visualize edges, textures, and shapes when in modern,</p>
    <p class="cue"><span class="time">[73:33]</span>call it, LLMs, we visualize relationships and meanings</p>
    <p class="cue"><span class="time">[73:39]</span>between concepts or between tokens.</p>
    <p class="cue"><span class="time">[73:44]</span>And this is because transformers are based on attention.</p>
    <p class="cue"><span class="time">[73:50]</span>And that started with the &quot;Attention Is All You Need&quot;</p>
    <p class="cue"><span class="time">[73:52]</span>paper, which essentially explained why attention on its</p>
    <p class="cue"><span class="time">[73:58]</span>own is highly performant and can allow us to model very complex</p>
    <p class="cue"><span class="time">[74:03]</span>relationships.</p>
    <p class="cue"><span class="time">[74:06]</span>By the way, this is just the first figure of the &quot;Attention</p>
    <p class="cue"><span class="time">[74:11]</span>Is All You Need&quot; paper, which you should all be able to read</p>
    <p class="cue"><span class="time">[74:13]</span>and understand by now in the class.</p>
    <p class="cue"><span class="time">[74:17]</span>And transformers really represent</p>
    <p class="cue"><span class="time">[74:20]</span>language using two very simple ideas that are visualizable.</p>
    <p class="cue"><span class="time">[74:26]</span>We can interpret them to a certain extent.</p>
    <p class="cue"><span class="time">[74:29]</span>The first one is the attention patterns.</p>
    <p class="cue"><span class="time">[74:33]</span>Attention looks at the relationship between tokens.</p>
    <p class="cue"><span class="time">[74:37]</span>So you look at a specific token, which can be a word,</p>
    <p class="cue"><span class="time">[74:40]</span>a sub-word or a syllable--</p>
    <p class="cue"><span class="time">[74:43]</span>I&#x27;m going to simplify by saying it&#x27;s a word--</p>
    <p class="cue"><span class="time">[74:46]</span>and its relationship with other words in the training set.</p>
    <p class="cue"><span class="time">[74:50]</span>And that&#x27;s the attention that the transformer looking at it.</p>
    <p class="cue"><span class="time">[74:54]</span>Each attention head learns different patterns.</p>
    <p class="cue"><span class="time">[74:58]</span>So it can learn things like linking pronouns</p>
    <p class="cue"><span class="time">[75:00]</span>to nouns or tracking structures or enforcing a certain ordering.</p>
    <p class="cue"><span class="time">[75:04]</span>And then I really like this visualization, which</p>
    <p class="cue"><span class="time">[75:09]</span>is from Jesse Vig in 2019.</p>
    <p class="cue"><span class="time">[75:13]</span>And this visualization essentially</p>
    <p class="cue"><span class="time">[75:16]</span>shows you there&#x27;s a very nice blog post</p>
    <p class="cue"><span class="time">[75:18]</span>that he wrote with a few figures where</p>
    <p class="cue"><span class="time">[75:21]</span>you can see he presents how attention can</p>
    <p class="cue"><span class="time">[75:24]</span>be visualized in simple ways.</p>
    <p class="cue"><span class="time">[75:27]</span>What is the connection between a fixed token with the surrounding</p>
    <p class="cue"><span class="time">[75:31]</span>tokens, let&#x27;s say.</p>
    <p class="cue"><span class="time">[75:35]</span>So this is essentially the transformer analog</p>
    <p class="cue"><span class="time">[75:39]</span>to the CNN saliency maps that we looked at, pretty much.</p>
    <p class="cue"><span class="time">[75:48]</span>The other things that transformers</p>
    <p class="cue"><span class="time">[75:51]</span>or more modern language model uses embeddings.</p>
    <p class="cue"><span class="time">[75:54]</span>During the pre-training phase, you&#x27;re also learning embeddings.</p>
    <p class="cue"><span class="time">[75:59]</span>You are ready to read the BERT paper, in fact, now</p>
    <p class="cue"><span class="time">[76:02]</span>with the baggage you have from the class.</p>
    <p class="cue"><span class="time">[76:05]</span>And what&#x27;s interesting about embeddings,</p>
    <p class="cue"><span class="time">[76:08]</span>and I printed a picture here from Garg in 2021.</p>
    <p class="cue"><span class="time">[76:13]</span>I also encourage you to see that short blog</p>
    <p class="cue"><span class="time">[76:17]</span>posts where he uses a visualization method</p>
    <p class="cue"><span class="time">[76:19]</span>called t-SNE.</p>
    <p class="cue"><span class="time">[76:20]</span>It&#x27;s a dimensionality reduction method.</p>
    <p class="cue"><span class="time">[76:22]</span>We&#x27;re not going to present it in the class,</p>
    <p class="cue"><span class="time">[76:24]</span>but it&#x27;s taught actually a lot in biotech and health.</p>
    <p class="cue"><span class="time">[76:28]</span>It&#x27;s used very extensively for those of you who work</p>
    <p class="cue"><span class="time">[76:31]</span>with the Stanford Hospital.</p>
    <p class="cue"><span class="time">[76:34]</span>And it allows you to visualize embeddings.</p>
    <p class="cue"><span class="time">[76:36]</span>And embeddings are how the language model</p>
    <p class="cue"><span class="time">[76:39]</span>perceives our words.</p>
    <p class="cue"><span class="time">[76:40]</span>So you would expect tokens that should</p>
    <p class="cue"><span class="time">[76:43]</span>have similar semantic meanings to be</p>
    <p class="cue"><span class="time">[76:45]</span>next to each other in that space,</p>
    <p class="cue"><span class="time">[76:47]</span>or tokens that have nothing to do with each other</p>
    <p class="cue"><span class="time">[76:50]</span>to be far away from each other in distance.</p>
    <p class="cue"><span class="time">[76:52]</span>And that can be a way to sanity check</p>
    <p class="cue"><span class="time">[76:55]</span>that your model actually is learning</p>
    <p class="cue"><span class="time">[76:57]</span>meaningful representations.</p>
    <p class="cue"><span class="time">[77:01]</span>So together attention and embeddings</p>
    <p class="cue"><span class="time">[77:04]</span>are what let large language models track relationship</p>
    <p class="cue"><span class="time">[77:07]</span>and meanings.</p>
    <p class="cue"><span class="time">[77:08]</span>And you can visualize your embeddings</p>
    <p class="cue"><span class="time">[77:12]</span>with dimensionality reduction tool.</p>
    <p class="cue"><span class="time">[77:14]</span>You can even visualize attention relationships as well.</p>
    <p class="cue"><span class="time">[77:19]</span>Unfortunately, the modern transformers</p>
    <p class="cue"><span class="time">[77:22]</span>are so complicated that even the cutting edge</p>
    <p class="cue"><span class="time">[77:26]</span>research is only able to interpret</p>
    <p class="cue"><span class="time">[77:30]</span>those relationships with two layer transformers, pretty much.</p>
    <p class="cue"><span class="time">[77:37]</span>The best you find out there is probably Anthropic&#x27;s work,</p>
    <p class="cue"><span class="time">[77:40]</span>so I linked two papers.</p>
    <p class="cue"><span class="time">[77:41]</span>The first one is called the &quot;Mathematical Framework</p>
    <p class="cue"><span class="time">[77:43]</span>for Transformer Circuits&quot;, which is essentially explaining how</p>
    <p class="cue"><span class="time">[77:48]</span>the different components within a transformer interact with each</p>
    <p class="cue"><span class="time">[77:50]</span>other, and they introduce the concept of a circuit.</p>
    <p class="cue"><span class="time">[77:54]</span>And then the second one is a follow up to that paper called</p>
    <p class="cue"><span class="time">[77:58]</span>&quot;In-Context Learning With Induction Heads&quot;.</p>
    <p class="cue"><span class="time">[78:00]</span>Induction heads are probably the best tool</p>
    <p class="cue"><span class="time">[78:02]</span>we have to visualize what&#x27;s happening inside a transformer.</p>
    <p class="cue"><span class="time">[78:06]</span>It&#x27;s pretty complex.</p>
    <p class="cue"><span class="time">[78:07]</span>You should be able to understand it by now,</p>
    <p class="cue"><span class="time">[78:09]</span>but you&#x27;d have to spend quite some time to go deeper into it.</p>
    <p class="cue"><span class="time">[78:13]</span>I just will link them.</p>
    <p class="cue"><span class="time">[78:14]</span>We&#x27;re not going to talk about it for the sake of time.</p>
    <p class="cue"><span class="time">[78:21]</span>Let&#x27;s get to some fun stuff.</p>
    <p class="cue"><span class="time">[78:24]</span>Training and scaling diagnostics.</p>
    <p class="cue"><span class="time">[78:27]</span>So how do frontier labs check if a model is training?</p>
    <p class="cue"><span class="time">[78:32]</span>Well, we&#x27;ve talked about it in the first case study.</p>
    <p class="cue"><span class="time">[78:35]</span>But one very natural way is to look at the loss curves.</p>
    <p class="cue"><span class="time">[78:39]</span>You can look at the training loss, at and the validation loss</p>
    <p class="cue"><span class="time">[78:42]</span>and make sure that they follow a smooth trajectory.</p>
    <p class="cue"><span class="time">[78:47]</span>And if it&#x27;s not smooth, there&#x27;s probably</p>
    <p class="cue"><span class="time">[78:48]</span>something that went wrong.</p>
    <p class="cue"><span class="time">[78:50]</span>You&#x27;ve probably trained your own network</p>
    <p class="cue"><span class="time">[78:52]</span>where some loss functions look very funky.</p>
    <p class="cue"><span class="time">[78:54]</span>I remember back in the days, there was even blogs</p>
    <p class="cue"><span class="time">[78:56]</span>where people would post their ugliest loss functions,</p>
    <p class="cue"><span class="time">[79:00]</span>and there was a lot on there.</p>
    <p class="cue"><span class="time">[79:03]</span>You might find sudden jumps on the loss.</p>
    <p class="cue"><span class="time">[79:06]</span>That means maybe the batch that has been processed</p>
    <p class="cue"><span class="time">[79:09]</span>has been corrupted.</p>
    <p class="cue"><span class="time">[79:11]</span>Maybe you&#x27;re doing extremely well on it</p>
    <p class="cue"><span class="time">[79:12]</span>when you should actually not do that well.</p>
    <p class="cue"><span class="time">[79:16]</span>And it might raise a flag.</p>
    <p class="cue"><span class="time">[79:19]</span>You might find bugs in your code because of that.</p>
    <p class="cue"><span class="time">[79:21]</span>You might find gradients that are exploding,</p>
    <p class="cue"><span class="time">[79:24]</span>gradients that are vanishing.</p>
    <p class="cue"><span class="time">[79:26]</span>All of that you could visualize at the loss function level.</p>
    <p class="cue"><span class="time">[79:30]</span>Now, note that loss functions can be run at a global level</p>
    <p class="cue"><span class="time">[79:34]</span>or on a specific subset of your data.</p>
    <p class="cue"><span class="time">[79:38]</span>We&#x27;re going to talk about it in data diagnostics.</p>
    <p class="cue"><span class="time">[79:41]</span>The other things that are interesting to track, also</p>
    <p class="cue"><span class="time">[79:44]</span>sometimes referred to in the community as a training</p>
    <p class="cue"><span class="time">[79:48]</span>telemetry, is to watch and track your gradient norms,</p>
    <p class="cue"><span class="time">[79:54]</span>look at your learning rate schedule,</p>
    <p class="cue"><span class="time">[79:57]</span>or even look at hardware efficiency metrics</p>
    <p class="cue"><span class="time">[80:00]</span>to feel if you&#x27;ve underutilized compute, which we talked about</p>
    <p class="cue"><span class="time">[80:04]</span>again in the first part.</p>
    <p class="cue"><span class="time">[80:06]</span>So imagine that if you&#x27;re working at a major frontier lab,</p>
    <p class="cue"><span class="time">[80:10]</span>you probably have a dashboard that tracks your different loss</p>
    <p class="cue"><span class="time">[80:13]</span>function for different subsets of the data, your checkpoints,</p>
    <p class="cue"><span class="time">[80:17]</span>all of that.</p>
    <p class="cue"><span class="time">[80:18]</span>You would have all of that.</p>
    <p class="cue"><span class="time">[80:20]</span>Unfortunately, very few of these are</p>
    <p class="cue"><span class="time">[80:22]</span>published because they&#x27;re IP.</p>
    <p class="cue"><span class="time">[80:26]</span>They don&#x27;t want to give it out because it</p>
    <p class="cue"><span class="time">[80:29]</span>will leak essential information about their architecture,</p>
    <p class="cue"><span class="time">[80:32]</span>about what&#x27;s going well, what&#x27;s not going well, et cetera.</p>
    <p class="cue"><span class="time">[80:34]</span>And that&#x27;s why you find very few information on these.</p>
    <p class="cue"><span class="time">[80:39]</span>The one thing that you do find some charts on that are</p>
    <p class="cue"><span class="time">[80:42]</span>really helpful is scaling laws.</p>
    <p class="cue"><span class="time">[80:44]</span>So scaling laws, which we&#x27;ve talked</p>
    <p class="cue"><span class="time">[80:47]</span>about in a previous lecture, is essentially</p>
    <p class="cue"><span class="time">[80:50]</span>trying to understand the relationship between our model</p>
    <p class="cue"><span class="time">[80:54]</span>performance and some other, call it, hyperparameters</p>
    <p class="cue"><span class="time">[81:00]</span>such as the model capacity, so the size</p>
    <p class="cue"><span class="time">[81:03]</span>of the model, the amount of compute that&#x27;s being used</p>
    <p class="cue"><span class="time">[81:06]</span>or the data set size.</p>
    <p class="cue"><span class="time">[81:08]</span>DeepMind has done amazing work, I</p>
    <p class="cue"><span class="time">[81:11]</span>think it was in 2022, a couple of years ago, with Chinchilla.</p>
    <p class="cue"><span class="time">[81:17]</span>This chart is borrowed from the Chinchilla paper, where</p>
    <p class="cue"><span class="time">[81:22]</span>essentially what I want you to look at here</p>
    <p class="cue"><span class="time">[81:25]</span>is they&#x27;re comparing the Chinchilla</p>
    <p class="cue"><span class="time">[81:27]</span>model, the green star, to other models,</p>
    <p class="cue"><span class="time">[81:30]</span>including GPT-3, which came up a little before.</p>
    <p class="cue"><span class="time">[81:35]</span>And what they&#x27;re showing is that the scaling law is actually</p>
    <p class="cue"><span class="time">[81:40]</span>slightly different than what OpenAI thought.</p>
    <p class="cue"><span class="time">[81:43]</span>And they analyze GPT-3.</p>
    <p class="cue"><span class="time">[81:45]</span>And said GPT-3 is actually not performing well enough</p>
    <p class="cue"><span class="time">[81:50]</span>for the size that it is at.</p>
    <p class="cue"><span class="time">[81:52]</span>And it was found that GPT-3 was not trained for long enough.</p>
    <p class="cue"><span class="time">[81:56]</span>They essentially explained that if you kept training GPT-3</p>
    <p class="cue"><span class="time">[81:59]</span>for longer, you would have had way better performance.</p>
    <p class="cue"><span class="time">[82:03]</span>And it was not about the model size.</p>
    <p class="cue"><span class="time">[82:05]</span>In fact, the model was underutilized.</p>
    <p class="cue"><span class="time">[82:08]</span>So they plotted these lines.</p>
    <p class="cue"><span class="time">[82:10]</span>So the dotted line is what probably we</p>
    <p class="cue"><span class="time">[82:13]</span>thought in 2021, the scaling law, the power law would be.</p>
    <p class="cue"><span class="time">[82:18]</span>And they showed that it&#x27;s actually not exactly that</p>
    <p class="cue"><span class="time">[82:20]</span>where essentially the idea is they plot the full line here,</p>
    <p class="cue"><span class="time">[82:26]</span>and they say this is our analysis of the scaling law.</p>
    <p class="cue"><span class="time">[82:30]</span>If your star is above that line, it&#x27;s</p>
    <p class="cue"><span class="time">[82:33]</span>probably that your model should be trained longer.</p>
    <p class="cue"><span class="time">[82:39]</span>If it&#x27;s on the line, it&#x27;s respecting the scaling laws</p>
    <p class="cue"><span class="time">[82:41]</span>that they&#x27;re finding.</p>
    <p class="cue"><span class="time">[82:43]</span>And that&#x27;s what&#x27;s interesting about this Chinchilla paper.</p>
    <p class="cue"><span class="time">[82:45]</span>Yeah.</p>
    <p class="cue"><span class="time">[82:46]</span>So this is after OpenAI GPT model paper?</p>
    <p class="cue"><span class="time">[82:50]</span>So that&#x27;s after the GPT-3 paper, Chinchilla</p>
    <p class="cue"><span class="time">[82:53]</span>came in 2022 saying you should have trained GPT-3 longer.</p>
    <p class="cue"><span class="time">[82:57]</span>You would have done better.</p>
    <p class="cue"><span class="time">[82:58]</span>And here&#x27;s Chinchilla, a model that</p>
    <p class="cue"><span class="time">[83:01]</span>has less parameters than GPT-3, so 70 billion</p>
    <p class="cue"><span class="time">[83:05]</span>versus 175 billion.</p>
    <p class="cue"><span class="time">[83:08]</span>And that is performing better.</p>
    <p class="cue"><span class="time">[83:13]</span>Yes.</p>
    <p class="cue"><span class="time">[83:14]</span>To go deeper, I also pulled a few charts</p>
    <p class="cue"><span class="time">[83:20]</span>that show you the power laws between the loss function.</p>
    <p class="cue"><span class="time">[83:26]</span>So on the vertical axis, you have the test loss</p>
    <p class="cue"><span class="time">[83:30]</span>that shows essentially your performance on the test set.</p>
    <p class="cue"><span class="time">[83:33]</span>And then on the horizontal axis, on the x-axis,</p>
    <p class="cue"><span class="time">[83:36]</span>you have compute data set size and parameters.</p>
    <p class="cue"><span class="time">[83:39]</span>So how are those scaling laws established?</p>
    <p class="cue"><span class="time">[83:41]</span>Essentially, they fix two of them,</p>
    <p class="cue"><span class="time">[83:42]</span>and they vary the third one.</p>
    <p class="cue"><span class="time">[83:44]</span>And they see if things are respected.</p>
    <p class="cue"><span class="time">[83:47]</span>Let&#x27;s say you&#x27;re keeping the same compute,</p>
    <p class="cue"><span class="time">[83:52]</span>the same data set size, but you&#x27;re training a model that</p>
    <p class="cue"><span class="time">[83:57]</span>is twice as big in logarithms, what</p>
    <p class="cue"><span class="time">[84:02]</span>does it tell you about the performance, essentially?</p>
    <p class="cue"><span class="time">[84:05]</span>Are those scaling laws respected?</p>
    <p class="cue"><span class="time">[84:07]</span>And so what&#x27;s nice now is that we have</p>
    <p class="cue"><span class="time">[84:08]</span>a precedent for scaling laws.</p>
    <p class="cue"><span class="time">[84:10]</span>So if you were actually training such big models,</p>
    <p class="cue"><span class="time">[84:14]</span>you would compare to the scaling laws</p>
    <p class="cue"><span class="time">[84:16]</span>that are available out there.</p>
    <p class="cue"><span class="time">[84:19]</span>Remember, another reason these are important</p>
    <p class="cue"><span class="time">[84:21]</span>is because models training runs are so expensive.</p>
    <p class="cue"><span class="time">[84:25]</span>It wasn&#x27;t shared publicly, but we</p>
    <p class="cue"><span class="time">[84:27]</span>estimate that GPT-5 is probably in the hundreds of millions.</p>
    <p class="cue"><span class="time">[84:33]</span>And so you want to know, should I train that model</p>
    <p class="cue"><span class="time">[84:36]</span>twice longer or not?</p>
    <p class="cue"><span class="time">[84:37]</span>Because that&#x27;s a big financial decision.</p>
    <p class="cue"><span class="time">[84:40]</span>And the scaling laws allow you to determine,</p>
    <p class="cue"><span class="time">[84:42]</span>should I invest in compute, should I</p>
    <p class="cue"><span class="time">[84:44]</span>invest in growing my data set, so finding more data,</p>
    <p class="cue"><span class="time">[84:48]</span>or should I invest in model capacity,</p>
    <p class="cue"><span class="time">[84:50]</span>making my model bigger?</p>
    <p class="cue"><span class="time">[85:02]</span>Together these forms a health dashboard for the model.</p>
    <p class="cue"><span class="time">[85:09]</span>So that&#x27;s training and scaling diagnostic, loss functions,</p>
    <p class="cue"><span class="time">[85:12]</span>et cetera.</p>
    <p class="cue"><span class="time">[85:14]</span>Health dashboard, scaling laws, all of that</p>
    <p class="cue"><span class="time">[85:17]</span>are things that researchers might</p>
    <p class="cue"><span class="time">[85:18]</span>use to get a broad sense of where to invest more</p>
    <p class="cue"><span class="time">[85:23]</span>in terms of improving their model.</p>
    <p class="cue"><span class="time">[85:25]</span>The other one is something we&#x27;ve already</p>
    <p class="cue"><span class="time">[85:27]</span>seen to a certain extent, is how labs evaluate</p>
    <p class="cue"><span class="time">[85:31]</span>model capabilities and safety.</p>
    <p class="cue"><span class="time">[85:34]</span>And they might do it with benchmarks.</p>
    <p class="cue"><span class="time">[85:36]</span>So capability benchmark might be evaluating</p>
    <p class="cue"><span class="time">[85:39]</span>the model in tasks like reasoning or coding</p>
    <p class="cue"><span class="time">[85:43]</span>or math or multilingual tasks, et cetera.</p>
    <p class="cue"><span class="time">[85:46]</span>It might also be comparing checkpoints</p>
    <p class="cue"><span class="time">[85:49]</span>that help you understand how your model is improving over</p>
    <p class="cue"><span class="time">[85:53]</span>time depending on what you&#x27;re feeding it, or depending</p>
    <p class="cue"><span class="time">[85:56]</span>on some hyperparameters that you&#x27;re tweaking.</p>
    <p class="cue"><span class="time">[86:01]</span>And also error clusters.</p>
    <p class="cue"><span class="time">[86:05]</span>So just to tell you a little more about error clusters,</p>
    <p class="cue"><span class="time">[86:08]</span>if you actually use benchmarks across a wide variety of tasks,</p>
    <p class="cue"><span class="time">[86:12]</span>you might see that all the model checkpoint number 5 is actually</p>
    <p class="cue"><span class="time">[86:16]</span>doing very poorly at reasoning.</p>
    <p class="cue"><span class="time">[86:17]</span>Let&#x27;s see why is that.</p>
    <p class="cue"><span class="time">[86:20]</span>So here are some examples from a competitive math benchmark</p>
    <p class="cue"><span class="time">[86:26]</span>2025 AIME published by OpenAI on GPT-5.</p>
    <p class="cue"><span class="time">[86:32]</span>And actually the bottom one is from today.</p>
    <p class="cue"><span class="time">[86:34]</span>This morning, Mistral announced their third generation model.</p>
    <p class="cue"><span class="time">[86:39]</span>So I thought I&#x27;d pull it to show you how real time these things</p>
    <p class="cue"><span class="time">[86:42]</span>are and just published today.</p>
    <p class="cue"><span class="time">[86:45]</span>And they&#x27;re comparing across reasoning, and math, and et</p>
    <p class="cue"><span class="time">[86:48]</span>cetera against benchmarks.</p>
    <p class="cue"><span class="time">[86:51]</span>Now the risk is, are these benchmarks contaminated?</p>
    <p class="cue"><span class="time">[86:55]</span>How can a benchmark be contaminated?</p>
    <p class="cue"><span class="time">[86:58]</span>Yeah.</p>
    <p class="cue"><span class="time">[87:01]</span>If it was in the training data.</p>
    <p class="cue"><span class="time">[87:02]</span>The problem is these models are trained on so much data online.</p>
    <p class="cue"><span class="time">[87:05]</span>You don&#x27;t know.</p>
    <p class="cue"><span class="time">[87:05]</span>Maybe it was trained on a blog post where someone actually</p>
    <p class="cue"><span class="time">[87:08]</span>was presenting a benchmark and describing</p>
    <p class="cue"><span class="time">[87:10]</span>what the benchmark was about.</p>
    <p class="cue"><span class="time">[87:11]</span>Maybe it was trained on GitHub, and there</p>
    <p class="cue"><span class="time">[87:13]</span>was a text file in a very shady part of the GitHub</p>
    <p class="cue"><span class="time">[87:16]</span>that was listing some of the test sets information.</p>
    <p class="cue"><span class="time">[87:20]</span>All of those might contaminate benchmarks.</p>
    <p class="cue"><span class="time">[87:22]</span>How would you identify that benchmark has been contaminated,</p>
    <p class="cue"><span class="time">[87:31]</span>test set has been contaminated?</p>
    <p class="cue"><span class="time">[87:33]</span>Isn&#x27;t that kind of what is normal for [INAUDIBLE].</p>
    <p class="cue"><span class="time">[87:36]</span>Everybody should read the results and benchmarks,</p>
    <p class="cue"><span class="time">[87:39]</span>but then the model came up and people actually</p>
    <p class="cue"><span class="time">[87:41]</span>tried it on similar tasks.</p>
    <p class="cue"><span class="time">[87:43]</span>It wasn&#x27;t performing well.</p>
    <p class="cue"><span class="time">[87:44]</span>So it&#x27;s like we&#x27;re testing it on similar stuff.</p>
    <p class="cue"><span class="time">[87:50]</span>Yeah.</p>
    <p class="cue"><span class="time">[87:50]</span>Llama 4 you brought up, just to repeat,</p>
    <p class="cue"><span class="time">[87:54]</span>looked good on benchmark, looked poor in practice</p>
    <p class="cue"><span class="time">[87:57]</span>after the community tested it.</p>
    <p class="cue"><span class="time">[87:59]</span>The general consensus, I mean, my opinion is, I actually</p>
    <p class="cue"><span class="time">[88:02]</span>don&#x27;t look too much at the benchmarks</p>
    <p class="cue"><span class="time">[88:04]</span>when a foundation model provider publishes them.</p>
    <p class="cue"><span class="time">[88:07]</span>Or in other words, I would look at them</p>
    <p class="cue"><span class="time">[88:09]</span>in relative value between models rather than absolute value.</p>
    <p class="cue"><span class="time">[88:13]</span>And you&#x27;ll wait for the community to test it,</p>
    <p class="cue"><span class="time">[88:16]</span>on agentic workflows on their tasks,</p>
    <p class="cue"><span class="time">[88:18]</span>and then people will get a taste for if it works or not,</p>
    <p class="cue"><span class="time">[88:21]</span>and on what it works.</p>
    <p class="cue"><span class="time">[88:23]</span>So it took some time, for example,</p>
    <p class="cue"><span class="time">[88:24]</span>for the community to realize how good Claude was at coding,</p>
    <p class="cue"><span class="time">[88:28]</span>let&#x27;s say.</p>
    <p class="cue"><span class="time">[88:29]</span>It was clear from the benchmark, but others were also</p>
    <p class="cue"><span class="time">[88:32]</span>clearly good.</p>
    <p class="cue"><span class="time">[88:33]</span>But over time, people felt like, oh, wow, it&#x27;s</p>
    <p class="cue"><span class="time">[88:35]</span>actually really good at coding.</p>
    <p class="cue"><span class="time">[88:37]</span>You had a question or no?</p>
    <p class="cue"><span class="time">[88:39]</span>OK.</p>
    <p class="cue"><span class="time">[88:40]</span>Cool.</p>
    <p class="cue"><span class="time">[88:41]</span>Oh, yeah, contamination.</p>
    <p class="cue"><span class="time">[88:43]</span>So how to detect if a test set has been exposed?</p>
    <p class="cue"><span class="time">[88:50]</span>A few methods.</p>
    <p class="cue"><span class="time">[88:53]</span>Some researchers might do a search within the data set.</p>
    <p class="cue"><span class="time">[88:59]</span>So let&#x27;s say you have a training set,</p>
    <p class="cue"><span class="time">[89:00]</span>and you have a held out test set.</p>
    <p class="cue"><span class="time">[89:03]</span>And you actually look for n grams.</p>
    <p class="cue"><span class="time">[89:05]</span>So you take sequences of tokens size 7, 8.</p>
    <p class="cue"><span class="time">[89:08]</span>And you search through the train set,</p>
    <p class="cue"><span class="time">[89:10]</span>and you find that they&#x27;re same n grams</p>
    <p class="cue"><span class="time">[89:12]</span>is also found in the test set.</p>
    <p class="cue"><span class="time">[89:15]</span>There&#x27;s a chance some of it has been contaminated.</p>
    <p class="cue"><span class="time">[89:17]</span>You can do it also with hashes or with embeddings.</p>
    <p class="cue"><span class="time">[89:21]</span>Actually, maybe the test set has been contaminated but not word</p>
    <p class="cue"><span class="time">[89:25]</span>for word, maybe semantically.</p>
    <p class="cue"><span class="time">[89:27]</span>And so you might do the same thing with an embedding</p>
    <p class="cue"><span class="time">[89:29]</span>and run a search and say that, oh, wow,</p>
    <p class="cue"><span class="time">[89:31]</span>this specific example from the test set</p>
    <p class="cue"><span class="time">[89:36]</span>is found in the training set semantically very similar stuff.</p>
    <p class="cue"><span class="time">[89:40]</span>So you might actually run analysis</p>
    <p class="cue"><span class="time">[89:43]</span>to figure out if it&#x27;s contaminated.</p>
    <p class="cue"><span class="time">[89:45]</span>And if you find that your test set has been exposed</p>
    <p class="cue"><span class="time">[89:48]</span>or you have a reason to think it&#x27;s been exposed,</p>
    <p class="cue"><span class="time">[89:51]</span>what do you do?</p>
    <p class="cue"><span class="time">[89:52]</span>You would usually fix the test set.</p>
    <p class="cue"><span class="time">[89:55]</span>The test set is smaller.</p>
    <p class="cue"><span class="time">[89:56]</span>You would remove all those examples</p>
    <p class="cue"><span class="time">[89:58]</span>that you think are exposed, and you would replace them</p>
    <p class="cue"><span class="time">[90:01]</span>with brand new ones that are completely held</p>
    <p class="cue"><span class="time">[90:03]</span>offline in a folder that is separate, not available</p>
    <p class="cue"><span class="time">[90:07]</span>online, et cetera.</p>
    <p class="cue"><span class="time">[90:11]</span>Yeah.</p>
    <p class="cue"><span class="time">[90:12]</span>Then there&#x27;s the problem of safety evaluations.</p>
    <p class="cue"><span class="time">[90:15]</span>I&#x27;m not going to spend too much time on it,</p>
    <p class="cue"><span class="time">[90:17]</span>but safety is important to foundation model providers.</p>
    <p class="cue"><span class="time">[90:23]</span>They stress test their model and their many adversarial attacks,</p>
    <p class="cue"><span class="time">[90:28]</span>jailbreaking, social engineering, misuses.</p>
    <p class="cue"><span class="time">[90:32]</span>They also assess harmful content generation, hallucination,</p>
    <p class="cue"><span class="time">[90:36]</span>privacy, leakage, et cetera, et cetera.</p>
    <p class="cue"><span class="time">[90:40]</span>And then they also look at how the foundation</p>
    <p class="cue"><span class="time">[90:43]</span>model behaves in an agentic workflow,</p>
    <p class="cue"><span class="time">[90:46]</span>as I was saying earlier.</p>
    <p class="cue"><span class="time">[90:47]</span>So not only evaluating it one shot,</p>
    <p class="cue"><span class="time">[90:52]</span>but evaluating it in a workflow.</p>
    <p class="cue"><span class="time">[90:57]</span>Here are some examples of actually very</p>
    <p class="cue"><span class="time">[91:01]</span>nice joint collaboration between OpenAI and Anthropic</p>
    <p class="cue"><span class="time">[91:05]</span>from last year, where they work together</p>
    <p class="cue"><span class="time">[91:08]</span>to assess the safety of their models,</p>
    <p class="cue"><span class="time">[91:11]</span>and they tried to jailbreak the model to socially engineer.</p>
    <p class="cue"><span class="time">[91:15]</span>And they published some the findings</p>
    <p class="cue"><span class="time">[91:19]</span>on password protection or phrase protection.</p>
    <p class="cue"><span class="time">[91:23]</span>I linked it, and I would encourage</p>
    <p class="cue"><span class="time">[91:24]</span>you to quickly look at it.</p>
    <p class="cue"><span class="time">[91:26]</span>They wrote prompts to try to extract a password from a model</p>
    <p class="cue"><span class="time">[91:31]</span>and see if the model was good at not leaking the password,</p>
    <p class="cue"><span class="time">[91:36]</span>for example.</p>
    <p class="cue"><span class="time">[91:40]</span>So these dashboards essentially inform the go/no-go decision</p>
    <p class="cue"><span class="time">[91:45]</span>for releasing or for determining what the HF will be based on.</p>
    <p class="cue"><span class="time">[91:52]</span>So if you&#x27;re actually going to do supervised fine-tuning</p>
    <p class="cue"><span class="time">[91:55]</span>or reinforcement learning from human feedback, it&#x27;s expensive</p>
    <p class="cue"><span class="time">[92:01]</span>and you want to do it on the stuff that&#x27;s failing.</p>
    <p class="cue"><span class="time">[92:04]</span>So if you identify exactly which evals are failing,</p>
    <p class="cue"><span class="time">[92:07]</span>you will then use that information</p>
    <p class="cue"><span class="time">[92:09]</span>to focus the RLHF on that specific problem</p>
    <p class="cue"><span class="time">[92:13]</span>and save a lot of money and human time.</p>
    <p class="cue"><span class="time">[92:20]</span>Lastly, let me see if there&#x27;s anything</p>
    <p class="cue"><span class="time">[92:22]</span>else I wanted to mention here.</p>
    <p class="cue"><span class="time">[92:35]</span>Let&#x27;s talk about the data diagnostic,</p>
    <p class="cue"><span class="time">[92:37]</span>and we&#x27;ll end on that.</p>
    <p class="cue"><span class="time">[92:40]</span>So data diagnostics, this is probably the last area</p>
    <p class="cue"><span class="time">[92:44]</span>that frontier models are very focused on.</p>
    <p class="cue"><span class="time">[92:47]</span>So how labs detect data issues.</p>
    <p class="cue"><span class="time">[92:52]</span>There are many things you can do.</p>
    <p class="cue"><span class="time">[92:55]</span>But I really like distribution check.</p>
    <p class="cue"><span class="time">[92:56]</span>So I pulled this chart from a paper called &quot;The Pile&quot;</p>
    <p class="cue"><span class="time">[93:01]</span>from 2020 where the pile is a very large data set,</p>
    <p class="cue"><span class="time">[93:05]</span>800 gigabytes, that is made from diverse texts.</p>
    <p class="cue"><span class="time">[93:10]</span>And they kept the data domain.</p>
    <p class="cue"><span class="time">[93:11]</span>So they explained using that figure what the data set</p>
    <p class="cue"><span class="time">[93:15]</span>is made of.</p>
    <p class="cue"><span class="time">[93:16]</span>So the data set might be made of information from free law,</p>
    <p class="cue"><span class="time">[93:20]</span>or it might be made of Wikipedia,</p>
    <p class="cue"><span class="time">[93:22]</span>Stack Exchange, GitHub with coding.</p>
    <p class="cue"><span class="time">[93:25]</span>And so you have different domains within that data set.</p>
    <p class="cue"><span class="time">[93:28]</span>And in fact, when you train a model on that,</p>
    <p class="cue"><span class="time">[93:30]</span>you can plot the loss function across the entire data set,</p>
    <p class="cue"><span class="time">[93:33]</span>or you can plot the loss function</p>
    <p class="cue"><span class="time">[93:34]</span>across different domains within that data set, which</p>
    <p class="cue"><span class="time">[93:37]</span>give you more intuition for where</p>
    <p class="cue"><span class="time">[93:41]</span>it might be failing or working.</p>
    <p class="cue"><span class="time">[93:43]</span>And so you might want to track domain proportions</p>
    <p class="cue"><span class="time">[93:46]</span>in your data set.</p>
    <p class="cue"><span class="time">[93:48]</span>And domain proportions also matter because it is observed</p>
    <p class="cue"><span class="time">[93:53]</span>that if certain domains are underrepresented in the data,</p>
    <p class="cue"><span class="time">[94:00]</span>the performance of the model on that domain</p>
    <p class="cue"><span class="time">[94:02]</span>is likely going to drop in comparison to another domain.</p>
    <p class="cue"><span class="time">[94:07]</span>So all things are not equal.</p>
    <p class="cue"><span class="time">[94:08]</span>If you actually have so much-- we remember with the speech</p>
    <p class="cue"><span class="time">[94:13]</span>recognition example where I said,</p>
    <p class="cue"><span class="time">[94:14]</span>you have too many zeros and too few ones,</p>
    <p class="cue"><span class="time">[94:16]</span>and so the model just doesn&#x27;t learn the ones.</p>
    <p class="cue"><span class="time">[94:25]</span>This is also a problem with online learning.</p>
    <p class="cue"><span class="time">[94:28]</span>So imagine those frontier model they&#x27;re learning live.</p>
    <p class="cue"><span class="time">[94:32]</span>Oftentimes, they&#x27;re just being fed data constantly.</p>
    <p class="cue"><span class="time">[94:35]</span>And maybe the batch from the last month</p>
    <p class="cue"><span class="time">[94:38]</span>had very little coding data.</p>
    <p class="cue"><span class="time">[94:40]</span>And so the last portion of the training, the distribution</p>
    <p class="cue"><span class="time">[94:44]</span>of the coding domain, or the frequency</p>
    <p class="cue"><span class="time">[94:47]</span>was lower than other domains.</p>
    <p class="cue"><span class="time">[94:49]</span>And so sometimes you might see a drop</p>
    <p class="cue"><span class="time">[94:51]</span>in performance for a specific domain if you&#x27;re not careful.</p>
    <p class="cue"><span class="time">[94:56]</span>That can be fixed with sampling like smart sampling.</p>
    <p class="cue"><span class="time">[94:59]</span>You remember what we saw in reinforcement</p>
    <p class="cue"><span class="time">[95:00]</span>learning with the experience replay, where we actually</p>
    <p class="cue"><span class="time">[95:03]</span>kept experiences and we put them in a replay memory,</p>
    <p class="cue"><span class="time">[95:06]</span>and then we sampled from that.</p>
    <p class="cue"><span class="time">[95:08]</span>Those are the types of methods, sampling methods that</p>
    <p class="cue"><span class="time">[95:11]</span>allow a model provider to make sure they keep</p>
    <p class="cue"><span class="time">[95:14]</span>the frequency of data domain the same at different portions</p>
    <p class="cue"><span class="time">[95:18]</span>of the training.</p>
    <p class="cue"><span class="time">[95:23]</span>Token statistics, just to mention it a little bit,</p>
    <p class="cue"><span class="time">[95:27]</span>you want to count the frequency changes for key tokens which</p>
    <p class="cue"><span class="time">[95:34]</span>I was mentioning.</p>
    <p class="cue"><span class="time">[95:35]</span>So let&#x27;s say, a math token is underrepresented.</p>
    <p class="cue"><span class="time">[95:41]</span>That will be a problem.</p>
    <p class="cue"><span class="time">[95:43]</span>The derivative symbol is underrepresented.</p>
    <p class="cue"><span class="time">[95:46]</span>That might actually lead to way worse performance</p>
    <p class="cue"><span class="time">[95:49]</span>for that specific task where you ask</p>
    <p class="cue"><span class="time">[95:51]</span>the model to make derivatives.</p>
    <p class="cue"><span class="time">[95:56]</span>And so labs oftentimes monitor token drift or distribution</p>
    <p class="cue"><span class="time">[96:02]</span>or the frequency per token.</p>
    <p class="cue"><span class="time">[96:03]</span>And they use sampling to fix it.</p>
    <p class="cue"><span class="time">[96:05]</span>And finally the contamination checks, which</p>
    <p class="cue"><span class="time">[96:07]</span>we have talked about earlier.</p>
    <p class="cue"><span class="time">[96:09]</span>I also give you concrete examples.</p>
    <p class="cue"><span class="time">[96:11]</span>I&#x27;m not going to go through all of them.</p>
    <p class="cue"><span class="time">[96:13]</span>But these are examples of token distribution, reef reports,</p>
    <p class="cue"><span class="time">[96:18]</span>tokenizer statistics, issues that I raise here</p>
    <p class="cue"><span class="time">[96:25]</span>or some anomalies on corrupt data detection.</p>
    <p class="cue"><span class="time">[96:31]</span>So if I read one of the examples for you,</p>
    <p class="cue"><span class="time">[96:35]</span>let&#x27;s pick this one maybe.</p>
    <p class="cue"><span class="time">[96:41]</span>Non-English tokens increase from 12% to 19% after new web crawl,</p>
    <p class="cue"><span class="time">[96:47]</span>where that might mean that the domain of that specific language</p>
    <p class="cue"><span class="time">[96:51]</span>is increasing relative to others,</p>
    <p class="cue"><span class="time">[96:53]</span>and that might lead to an increase in performance</p>
    <p class="cue"><span class="time">[96:57]</span>or a drop in performance for a different language.</p>
    <p class="cue"><span class="time">[97:00]</span>As simple as that.</p>
    <p class="cue"><span class="time">[97:06]</span>OK, to summarize everything, what are examples of things</p>
    <p class="cue"><span class="time">[97:12]</span>that frontier labs monitor?</p>
    <p class="cue"><span class="time">[97:15]</span>Global training loss, validation loss, both global and domain</p>
    <p class="cue"><span class="time">[97:18]</span>specific on the subset of the data,</p>
    <p class="cue"><span class="time">[97:21]</span>scaling curve alignment, comparing your test loss</p>
    <p class="cue"><span class="time">[97:25]</span>to your compute to your, to your data set,</p>
    <p class="cue"><span class="time">[97:27]</span>or to your model capacity.</p>
    <p class="cue"><span class="time">[97:30]</span>We didn&#x27;t talk too much about router, but mixture of experts.</p>
    <p class="cue"><span class="time">[97:34]</span>Imagine you have a lot of the models that are top models right</p>
    <p class="cue"><span class="time">[97:38]</span>now or mixtures of experts, meaning</p>
    <p class="cue"><span class="time">[97:40]</span>that in your transformer block for the multi-layer perceptron,</p>
    <p class="cue"><span class="time">[97:46]</span>there&#x27;s actually multiple experts that are being trained</p>
    <p class="cue"><span class="time">[97:48]</span>in parallel, and there&#x27;s a router that</p>
    <p class="cue"><span class="time">[97:51]</span>will route that batch of data to the right experts</p>
    <p class="cue"><span class="time">[97:55]</span>to top 1, top 2, top 3, experts.</p>
    <p class="cue"><span class="time">[97:58]</span>And it&#x27;s very common for the router to fail to</p>
    <p class="cue"><span class="time">[98:01]</span>or to always exploit the same mixture of experts.</p>
    <p class="cue"><span class="time">[98:05]</span>You need a mechanism to detect when this happens.</p>
    <p class="cue"><span class="time">[98:08]</span>And so you might have in your health dashboard some</p>
    <p class="cue"><span class="time">[98:10]</span>of a router information, or whether the mixture of experts</p>
    <p class="cue"><span class="time">[98:15]</span>are all used as much as each other.</p>
    <p class="cue"><span class="time">[98:17]</span>Sometimes certain experts are going</p>
    <p class="cue"><span class="time">[98:18]</span>to be so specialized that they&#x27;re never</p>
    <p class="cue"><span class="time">[98:20]</span>going to be used almost.</p>
    <p class="cue"><span class="time">[98:21]</span>And you want to avoid that.</p>
    <p class="cue"><span class="time">[98:22]</span>And you might do some load balancing to avoid.</p>
    <p class="cue"><span class="time">[98:25]</span>Gradient norms, learning rates, checkpoint</p>
    <p class="cue"><span class="time">[98:31]</span>to checkpoint, eval benchmark token distribution,</p>
    <p class="cue"><span class="time">[98:34]</span>tokenizer statistic.</p>
    <p class="cue"><span class="time">[98:35]</span>We covered all of that at a high level.</p>
    <p class="cue"><span class="time">[98:37]</span>And as I said earlier, frontier labs rarely</p>
    <p class="cue"><span class="time">[98:40]</span>publish those dashboards because it&#x27;s IP</p>
    <p class="cue"><span class="time">[98:43]</span>and because it can leak certain deep information about their IP</p>
    <p class="cue"><span class="time">[98:47]</span>and how their models are trained.</p>
    <p class="cue"><span class="time">[98:49]</span>And so you usually learn about these things year after.</p>
    <p class="cue"><span class="time">[98:52]</span>You might learn about these things</p>
    <p class="cue"><span class="time">[98:54]</span>on a model that came out three years ago or four years ago</p>
    <p class="cue"><span class="time">[98:58]</span>and they&#x27;re OK now with sharing it.</p>
    <p class="cue"><span class="time">[99:01]</span>It&#x27;s pretty common.</p>
    <p class="cue"><span class="time">[99:05]</span>So closing remarks, any questions first?</p>
    <p class="cue"><span class="time">[99:08]</span>Yeah.</p>
    <p class="cue"><span class="time">[99:09]</span>Do you, for example, Claude training coding models.</p>
    <p class="cue"><span class="time">[99:14]</span>So do they care more about tokens</p>
    <p class="cue"><span class="time">[99:17]</span>that are shown in code in general,</p>
    <p class="cue"><span class="time">[99:21]</span>or are they more worried about having that diverse tokens?</p>
    <p class="cue"><span class="time">[99:26]</span>Yeah.</p>
    <p class="cue"><span class="time">[99:27]</span>So you&#x27;re asking if Anthropic is training Cloud Code,</p>
    <p class="cue"><span class="time">[99:31]</span>do they care mostly about coding data,</p>
    <p class="cue"><span class="time">[99:34]</span>or do they also add other data?</p>
    <p class="cue"><span class="time">[99:37]</span>Yeah, it&#x27;s a tough question.</p>
    <p class="cue"><span class="time">[99:39]</span>I don&#x27;t have the exact answer.</p>
    <p class="cue"><span class="time">[99:41]</span>It&#x27;s been shown that certain domains might</p>
    <p class="cue"><span class="time">[99:43]</span>improve the performance of other domains.</p>
    <p class="cue"><span class="time">[99:45]</span>So I imagine that in coding if you have math data,</p>
    <p class="cue"><span class="time">[99:50]</span>maybe math data actually helps the performance of coding,</p>
    <p class="cue"><span class="time">[99:53]</span>especially for functional programming,</p>
    <p class="cue"><span class="time">[99:54]</span>let&#x27;s say coding languages that are more mathematical.</p>
    <p class="cue"><span class="time">[99:58]</span>But I could clearly see that if they were training</p>
    <p class="cue"><span class="time">[100:02]</span>Cloud Code on web crawl and everything,</p>
    <p class="cue"><span class="time">[100:04]</span>it would not perform well because you would have</p>
    <p class="cue"><span class="time">[100:06]</span>so much crap data that is not relevant for what you&#x27;re</p>
    <p class="cue"><span class="time">[100:09]</span>trying to get the model to do.</p>
    <p class="cue"><span class="time">[100:10]</span>And so I think there is a balance between those things.</p>
    <p class="cue"><span class="time">[100:13]</span>So it&#x27;s safe to say you would want to be in the--</p>
    <p class="cue"><span class="time">[100:17]</span>you would want to include neighboring domains as well?</p>
    <p class="cue"><span class="time">[100:21]</span>I think you could run experiments.</p>
    <p class="cue"><span class="time">[100:23]</span>So would you include neighboring domains</p>
    <p class="cue"><span class="time">[100:25]</span>if I were training Cloud Code and I</p>
    <p class="cue"><span class="time">[100:29]</span>had a lot of money to do that, I would probably--</p>
    <p class="cue"><span class="time">[100:32]</span>maybe you would start with a Python language,</p>
    <p class="cue"><span class="time">[100:35]</span>and you get as much, and there&#x27;s so much data on Python language,</p>
    <p class="cue"><span class="time">[100:38]</span>so you probably have enough already there.</p>
    <p class="cue"><span class="time">[100:40]</span>But then you want a model that scales to other programming</p>
    <p class="cue"><span class="time">[100:43]</span>languages.</p>
    <p class="cue"><span class="time">[100:43]</span>Well, probably Python is useful for C++, C++ is useful for Java,</p>
    <p class="cue"><span class="time">[100:48]</span>and then functional programming, if you&#x27;re going to ELIXIR,</p>
    <p class="cue"><span class="time">[100:52]</span>Scala, things like that, they&#x27;re helping each other probably</p>
    <p class="cue"><span class="time">[100:54]</span>to a certain extent.</p>
    <p class="cue"><span class="time">[100:56]</span>But you will need to have a presentation of those.</p>
    <p class="cue"><span class="time">[100:59]</span>I could see that--</p>
    <p class="cue"><span class="time">[101:01]</span>I&#x27;m pretty sure, and I don&#x27;t work at Anthropic,</p>
    <p class="cue"><span class="time">[101:04]</span>so I don&#x27;t know.</p>
    <p class="cue"><span class="time">[101:05]</span>But I&#x27;m pretty sure, let&#x27;s say a language like Rust increases</p>
    <p class="cue"><span class="time">[101:09]</span>in popularity, which is the case.</p>
    <p class="cue"><span class="time">[101:12]</span>And then in the data distribution,</p>
    <p class="cue"><span class="time">[101:14]</span>you start seeing more frequency of those tokens from Rust.</p>
    <p class="cue"><span class="time">[101:18]</span>Does that affect the performance on other languages?</p>
    <p class="cue"><span class="time">[101:22]</span>Probably yes.</p>
    <p class="cue"><span class="time">[101:23]</span>That&#x27;s my guess.</p>
    <p class="cue"><span class="time">[101:25]</span>And how do you track it?</p>
    <p class="cue"><span class="time">[101:26]</span>This is all what we talked about.</p>
    <p class="cue"><span class="time">[101:30]</span>Yeah.</p>
    <p class="cue"><span class="time">[101:30]</span>If you train on publicly available data, a lot of people</p>
    <p class="cue"><span class="time">[101:34]</span>are saying to use synthetic data.</p>
    <p class="cue"><span class="time">[101:35]</span>What do you think of that?</p>
    <p class="cue"><span class="time">[101:37]</span>Do you think that would increase performance?</p>
    <p class="cue"><span class="time">[101:39]</span>Yeah.</p>
    <p class="cue"><span class="time">[101:39]</span>Question is, let&#x27;s say we trained on everything online</p>
    <p class="cue"><span class="time">[101:44]</span>and now real data.</p>
    <p class="cue"><span class="time">[101:46]</span>What about synthetic data?</p>
    <p class="cue"><span class="time">[101:47]</span>Should we use it a lot?</p>
    <p class="cue"><span class="time">[101:48]</span>Should we use it strategically?</p>
    <p class="cue"><span class="time">[101:50]</span>What&#x27;s the future of that?</p>
    <p class="cue"><span class="time">[101:53]</span>So it depends of are you talking about general purpose models</p>
    <p class="cue"><span class="time">[101:58]</span>or not, specialized models?</p>
    <p class="cue"><span class="time">[102:00]</span>In general, it is a good idea to do data augmentation</p>
    <p class="cue"><span class="time">[102:04]</span>to use synthetic data.</p>
    <p class="cue"><span class="time">[102:05]</span>Although I would always watch the token frequency, meaning you</p>
    <p class="cue"><span class="time">[102:10]</span>can&#x27;t because synthetic data is way cheaper.</p>
    <p class="cue"><span class="time">[102:13]</span>And so if you actually generate some synthetic data</p>
    <p class="cue"><span class="time">[102:16]</span>of a certain data domain, and then it impedes on the rest</p>
    <p class="cue"><span class="time">[102:19]</span>and lowers the performance on the rest because the model just</p>
    <p class="cue"><span class="time">[102:22]</span>is always trained on that synthetic data,</p>
    <p class="cue"><span class="time">[102:24]</span>then that&#x27;s a problem.</p>
    <p class="cue"><span class="time">[102:25]</span>In practice, I think also the returns of synthetic data</p>
    <p class="cue"><span class="time">[102:28]</span>might be plateauing at some point.</p>
    <p class="cue"><span class="time">[102:32]</span>The recent news, I guess, and if you look at the DeepMind paper,</p>
    <p class="cue"><span class="time">[102:38]</span>it&#x27;s probably that we&#x27;re lacking high quality data more</p>
    <p class="cue"><span class="time">[102:41]</span>than we&#x27;re lacking synthetic data for most domains right now.</p>
    <p class="cue"><span class="time">[102:44]</span>But who knows if it&#x27;s going to be the case.</p>
    <p class="cue"><span class="time">[102:46]</span>Some other people would say what we&#x27;re actually</p>
    <p class="cue"><span class="time">[102:49]</span>lacking is letting these agents play in RL environments</p>
    <p class="cue"><span class="time">[102:52]</span>in the wild and generate their own synthetic data or real data</p>
    <p class="cue"><span class="time">[102:57]</span>but part of a game.</p>
    <p class="cue"><span class="time">[102:59]</span>Nobody has quite the answer.</p>
    <p class="cue"><span class="time">[103:00]</span>I would just say the trend has gone from--</p>
    <p class="cue"><span class="time">[103:04]</span>Actually you should look at a paper from Epoch AI.</p>
    <p class="cue"><span class="time">[103:07]</span>Maybe you&#x27;ve seen that already.</p>
    <p class="cue"><span class="time">[103:09]</span>But Epoch AI has a really nice research report which says by--</p>
    <p class="cue"><span class="time">[103:14]</span>I forgot the exact numbers, but it&#x27;s in there.</p>
    <p class="cue"><span class="time">[103:16]</span>By 2025, the frontier labs would have exhausted low quality</p>
    <p class="cue"><span class="time">[103:23]</span>data available online in texts.</p>
    <p class="cue"><span class="time">[103:27]</span>By 2027, low quality data in audio, image, and video</p>
    <p class="cue"><span class="time">[103:30]</span>would have been exhausted.</p>
    <p class="cue"><span class="time">[103:32]</span>By 2030, high quality data would also have been exhausted.</p>
    <p class="cue"><span class="time">[103:35]</span>And at that point it&#x27;s like, what&#x27;s next?</p>
    <p class="cue"><span class="time">[103:37]</span>Probably by that time, data is not</p>
    <p class="cue"><span class="time">[103:41]</span>going to be the bottleneck anymore.</p>
    <p class="cue"><span class="time">[103:43]</span>And it&#x27;s going to be more about model architecture, potentially.</p>
    <p class="cue"><span class="time">[103:52]</span>Are we producing more data than we&#x27;re using to train the models?</p>
    <p class="cue"><span class="time">[103:56]</span>Are we producing more data than we&#x27;re using?</p>
    <p class="cue"><span class="time">[103:59]</span>Probably, yes.</p>
    <p class="cue"><span class="time">[104:00]</span>But it doesn&#x27;t mean the models are not plateauing.</p>
    <p class="cue"><span class="time">[104:05]</span>You go and you code in Python.</p>
    <p class="cue"><span class="time">[104:07]</span>Your Python code is going to be already online somewhere,</p>
    <p class="cue"><span class="time">[104:11]</span>most likely, or 99% of it.</p>
    <p class="cue"><span class="time">[104:13]</span>So the model is actually not learning that much from it.</p>
    <p class="cue"><span class="time">[104:16]</span>It&#x27;s just more data, not higher quality data.</p>
    <p class="cue"><span class="time">[104:19]</span>And that&#x27;s why I think the plateau is there.</p>
    <p class="cue"><span class="time">[104:21]</span>Maybe the best radiologist in the world</p>
    <p class="cue"><span class="time">[104:24]</span>is producing a research paper that</p>
    <p class="cue"><span class="time">[104:26]</span>is so unique that it&#x27;s high quality by definition</p>
    <p class="cue"><span class="time">[104:30]</span>of what the models feel is high quality today.</p>
    <p class="cue"><span class="time">[104:32]</span>But how much of that can we expect?</p>
    <p class="cue"><span class="time">[104:35]</span>Is there a risk that the model gives training</p>
    <p class="cue"><span class="time">[104:38]</span>on data information [INAUDIBLE] and that data is probably</p>
    <p class="cue"><span class="time">[104:43]</span>a bad idea to train on this thing [INAUDIBLE]</p>
    <p class="cue"><span class="time">[104:46]</span>we produce for what.</p>
    <p class="cue"><span class="time">[104:48]</span>What would that [INAUDIBLE]</p>
    <p class="cue"><span class="time">[104:50]</span>Yeah, it&#x27;s risky.</p>
    <p class="cue"><span class="time">[104:51]</span>Is it risky for the model to-- the model,</p>
    <p class="cue"><span class="time">[104:54]</span>let&#x27;s say is online learning, so it&#x27;s</p>
    <p class="cue"><span class="time">[104:55]</span>learning from new data being produced by everyone.</p>
    <p class="cue"><span class="time">[104:58]</span>Is that going to risk the model performance to drop?</p>
    <p class="cue"><span class="time">[105:03]</span>Essentially, that&#x27;s what you&#x27;re asking?</p>
    <p class="cue"><span class="time">[105:04]</span>[INAUDIBLE] anyone at the end of the day</p>
    <p class="cue"><span class="time">[105:07]</span>is also [INAUDIBLE] because most people have used data.</p>
    <p class="cue"><span class="time">[105:11]</span>Yeah, yeah.</p>
    <p class="cue"><span class="time">[105:11]</span>In that case, yeah.</p>
    <p class="cue"><span class="time">[105:13]</span>Yeah, the data produced is also coming out of AI.</p>
    <p class="cue"><span class="time">[105:15]</span>Yeah, for sure, more today than before.</p>
    <p class="cue"><span class="time">[105:17]</span>Coding data today is increasingly generated.</p>
    <p class="cue"><span class="time">[105:25]</span>And so it&#x27;s just fed back.</p>
    <p class="cue"><span class="time">[105:27]</span>So just long story short, it&#x27;s not</p>
    <p class="cue"><span class="time">[105:28]</span>that interesting for training.</p>
    <p class="cue"><span class="time">[105:37]</span>Super.</p>
    <p class="cue"><span class="time">[105:38]</span>So closing remarks and reminder on what&#x27;s next.</p>
    <p class="cue"><span class="time">[105:43]</span>So by the way, I hope you feel after this lecture</p>
    <p class="cue"><span class="time">[105:45]</span>that you have a better understanding of the techniques</p>
    <p class="cue"><span class="time">[105:48]</span>that you can use in order to look inside a model,</p>
    <p class="cue"><span class="time">[105:50]</span>look outside the model, both for CNNs and for frontier models.</p>
    <p class="cue"><span class="time">[105:55]</span>Again, it&#x27;s just a two-hour lecture.</p>
    <p class="cue"><span class="time">[105:58]</span>We don&#x27;t have time to go so deep as much as I would like it</p>
    <p class="cue"><span class="time">[106:01]</span>in each of these domains.</p>
    <p class="cue"><span class="time">[106:04]</span>It&#x27;s my last lecture this quarter</p>
    <p class="cue"><span class="time">[106:08]</span>and so thank you for participating.</p>
    <p class="cue"><span class="time">[106:10]</span>I enjoyed spending time with you all.</p>
    <p class="cue"><span class="time">[106:14]</span>I hope you spend time on your projects.</p>
    <p class="cue"><span class="time">[106:17]</span>Projects can be very delightful in CS230.</p>
    <p class="cue"><span class="time">[106:20]</span>Over the years, I&#x27;ve seen people use their products to get a job,</p>
    <p class="cue"><span class="time">[106:24]</span>to start a company, to make friends.</p>
    <p class="cue"><span class="time">[106:27]</span>And so I don&#x27;t think you will regret</p>
    <p class="cue"><span class="time">[106:29]</span>putting time and effort into your projects,</p>
    <p class="cue"><span class="time">[106:32]</span>even if we don&#x27;t have too much time left.</p>
    <p class="cue"><span class="time">[106:34]</span>Those are the last milestones or deliverables for the class.</p>
    <p class="cue"><span class="time">[106:40]</span>I hope you enjoyed the class.</p>
    <p class="cue"><span class="time">[106:41]</span>We&#x27;re always looking for feedback.</p>
    <p class="cue"><span class="time">[106:44]</span>And so I&#x27;m eager to hear from you all.</p>
    <p class="cue"><span class="time">[106:46]</span>Thank you.</p>
  </section>
</article>
</body>
</html>
