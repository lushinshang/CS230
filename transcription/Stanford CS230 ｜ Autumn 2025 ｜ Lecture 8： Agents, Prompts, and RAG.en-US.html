<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Stanford CS230 ｜ Autumn 2025 ｜ Lecture 8： Agents, Prompts, and RAG.en-US.html</title>
  <style>
    body{font-family:Inter, system-ui, -apple-system, Arial, sans-serif;line-height:1.6;padding:1rem;max-width:900px;margin:0 auto;color:#111}
    .meta{color:#666;font-size:0.95rem;margin-bottom:0.5rem}
    article{background:#fff;border-radius:8px;padding:1rem 1.2rem;box-shadow:0 6px 18px rgba(10,20,30,0.05)}
    p.cue{margin:0 0 0.6rem}
    span.time{color:#666;margin-right:8px;font-size:0.95rem}
  </style>
</head>
<body>
<article lang="en">
  <header>
    <h1>Stanford CS230 ｜ Autumn 2025 ｜ Lecture 8： Agents, Prompts, and RAG</h1>
    <p class="meta">Source: Stanford CS230 ｜ Autumn 2025 ｜ Lecture 8： Agents, Prompts, and RAG.en-US.srt</p>
  </header>
  <section class="transcript">
    <p class="cue"><span class="time">[00:05]</span>Hi, everyone.</p>
    <p class="cue"><span class="time">[00:06]</span>Welcome to another lecture for CS230 Deep Learning.</p>
    <p class="cue"><span class="time">[00:11]</span>Today, we&#x27;re going to talk about enhancing large language model</p>
    <p class="cue"><span class="time">[00:17]</span>applications.</p>
    <p class="cue"><span class="time">[00:19]</span>And I call this lecture Beyond LLM.</p>
    <p class="cue"><span class="time">[00:23]</span>It has a lot of newer content.</p>
    <p class="cue"><span class="time">[00:26]</span>And the idea behind this lecture is</p>
    <p class="cue"><span class="time">[00:31]</span>we started to learn about neurons,</p>
    <p class="cue"><span class="time">[00:34]</span>and then we learned about layers,</p>
    <p class="cue"><span class="time">[00:35]</span>and then we learned about deep neural networks,</p>
    <p class="cue"><span class="time">[00:38]</span>and then we learned a little bit about how to structure projects</p>
    <p class="cue"><span class="time">[00:43]</span>in C3.</p>
    <p class="cue"><span class="time">[00:44]</span>And now we&#x27;re going one level beyond into, what would it</p>
    <p class="cue"><span class="time">[00:48]</span>look if you were building agentic AI systems at work,</p>
    <p class="cue"><span class="time">[00:54]</span>in a startup, in a company?</p>
    <p class="cue"><span class="time">[00:58]</span>And it&#x27;s probably one of the more practical lectures.</p>
    <p class="cue"><span class="time">[01:02]</span>Again, the goal is not to build a product</p>
    <p class="cue"><span class="time">[01:05]</span>end to end in the next hour or so,</p>
    <p class="cue"><span class="time">[01:07]</span>but rather to tell you all the techniques</p>
    <p class="cue"><span class="time">[01:09]</span>that AI engineers have cracked, figured out, are exploring,</p>
    <p class="cue"><span class="time">[01:15]</span>so that after the class, you have the breadth of view</p>
    <p class="cue"><span class="time">[01:18]</span>of different prompting techniques,</p>
    <p class="cue"><span class="time">[01:20]</span>different agentic workflows, multi-agent systems, evals.</p>
    <p class="cue"><span class="time">[01:25]</span>And then when you want to dive deeper,</p>
    <p class="cue"><span class="time">[01:26]</span>you have the baggage to dive deeper and learn faster</p>
    <p class="cue"><span class="time">[01:29]</span>about it.</p>
    <p class="cue"><span class="time">[01:32]</span>Let&#x27;s try to make it as interactive as possible, as</p>
    <p class="cue"><span class="time">[01:36]</span>usual.</p>
    <p class="cue"><span class="time">[01:37]</span>When we look at the agenda, the agenda</p>
    <p class="cue"><span class="time">[01:40]</span>is going to start with the core idea behind challenges</p>
    <p class="cue"><span class="time">[01:45]</span>and opportunities for augmenting LLMs.</p>
    <p class="cue"><span class="time">[01:48]</span>So we start from a base model.</p>
    <p class="cue"><span class="time">[01:50]</span>How do we maximize the performance of that base model?</p>
    <p class="cue"><span class="time">[01:55]</span>Then we&#x27;ll dive deep into the first line of optimization,</p>
    <p class="cue"><span class="time">[01:59]</span>which is prompting methods, and we&#x27;ll see a variety of them.</p>
    <p class="cue"><span class="time">[02:02]</span>Then we&#x27;ll go slightly deeper.</p>
    <p class="cue"><span class="time">[02:04]</span>If we were to get our hands under the hood</p>
    <p class="cue"><span class="time">[02:06]</span>and do some fine tuning, what would it look like?</p>
    <p class="cue"><span class="time">[02:09]</span>I&#x27;m not a fan of fine tuning, and I talk a lot about that,</p>
    <p class="cue"><span class="time">[02:12]</span>but I&#x27;ll explain why I try to avoid fine tuning as much as</p>
    <p class="cue"><span class="time">[02:16]</span>possible.</p>
    <p class="cue"><span class="time">[02:18]</span>And then we&#x27;ll do a section 4 on Retrieval-Augmented Generation,</p>
    <p class="cue"><span class="time">[02:22]</span>or RAG, which you&#x27;ve probably heard of in the news.</p>
    <p class="cue"><span class="time">[02:26]</span>Maybe some of you have played with RAGs.</p>
    <p class="cue"><span class="time">[02:28]</span>We&#x27;re going to unpack what a RAG is</p>
    <p class="cue"><span class="time">[02:31]</span>and how it works and then the different methods within RAGs.</p>
    <p class="cue"><span class="time">[02:36]</span>And then we&#x27;ll talk about agentic AI workflows.</p>
    <p class="cue"><span class="time">[02:40]</span>I&#x27;ll define it.</p>
    <p class="cue"><span class="time">[02:42]</span>Andrew Ng is one of the first ones</p>
    <p class="cue"><span class="time">[02:45]</span>to have called this trend agenetic AI workflows.</p>
    <p class="cue"><span class="time">[02:49]</span>And so we look at the definition that Andrew</p>
    <p class="cue"><span class="time">[02:51]</span>gives to agentic workflows, and then we&#x27;ll</p>
    <p class="cue"><span class="time">[02:54]</span>start seeing examples.</p>
    <p class="cue"><span class="time">[02:56]</span>The section 6 is very practical.</p>
    <p class="cue"><span class="time">[02:59]</span>It&#x27;s a case study where we will think about an agentic workflow,</p>
    <p class="cue"><span class="time">[03:05]</span>and I&#x27;ll ask you to measure if the agent actually works,</p>
    <p class="cue"><span class="time">[03:10]</span>and we brainstorm how we can measure</p>
    <p class="cue"><span class="time">[03:13]</span>if an agentic workflow is working</p>
    <p class="cue"><span class="time">[03:15]</span>the way you want it to work.</p>
    <p class="cue"><span class="time">[03:16]</span>There&#x27;s plenty of methods called evals that solve that problem.</p>
    <p class="cue"><span class="time">[03:22]</span>And then we&#x27;ll look briefly at multi-agent workflow.</p>
    <p class="cue"><span class="time">[03:24]</span>And then we can have a open-ended discussion</p>
    <p class="cue"><span class="time">[03:27]</span>where I share some thoughts on what&#x27;s next in AI.</p>
    <p class="cue"><span class="time">[03:31]</span>And I&#x27;m looking forward to hearing from you all,</p>
    <p class="cue"><span class="time">[03:34]</span>as well, on that one.</p>
    <p class="cue"><span class="time">[03:36]</span>So let&#x27;s get started with the problem of augmenting LLMs.</p>
    <p class="cue"><span class="time">[03:42]</span>So open-ended question for you--</p>
    <p class="cue"><span class="time">[03:44]</span>you are all familiar with pre-trained models</p>
    <p class="cue"><span class="time">[03:47]</span>like GPT 3.5 Turbo or GPT 4.0.</p>
    <p class="cue"><span class="time">[03:52]</span>What&#x27;s the limitation of using just a base model?</p>
    <p class="cue"><span class="time">[03:56]</span>What are the typical issues that might</p>
    <p class="cue"><span class="time">[03:59]</span>arise as you&#x27;re using a vanilla pre-trained model?</p>
    <p class="cue"><span class="time">[04:07]</span>Yes.</p>
    <p class="cue"><span class="time">[04:08]</span>It lacks some domain knowledge.</p>
    <p class="cue"><span class="time">[04:10]</span>Lacks some domain knowledge.</p>
    <p class="cue"><span class="time">[04:11]</span>You&#x27;re perfectly right.</p>
    <p class="cue"><span class="time">[04:13]</span>We had a group of students a few years ago.</p>
    <p class="cue"><span class="time">[04:16]</span>It was not LLM related, but they were building an autonomous</p>
    <p class="cue"><span class="time">[04:22]</span>farming device or vehicle that had a camera underneath, taking</p>
    <p class="cue"><span class="time">[04:26]</span>pictures of crops to determine if the crop is</p>
    <p class="cue"><span class="time">[04:30]</span>sick or not, if it should be thrown away,</p>
    <p class="cue"><span class="time">[04:32]</span>if it should be used or not.</p>
    <p class="cue"><span class="time">[04:35]</span>And that data set is not a data set you find out there.</p>
    <p class="cue"><span class="time">[04:40]</span>And the base model or pre-trained computer vision</p>
    <p class="cue"><span class="time">[04:44]</span>model would lack that knowledge, of course.</p>
    <p class="cue"><span class="time">[04:47]</span>What else?</p>
    <p class="cue"><span class="time">[04:49]</span>Yes.</p>
    <p class="cue"><span class="time">[04:50]</span>[INAUDIBLE] pictures are very dark [INAUDIBLE]</p>
    <p class="cue"><span class="time">[04:57]</span>OK, maybe the-- you&#x27;re saying--</p>
    <p class="cue"><span class="time">[04:59]</span>so just to repeat for people online,</p>
    <p class="cue"><span class="time">[05:02]</span>you&#x27;re saying the model might have been trained</p>
    <p class="cue"><span class="time">[05:04]</span>on high-quality data, but the data in the wild</p>
    <p class="cue"><span class="time">[05:06]</span>is actually not that high quality.</p>
    <p class="cue"><span class="time">[05:08]</span>And in fact, yes, the distribution of the real world</p>
    <p class="cue"><span class="time">[05:11]</span>might differ, as we&#x27;ve seen with GANs, from the training set,</p>
    <p class="cue"><span class="time">[05:16]</span>and that might create an issue with pre-trained models.</p>
    <p class="cue"><span class="time">[05:18]</span>Although pre-trained LLMs are getting better</p>
    <p class="cue"><span class="time">[05:20]</span>at handling all sorts of data inputs.</p>
    <p class="cue"><span class="time">[05:25]</span>Yes.</p>
    <p class="cue"><span class="time">[05:26]</span>Lacks current information.</p>
    <p class="cue"><span class="time">[05:28]</span>Lack what?</p>
    <p class="cue"><span class="time">[05:28]</span>Current information.</p>
    <p class="cue"><span class="time">[05:30]</span>Lacks current information.</p>
    <p class="cue"><span class="time">[05:32]</span>The LLM is not up to date.</p>
    <p class="cue"><span class="time">[05:34]</span>And in fact, you&#x27;re right.</p>
    <p class="cue"><span class="time">[05:35]</span>Imagine you have to retrain from scratch your LLM</p>
    <p class="cue"><span class="time">[05:38]</span>every couple of months.</p>
    <p class="cue"><span class="time">[05:39]</span>One story that I found funny--</p>
    <p class="cue"><span class="time">[05:42]</span>it&#x27;s from probably three years ago or maybe more five years</p>
    <p class="cue"><span class="time">[05:45]</span>ago, where during his first presidency,</p>
    <p class="cue"><span class="time">[05:49]</span>President Trump one day tweeted, &quot;Covfefe.&quot;</p>
    <p class="cue"><span class="time">[05:53]</span>You remember that tweet or no?</p>
    <p class="cue"><span class="time">[05:56]</span>Just &quot;Covfefe.&quot;</p>
    <p class="cue"><span class="time">[05:57]</span>And it was probably a typo or it was in his pocket.</p>
    <p class="cue"><span class="time">[05:59]</span>I don&#x27;t know.</p>
    <p class="cue"><span class="time">[06:00]</span>But that word did not exist.</p>
    <p class="cue"><span class="time">[06:03]</span>The LLMs, in fact, that Twitter was running at the time</p>
    <p class="cue"><span class="time">[06:06]</span>could not recognize that word.</p>
    <p class="cue"><span class="time">[06:08]</span>And so the recommender system sort of went wild,</p>
    <p class="cue"><span class="time">[06:11]</span>because suddenly everybody was making fun of that tweet using</p>
    <p class="cue"><span class="time">[06:15]</span>the word &quot;Covfefe,&quot; and the LLM was so confused on, what does</p>
    <p class="cue"><span class="time">[06:19]</span>that mean?</p>
    <p class="cue"><span class="time">[06:20]</span>Where should we show it?</p>
    <p class="cue"><span class="time">[06:21]</span>To whom should we show it?</p>
    <p class="cue"><span class="time">[06:22]</span>And this is an example of a-- nowadays,</p>
    <p class="cue"><span class="time">[06:25]</span>especially on social media, there&#x27;s so many new trends,</p>
    <p class="cue"><span class="time">[06:28]</span>and it&#x27;s very hard to retrain an LLM to match the new trend</p>
    <p class="cue"><span class="time">[06:33]</span>and understand the new words out there.</p>
    <p class="cue"><span class="time">[06:34]</span>I mean, you oftentimes hear Gen Z words like &quot;rizz&quot; or &quot;mid&quot;</p>
    <p class="cue"><span class="time">[06:39]</span>or whatever.</p>
    <p class="cue"><span class="time">[06:40]</span>I don&#x27;t know all of them.</p>
    <p class="cue"><span class="time">[06:41]</span>But you probably want to find a way that</p>
    <p class="cue"><span class="time">[06:45]</span>can allow the LLM to understand those trends without retraining</p>
    <p class="cue"><span class="time">[06:49]</span>the LLM from scratch.</p>
    <p class="cue"><span class="time">[06:51]</span>What else?</p>
    <p class="cue"><span class="time">[06:53]</span>It&#x27;s trained to have a breadth of knowledge.</p>
    <p class="cue"><span class="time">[06:56]</span>And if you wanted to do something specialized,</p>
    <p class="cue"><span class="time">[06:58]</span>that might limit [INAUDIBLE].</p>
    <p class="cue"><span class="time">[06:59]</span>Yeah, it might be trained on a breadth of knowledge,</p>
    <p class="cue"><span class="time">[07:02]</span>but it might fail or not perform adequately</p>
    <p class="cue"><span class="time">[07:05]</span>on a narrow task that is very well defined.</p>
    <p class="cue"><span class="time">[07:09]</span>Think about enterprise applications that--</p>
    <p class="cue"><span class="time">[07:11]</span>yeah, enterprise application.</p>
    <p class="cue"><span class="time">[07:13]</span>You need high precision, high fidelity, low latency.</p>
    <p class="cue"><span class="time">[07:17]</span>And maybe the model is not great at that specific thing.</p>
    <p class="cue"><span class="time">[07:20]</span>It might do fine, but just not good enough.</p>
    <p class="cue"><span class="time">[07:22]</span>And you might want to augment it in a certain way.</p>
    <p class="cue"><span class="time">[07:24]</span>Yeah.</p>
    <p class="cue"><span class="time">[07:25]</span>Maybe it has [INAUDIBLE] so it makes the model</p>
    <p class="cue"><span class="time">[07:29]</span>a lot heavier, a lot slower.</p>
    <p class="cue"><span class="time">[07:32]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[07:33]</span>So maybe it has a lot of broad domain knowledge that might not</p>
    <p class="cue"><span class="time">[07:37]</span>be needed for your application.</p>
    <p class="cue"><span class="time">[07:39]</span>And so you&#x27;re using a massive, heavy model</p>
    <p class="cue"><span class="time">[07:41]</span>when you actually are only using 2% of the model capability.</p>
    <p class="cue"><span class="time">[07:44]</span>You&#x27;re perfectly right.</p>
    <p class="cue"><span class="time">[07:45]</span>You might not need all of it.</p>
    <p class="cue"><span class="time">[07:46]</span>So you might find ways to prune, quantize the model, modify it.</p>
    <p class="cue"><span class="time">[07:51]</span>All of these are good points.</p>
    <p class="cue"><span class="time">[07:53]</span>I&#x27;m going to add a few more, as well.</p>
    <p class="cue"><span class="time">[07:55]</span>LLMs are very difficult to control.</p>
    <p class="cue"><span class="time">[07:58]</span>Your last point is actually an example of that.</p>
    <p class="cue"><span class="time">[08:00]</span>You want to control the LLM to use a part of its knowledge,</p>
    <p class="cue"><span class="time">[08:03]</span>but it&#x27;s not--</p>
    <p class="cue"><span class="time">[08:04]</span>it&#x27;s, in fact, getting confused.</p>
    <p class="cue"><span class="time">[08:06]</span>We&#x27;ve seen that in history.</p>
    <p class="cue"><span class="time">[08:08]</span>In 2016, Microsoft created a notorious Twitter</p>
    <p class="cue"><span class="time">[08:13]</span>bot that learned from users, and it quickly became a racist jerk.</p>
    <p class="cue"><span class="time">[08:18]</span>Microsoft ended up removing the bot 16 hours after launching it.</p>
    <p class="cue"><span class="time">[08:22]</span>The community was really fast at determining</p>
    <p class="cue"><span class="time">[08:25]</span>that this was a racist bot.</p>
    <p class="cue"><span class="time">[08:28]</span>And you can empathize with Microsoft in the sense</p>
    <p class="cue"><span class="time">[08:31]</span>that it is actually hard to control an LLM.</p>
    <p class="cue"><span class="time">[08:34]</span>They might have done a better job to qualify before launching,</p>
    <p class="cue"><span class="time">[08:37]</span>but it is really hard to control an LLM.</p>
    <p class="cue"><span class="time">[08:40]</span>Even more recently, this is a tweet</p>
    <p class="cue"><span class="time">[08:42]</span>from Sam Altman last November, where</p>
    <p class="cue"><span class="time">[08:46]</span>there was this debate between Elon Musk and Sam</p>
    <p class="cue"><span class="time">[08:50]</span>Altman on whose LLM is the left wing propaganda</p>
    <p class="cue"><span class="time">[08:54]</span>machine or the right wing propaganda machine,</p>
    <p class="cue"><span class="time">[08:57]</span>and they were hating on each other&#x27;s LLMs.</p>
    <p class="cue"><span class="time">[08:59]</span>But that tells you, at the end of the day,</p>
    <p class="cue"><span class="time">[09:01]</span>that even those two teams, Grok and OpenAI, which are probably</p>
    <p class="cue"><span class="time">[09:05]</span>the best funded team with a lot of talent,</p>
    <p class="cue"><span class="time">[09:08]</span>are not doing a great job at controlling their LLMs.</p>
    <p class="cue"><span class="time">[09:14]</span>And from time to time, if you hang out on X,</p>
    <p class="cue"><span class="time">[09:16]</span>you might see screenshots of users interacting with LLMs</p>
    <p class="cue"><span class="time">[09:21]</span>and the LLM saying something really controversial</p>
    <p class="cue"><span class="time">[09:24]</span>or racist or something that would not be considered great</p>
    <p class="cue"><span class="time">[09:31]</span>by social standards, I guess.</p>
    <p class="cue"><span class="time">[09:33]</span>And that tells you that the model is really hard to control.</p>
    <p class="cue"><span class="time">[09:39]</span>The second aspect of it is something</p>
    <p class="cue"><span class="time">[09:41]</span>that you mentioned earlier.</p>
    <p class="cue"><span class="time">[09:43]</span>LLMs may underperform in your task,</p>
    <p class="cue"><span class="time">[09:47]</span>and that might include specific knowledge gaps,</p>
    <p class="cue"><span class="time">[09:49]</span>such as medical diagnosis.</p>
    <p class="cue"><span class="time">[09:51]</span>If you&#x27;re doing medical diagnosis,</p>
    <p class="cue"><span class="time">[09:52]</span>you would rather have an LLM that is specialized for that</p>
    <p class="cue"><span class="time">[09:55]</span>and is great at it and, in fact, something</p>
    <p class="cue"><span class="time">[09:57]</span>that we haven&#x27;t mentioned as a group, has sources.</p>
    <p class="cue"><span class="time">[10:00]</span>So the answer is sourced specifically.</p>
    <p class="cue"><span class="time">[10:03]</span>You have a hard time believing something</p>
    <p class="cue"><span class="time">[10:05]</span>unless you have the actual source of the research that</p>
    <p class="cue"><span class="time">[10:08]</span>backs it up.</p>
    <p class="cue"><span class="time">[10:10]</span>Inconsistencies in style and format--</p>
    <p class="cue"><span class="time">[10:12]</span>so imagine you&#x27;re building a legal AI agentic workflow.</p>
    <p class="cue"><span class="time">[10:17]</span>Legal has a very specific way to write and read,</p>
    <p class="cue"><span class="time">[10:21]</span>where every word counts.</p>
    <p class="cue"><span class="time">[10:22]</span>If you&#x27;re negotiating a large contract,</p>
    <p class="cue"><span class="time">[10:25]</span>every word on that contract might mean something else</p>
    <p class="cue"><span class="time">[10:28]</span>when it comes to the court.</p>
    <p class="cue"><span class="time">[10:29]</span>And so it&#x27;s very important that you use</p>
    <p class="cue"><span class="time">[10:31]</span>an LLM that is very good at it.</p>
    <p class="cue"><span class="time">[10:34]</span>The precision matters.</p>
    <p class="cue"><span class="time">[10:35]</span>And then task-specific understanding,</p>
    <p class="cue"><span class="time">[10:38]</span>such as doing a classification on a niche field,</p>
    <p class="cue"><span class="time">[10:40]</span>here I pulled an example where-- let&#x27;s say a biotech product is</p>
    <p class="cue"><span class="time">[10:45]</span>trying to use an LLM to categorize</p>
    <p class="cue"><span class="time">[10:48]</span>user reviews into positive, neutral, or negative.</p>
    <p class="cue"><span class="time">[10:54]</span>Maybe for that company, something</p>
    <p class="cue"><span class="time">[10:56]</span>that would be considered a negative review typically</p>
    <p class="cue"><span class="time">[11:01]</span>is actually considered a neutral review</p>
    <p class="cue"><span class="time">[11:04]</span>because the NPS of that industry tends</p>
    <p class="cue"><span class="time">[11:06]</span>to be way lower than other industries, let&#x27;s say.</p>
    <p class="cue"><span class="time">[11:10]</span>That&#x27;s a task-specific understanding,</p>
    <p class="cue"><span class="time">[11:12]</span>and the LLM needs to be aligned to what</p>
    <p class="cue"><span class="time">[11:14]</span>the company believes is the categorization that it wants.</p>
    <p class="cue"><span class="time">[11:17]</span>We will see an example of how to solve that problem in a second.</p>
    <p class="cue"><span class="time">[11:21]</span>And then limited context handling--</p>
    <p class="cue"><span class="time">[11:24]</span>a lot of AI applications, especially in the enterprise,</p>
    <p class="cue"><span class="time">[11:28]</span>have required data that has a lot of context.</p>
    <p class="cue"><span class="time">[11:33]</span>Just to give you a simple example,</p>
    <p class="cue"><span class="time">[11:35]</span>knowledge management is an important space</p>
    <p class="cue"><span class="time">[11:37]</span>that enterprises buy a lot of knowledge management tool.</p>
    <p class="cue"><span class="time">[11:40]</span>When you go on your drive and you have all your documents,</p>
    <p class="cue"><span class="time">[11:43]</span>ideally, you could have an LLM running on top of that drive.</p>
    <p class="cue"><span class="time">[11:47]</span>You can ask any question, and it will read immediately</p>
    <p class="cue"><span class="time">[11:50]</span>thousands of documents and answer, what was</p>
    <p class="cue"><span class="time">[11:53]</span>our Q4 performance in sales?</p>
    <p class="cue"><span class="time">[11:56]</span>It was x dollars.</p>
    <p class="cue"><span class="time">[11:58]</span>It finds it super quickly.</p>
    <p class="cue"><span class="time">[11:59]</span>In practice, because LLMs do not have a large enough context,</p>
    <p class="cue"><span class="time">[12:04]</span>you cannot use a standalone vanilla pre-trained LLM to solve</p>
    <p class="cue"><span class="time">[12:07]</span>that problem.</p>
    <p class="cue"><span class="time">[12:08]</span>You will have to augment it.</p>
    <p class="cue"><span class="time">[12:11]</span>Does that make sense?</p>
    <p class="cue"><span class="time">[12:13]</span>The other aspect around context windows is they are, in fact,</p>
    <p class="cue"><span class="time">[12:16]</span>limited.</p>
    <p class="cue"><span class="time">[12:17]</span>If you look at the context windows of the models</p>
    <p class="cue"><span class="time">[12:20]</span>from the last five years, even the best models</p>
    <p class="cue"><span class="time">[12:25]</span>today will range in context, window, or number of tokens</p>
    <p class="cue"><span class="time">[12:30]</span>it can take as input, somewhere in the hundreds of thousands</p>
    <p class="cue"><span class="time">[12:35]</span>of tokens max.</p>
    <p class="cue"><span class="time">[12:36]</span>Just to give you a sense, 200,000 tokens is roughly two</p>
    <p class="cue"><span class="time">[12:40]</span>books.</p>
    <p class="cue"><span class="time">[12:42]</span>So that&#x27;s how much you can upload</p>
    <p class="cue"><span class="time">[12:45]</span>and it can read, pretty much.</p>
    <p class="cue"><span class="time">[12:47]</span>And you can imagine that when you&#x27;re</p>
    <p class="cue"><span class="time">[12:48]</span>dealing with video understanding or heavier data</p>
    <p class="cue"><span class="time">[12:52]</span>files, that is, of course, an issue.</p>
    <p class="cue"><span class="time">[12:56]</span>So you might have to chunk it.</p>
    <p class="cue"><span class="time">[12:58]</span>You might have to embed it.</p>
    <p class="cue"><span class="time">[12:59]</span>You might have to find other ways</p>
    <p class="cue"><span class="time">[13:00]</span>to get the LLM to handle larger contexts.</p>
    <p class="cue"><span class="time">[13:06]</span>The attention mechanism is also powerful, but problematic,</p>
    <p class="cue"><span class="time">[13:10]</span>because it does not do a great job at attending</p>
    <p class="cue"><span class="time">[13:13]</span>in very large contexts.</p>
    <p class="cue"><span class="time">[13:16]</span>There is actually an interesting problem</p>
    <p class="cue"><span class="time">[13:19]</span>called needle in a haystack.</p>
    <p class="cue"><span class="time">[13:21]</span>It&#x27;s an AI problem where--</p>
    <p class="cue"><span class="time">[13:23]</span>or call it a benchmark--</p>
    <p class="cue"><span class="time">[13:25]</span>where, in order to test if your LLM is good at putting attention</p>
    <p class="cue"><span class="time">[13:30]</span>on a very specific fact within a large corpus,</p>
    <p class="cue"><span class="time">[13:35]</span>researchers might randomly insert</p>
    <p class="cue"><span class="time">[13:38]</span>in about one sentence that outlines</p>
    <p class="cue"><span class="time">[13:44]</span>a certain fact, such as Arun and Max</p>
    <p class="cue"><span class="time">[13:47]</span>are having coffee at Blue Bottle,</p>
    <p class="cue"><span class="time">[13:48]</span>in the middle of the Bible, let&#x27;s say,</p>
    <p class="cue"><span class="time">[13:51]</span>or some very long text.</p>
    <p class="cue"><span class="time">[13:54]</span>And then you ask the LLM, what were Arun and Max having</p>
    <p class="cue"><span class="time">[14:01]</span>at Blue Bottle?</p>
    <p class="cue"><span class="time">[14:02]</span>And you see if it remembers that it was coffee.</p>
    <p class="cue"><span class="time">[14:04]</span>It&#x27;s actually a complex problem, not because the question</p>
    <p class="cue"><span class="time">[14:07]</span>is complex, but because you&#x27;re asking the model</p>
    <p class="cue"><span class="time">[14:09]</span>to find a fact within a very large corpus,</p>
    <p class="cue"><span class="time">[14:12]</span>and that&#x27;s complicated.</p>
    <p class="cue"><span class="time">[14:16]</span>So, again, this is a limiting factor for LLMs.</p>
    <p class="cue"><span class="time">[14:19]</span>We&#x27;ll talk about RAG in a second.</p>
    <p class="cue"><span class="time">[14:21]</span>But I want to preview--</p>
    <p class="cue"><span class="time">[14:22]</span>there is debates around whether RAG</p>
    <p class="cue"><span class="time">[14:26]</span>is the right long-term approach for AI systems.</p>
    <p class="cue"><span class="time">[14:29]</span>So as a high-level idea, a RAG is a mechanism, if you will,</p>
    <p class="cue"><span class="time">[14:34]</span>that embeds documents that an LLM can retrieve and then</p>
    <p class="cue"><span class="time">[14:39]</span>add as context to its initial prompt and answer a question.</p>
    <p class="cue"><span class="time">[14:44]</span>It has lots of application.</p>
    <p class="cue"><span class="time">[14:45]</span>Knowledge management is an example.</p>
    <p class="cue"><span class="time">[14:47]</span>So imagine you have your drive again.</p>
    <p class="cue"><span class="time">[14:49]</span>But every document is compressed in representation,</p>
    <p class="cue"><span class="time">[14:53]</span>and the LLM has access to that lower</p>
    <p class="cue"><span class="time">[14:55]</span>dimensional representation.</p>
    <p class="cue"><span class="time">[14:59]</span>The debates that this tweet from [INAUDIBLE] outlines</p>
    <p class="cue"><span class="time">[15:03]</span>is, in theory, if we have infinite compute,</p>
    <p class="cue"><span class="time">[15:08]</span>then RAG is useless.</p>
    <p class="cue"><span class="time">[15:09]</span>Because you can just read a massive corpus immediately</p>
    <p class="cue"><span class="time">[15:13]</span>and answer your question.</p>
    <p class="cue"><span class="time">[15:15]</span>But even in that case, latency might be an issue.</p>
    <p class="cue"><span class="time">[15:19]</span>Imagine the time it takes for an AI</p>
    <p class="cue"><span class="time">[15:20]</span>to read all your drive every single time you ask a question.</p>
    <p class="cue"><span class="time">[15:24]</span>It doesn&#x27;t make sense.</p>
    <p class="cue"><span class="time">[15:25]</span>So RAG has other advantages beyond even the accuracy.</p>
    <p class="cue"><span class="time">[15:30]</span>On top of that, the sourcing matters, as well.</p>
    <p class="cue"><span class="time">[15:33]</span>So it might-- RAG allows you to source.</p>
    <p class="cue"><span class="time">[15:35]</span>We&#x27;ll talk about all that later.</p>
    <p class="cue"><span class="time">[15:38]</span>But there&#x27;s always this debate in the community</p>
    <p class="cue"><span class="time">[15:42]</span>whether a certain method is actually future proof.</p>
    <p class="cue"><span class="time">[15:46]</span>Because in practice, as compute power doubles every year,</p>
    <p class="cue"><span class="time">[15:49]</span>let&#x27;s say, some of the methods we&#x27;re learning right now</p>
    <p class="cue"><span class="time">[15:52]</span>might not be relevant three years from now.</p>
    <p class="cue"><span class="time">[15:54]</span>We don&#x27;t know, essentially.</p>
    <p class="cue"><span class="time">[15:59]</span>And the analogy that he makes on context windows</p>
    <p class="cue"><span class="time">[16:04]</span>and why RAG approaches might be relevant even a long time</p>
    <p class="cue"><span class="time">[16:07]</span>from now is search.</p>
    <p class="cue"><span class="time">[16:09]</span>When you search on a search engine,</p>
    <p class="cue"><span class="time">[16:12]</span>you still find sources of information.</p>
    <p class="cue"><span class="time">[16:14]</span>And in fact, in the background, there</p>
    <p class="cue"><span class="time">[16:16]</span>is very detailed traversal algorithms</p>
    <p class="cue"><span class="time">[16:20]</span>that rank and find the specific links that might be the best</p>
    <p class="cue"><span class="time">[16:25]</span>to present you versus if you had to read-- imagine you had</p>
    <p class="cue"><span class="time">[16:29]</span>to read the entire web every single time you&#x27;re doing</p>
    <p class="cue"><span class="time">[16:31]</span>a search query, without being able to narrow</p>
    <p class="cue"><span class="time">[16:34]</span>to a certain portion of the space.</p>
    <p class="cue"><span class="time">[16:36]</span>That might, again, not be reasonable.</p>
    <p class="cue"><span class="time">[16:41]</span>OK, when we&#x27;re thinking of improving LLMs,</p>
    <p class="cue"><span class="time">[16:46]</span>the easiest way we think of it is two dimensions.</p>
    <p class="cue"><span class="time">[16:50]</span>One dimension is we are going to improve the foundation</p>
    <p class="cue"><span class="time">[16:53]</span>model itself.</p>
    <p class="cue"><span class="time">[16:54]</span>So, for example, we move from GPT 3.5 Turbo, to GPT 4,</p>
    <p class="cue"><span class="time">[17:01]</span>to GPT 4.0, to GPT 5.</p>
    <p class="cue"><span class="time">[17:04]</span>Each of that is supposed to improve the base model.</p>
    <p class="cue"><span class="time">[17:07]</span>GPT 5 is another debate because it&#x27;s packaging other models</p>
    <p class="cue"><span class="time">[17:11]</span>within itself.</p>
    <p class="cue"><span class="time">[17:12]</span>But if you&#x27;re thinking about 3.5, 4, and 4.0,</p>
    <p class="cue"><span class="time">[17:15]</span>that&#x27;s really what it is.</p>
    <p class="cue"><span class="time">[17:16]</span>The pre-trained model improves.</p>
    <p class="cue"><span class="time">[17:18]</span>And so you should see your performance</p>
    <p class="cue"><span class="time">[17:20]</span>improve on your tasks.</p>
    <p class="cue"><span class="time">[17:22]</span>But the other dimension is we can actually engineer--</p>
    <p class="cue"><span class="time">[17:27]</span>leverage the LLM in a way that makes it better.</p>
    <p class="cue"><span class="time">[17:30]</span>So you can prompt simply GPT 4.0.</p>
    <p class="cue"><span class="time">[17:34]</span>You can change some prompts and improve the prompt,</p>
    <p class="cue"><span class="time">[17:38]</span>and it will improve the performance.</p>
    <p class="cue"><span class="time">[17:40]</span>It&#x27;s shown.</p>
    <p class="cue"><span class="time">[17:41]</span>You can even put a RAG around it.</p>
    <p class="cue"><span class="time">[17:42]</span>You can put an agentic workflow around it.</p>
    <p class="cue"><span class="time">[17:45]</span>You can even put a multi-agent system around it.</p>
    <p class="cue"><span class="time">[17:49]</span>And that is another dimension for you to improve performance.</p>
    <p class="cue"><span class="time">[17:52]</span>So that&#x27;s how I want you to think about it-- which</p>
    <p class="cue"><span class="time">[17:54]</span>LLM I&#x27;m using, and then how can I maximize</p>
    <p class="cue"><span class="time">[17:56]</span>the performance of that LLM?</p>
    <p class="cue"><span class="time">[17:59]</span>This lecture is about the vertical axis.</p>
    <p class="cue"><span class="time">[18:02]</span>Those are the methods that we will see together.</p>
    <p class="cue"><span class="time">[18:08]</span>Sounds good for the introduction.</p>
    <p class="cue"><span class="time">[18:11]</span>So let&#x27;s move to prompt engineering.</p>
    <p class="cue"><span class="time">[18:14]</span>I&#x27;m going to start with an interesting study just</p>
    <p class="cue"><span class="time">[18:17]</span>to motivate why prompt engineering matters.</p>
    <p class="cue"><span class="time">[18:20]</span>There is a study from HBS, UPenn,</p>
    <p class="cue"><span class="time">[18:26]</span>as well as Harvard Business School, and--</p>
    <p class="cue"><span class="time">[18:29]</span>well, there is also involved Wharton--</p>
    <p class="cue"><span class="time">[18:31]</span>that took a subset of BCG consultants,</p>
    <p class="cue"><span class="time">[18:34]</span>individual contributors, split them into three groups.</p>
    <p class="cue"><span class="time">[18:37]</span>One group had no access to AI.</p>
    <p class="cue"><span class="time">[18:39]</span>One group had access to--</p>
    <p class="cue"><span class="time">[18:41]</span>I think it was GPT 4.</p>
    <p class="cue"><span class="time">[18:44]</span>And then one group had access to the LLM,</p>
    <p class="cue"><span class="time">[18:46]</span>but also a training on how to prompt better.</p>
    <p class="cue"><span class="time">[18:50]</span>And then they observed the performance of these consultants</p>
    <p class="cue"><span class="time">[18:53]</span>across a wide variety of tasks.</p>
    <p class="cue"><span class="time">[18:56]</span>There&#x27;s a few things that they noticed</p>
    <p class="cue"><span class="time">[18:57]</span>that I thought was interesting.</p>
    <p class="cue"><span class="time">[18:59]</span>One is something they called the jagged frontier,</p>
    <p class="cue"><span class="time">[19:02]</span>meaning that certain tasks that consultants are doing fall</p>
    <p class="cue"><span class="time">[19:07]</span>beyond the jagged frontier, meaning AI is not good enough.</p>
    <p class="cue"><span class="time">[19:14]</span>It&#x27;s not improving human performance.</p>
    <p class="cue"><span class="time">[19:18]</span>In fact, it&#x27;s actually making it worse.</p>
    <p class="cue"><span class="time">[19:20]</span>And some tasks are within the frontier,</p>
    <p class="cue"><span class="time">[19:23]</span>meaning that AI is actually significantly improving</p>
    <p class="cue"><span class="time">[19:27]</span>the performance, the speed, the quality of the consultant.</p>
    <p class="cue"><span class="time">[19:32]</span>Many tasks fell within and many tasks fell without,</p>
    <p class="cue"><span class="time">[19:35]</span>and they shared their insights.</p>
    <p class="cue"><span class="time">[19:37]</span>But the TLDR is--</p>
    <p class="cue"><span class="time">[19:39]</span>there is a frontier within which AI is absolutely helping</p>
    <p class="cue"><span class="time">[19:42]</span>and one where they call out this behavior, or falling asleep</p>
    <p class="cue"><span class="time">[19:47]</span>at the wheel, where people relied on AI on a task that</p>
    <p class="cue"><span class="time">[19:51]</span>was beyond the frontier.</p>
    <p class="cue"><span class="time">[19:52]</span>And in fact, it ended up going worse</p>
    <p class="cue"><span class="time">[19:55]</span>because the human was not reviewing the outputs carefully</p>
    <p class="cue"><span class="time">[19:58]</span>enough.</p>
    <p class="cue"><span class="time">[20:01]</span>They did note that the group that was trained</p>
    <p class="cue"><span class="time">[20:04]</span>was the best, better than the group that was not trained</p>
    <p class="cue"><span class="time">[20:08]</span>on prompt engineering, which also motivates why</p>
    <p class="cue"><span class="time">[20:10]</span>this lecture matters, so that you&#x27;re within that group</p>
    <p class="cue"><span class="time">[20:14]</span>afterwards.</p>
    <p class="cue"><span class="time">[20:15]</span>One other insights were the centaurs and the cyborgs.</p>
    <p class="cue"><span class="time">[20:20]</span>They noticed that consultants had the tendency</p>
    <p class="cue"><span class="time">[20:22]</span>to work with AI in one of two ways,</p>
    <p class="cue"><span class="time">[20:24]</span>and you might, yourself, be part of one of these groups.</p>
    <p class="cue"><span class="time">[20:29]</span>The centaurs are mythical creatures</p>
    <p class="cue"><span class="time">[20:31]</span>that are half human, half--</p>
    <p class="cue"><span class="time">[20:35]</span>I think, half, what, horses?</p>
    <p class="cue"><span class="time">[20:38]</span>Yeah?</p>
    <p class="cue"><span class="time">[20:39]</span>Horses?</p>
    <p class="cue"><span class="time">[20:39]</span>Half horses, half something.</p>
    <p class="cue"><span class="time">[20:42]</span>And those were individuals that would divide and delegate.</p>
    <p class="cue"><span class="time">[20:45]</span>They might give a pretty big task to the AI.</p>
    <p class="cue"><span class="time">[20:48]</span>So imagine you&#x27;re working on a PowerPoint, which consultants</p>
    <p class="cue"><span class="time">[20:51]</span>are known to do.</p>
    <p class="cue"><span class="time">[20:52]</span>You might actually write a very long prompt on how</p>
    <p class="cue"><span class="time">[20:55]</span>you want it to do your PowerPoint and then let it</p>
    <p class="cue"><span class="time">[20:57]</span>work for some time and then come back</p>
    <p class="cue"><span class="time">[20:59]</span>and it&#x27;s done, when others would act as cyborgs.</p>
    <p class="cue"><span class="time">[21:02]</span>Cyborgs are fully blended, bionic human robots,</p>
    <p class="cue"><span class="time">[21:06]</span>human and robot, augmented with robotic parts.</p>
    <p class="cue"><span class="time">[21:10]</span>And those individuals will not delegate fully a task.</p>
    <p class="cue"><span class="time">[21:13]</span>They would actually work super quickly with the model</p>
    <p class="cue"><span class="time">[21:16]</span>back and forth.</p>
    <p class="cue"><span class="time">[21:17]</span>I find that a lot of students are actually more working</p>
    <p class="cue"><span class="time">[21:20]</span>like cyborgs than centaurs, but while maybe in the enterprise,</p>
    <p class="cue"><span class="time">[21:24]</span>when you&#x27;re trying to automate the workflow,</p>
    <p class="cue"><span class="time">[21:26]</span>you&#x27;re thinking more like a centaur.</p>
    <p class="cue"><span class="time">[21:29]</span>That&#x27;s just something good to keep in mind.</p>
    <p class="cue"><span class="time">[21:31]</span>Also, a lot of companies will tell you, oh, we&#x27;re</p>
    <p class="cue"><span class="time">[21:33]</span>hiring prompt engineers, et cetera.</p>
    <p class="cue"><span class="time">[21:34]</span>It&#x27;s [? a cure. ?] I don&#x27;t buy that.</p>
    <p class="cue"><span class="time">[21:36]</span>I think it&#x27;s just a skill that everybody should have.</p>
    <p class="cue"><span class="time">[21:39]</span>You&#x27;re not going to make a [? cure ?] out</p>
    <p class="cue"><span class="time">[21:40]</span>of prompt engineering, but you&#x27;re probably</p>
    <p class="cue"><span class="time">[21:42]</span>going to use it as a very powerful skill in your career.</p>
    <p class="cue"><span class="time">[21:49]</span>So let&#x27;s talk about basic prompt design principles.</p>
    <p class="cue"><span class="time">[21:52]</span>I&#x27;m giving you a very simple prompt here.</p>
    <p class="cue"><span class="time">[21:56]</span>Summarize this document, and then the document</p>
    <p class="cue"><span class="time">[21:58]</span>is uploaded alongside it.</p>
    <p class="cue"><span class="time">[22:00]</span>And the model has not much context around</p>
    <p class="cue"><span class="time">[22:04]</span>what should be the summary?</p>
    <p class="cue"><span class="time">[22:06]</span>How long should be the summary?</p>
    <p class="cue"><span class="time">[22:07]</span>What should it talk about, et cetera?</p>
    <p class="cue"><span class="time">[22:09]</span>You can actually improve these prompts by doing something like</p>
    <p class="cue"><span class="time">[22:14]</span>summarize this 10-page scientific paper on renewable</p>
    <p class="cue"><span class="time">[22:18]</span>energy in five bullet points, focusing on key findings</p>
    <p class="cue"><span class="time">[22:22]</span>and implications for policymakers.</p>
    <p class="cue"><span class="time">[22:25]</span>That&#x27;s already better.</p>
    <p class="cue"><span class="time">[22:26]</span>You&#x27;re sharing the audience, and it&#x27;s</p>
    <p class="cue"><span class="time">[22:28]</span>going to tailor it to the audience.</p>
    <p class="cue"><span class="time">[22:30]</span>You&#x27;re saying that you want five bullet points,</p>
    <p class="cue"><span class="time">[22:33]</span>and you want to focus only on key findings.</p>
    <p class="cue"><span class="time">[22:35]</span>That&#x27;s a better prompt, you would argue.</p>
    <p class="cue"><span class="time">[22:39]</span>How could you even make this prompt better?</p>
    <p class="cue"><span class="time">[22:41]</span>What are other techniques that you&#x27;ve</p>
    <p class="cue"><span class="time">[22:43]</span>heard of or tried yourself that could make this one shot prompt</p>
    <p class="cue"><span class="time">[22:47]</span>better?</p>
    <p class="cue"><span class="time">[22:53]</span>Yeah.</p>
    <p class="cue"><span class="time">[22:53]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[22:57]</span>OK.</p>
    <p class="cue"><span class="time">[22:58]</span>Right example.</p>
    <p class="cue"><span class="time">[22:58]</span>So say, you mean, here is an example of a great summary.</p>
    <p class="cue"><span class="time">[23:02]</span>Yeah.</p>
    <p class="cue"><span class="time">[23:03]</span>You&#x27;re right.</p>
    <p class="cue"><span class="time">[23:03]</span>That&#x27;s a good idea.</p>
    <p class="cue"><span class="time">[23:05]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[23:08]</span>Very popular technique.</p>
    <p class="cue"><span class="time">[23:10]</span>Act like a renewable energy expert giving a conference</p>
    <p class="cue"><span class="time">[23:15]</span>at Davos, let&#x27;s say, yeah.</p>
    <p class="cue"><span class="time">[23:17]</span>That&#x27;s great.</p>
    <p class="cue"><span class="time">[23:18]</span>Someone-- yeah.</p>
    <p class="cue"><span class="time">[23:20]</span>Say you&#x27;re really good at it.</p>
    <p class="cue"><span class="time">[23:22]</span>Yeah.</p>
    <p class="cue"><span class="time">[23:23]</span>You are the best in the world at this.</p>
    <p class="cue"><span class="time">[23:25]</span>Explain.</p>
    <p class="cue"><span class="time">[23:26]</span>Yeah.</p>
    <p class="cue"><span class="time">[23:26]</span>Actually, I mean, these things work.</p>
    <p class="cue"><span class="time">[23:28]</span>It&#x27;s funny, but it does work to say act like x, y, z.</p>
    <p class="cue"><span class="time">[23:32]</span>It&#x27;s a very popular prompt template.</p>
    <p class="cue"><span class="time">[23:34]</span>We&#x27;ll see a few examples.</p>
    <p class="cue"><span class="time">[23:36]</span>What else could you do?</p>
    <p class="cue"><span class="time">[23:40]</span>Yes.</p>
    <p class="cue"><span class="time">[23:41]</span>Of course, you&#x27;d like to critique your own model.</p>
    <p class="cue"><span class="time">[23:46]</span>Critique your own project.</p>
    <p class="cue"><span class="time">[23:47]</span>So you&#x27;re using reflection.</p>
    <p class="cue"><span class="time">[23:48]</span>So you might actually do one output</p>
    <p class="cue"><span class="time">[23:50]</span>and then ask it to critique it and then give it back.</p>
    <p class="cue"><span class="time">[23:52]</span>Yeah.</p>
    <p class="cue"><span class="time">[23:53]</span>We see that.</p>
    <p class="cue"><span class="time">[23:53]</span>That&#x27;s a great one.</p>
    <p class="cue"><span class="time">[23:54]</span>That&#x27;s the one that probably works best</p>
    <p class="cue"><span class="time">[23:56]</span>within those typically, but we see some examples.</p>
    <p class="cue"><span class="time">[23:59]</span>What else?</p>
    <p class="cue"><span class="time">[24:00]</span>Yeah.</p>
    <p class="cue"><span class="time">[24:01]</span>Break the task down into steps.</p>
    <p class="cue"><span class="time">[24:03]</span>OK.</p>
    <p class="cue"><span class="time">[24:03]</span>Break the task down into steps.</p>
    <p class="cue"><span class="time">[24:05]</span>You know how that is called?</p>
    <p class="cue"><span class="time">[24:06]</span>No.</p>
    <p class="cue"><span class="time">[24:07]</span>OK.</p>
    <p class="cue"><span class="time">[24:08]</span>Chain of thoughts.</p>
    <p class="cue"><span class="time">[24:09]</span>So this is actually a popular method</p>
    <p class="cue"><span class="time">[24:12]</span>that&#x27;s been shown in research that it improves.</p>
    <p class="cue"><span class="time">[24:15]</span>You could actually give a clear instruction</p>
    <p class="cue"><span class="time">[24:17]</span>and also encourage the model to think step</p>
    <p class="cue"><span class="time">[24:19]</span>by step approach, the task step by step,</p>
    <p class="cue"><span class="time">[24:22]</span>and do not skip any step.</p>
    <p class="cue"><span class="time">[24:24]</span>And then you give it some steps, such as step one,</p>
    <p class="cue"><span class="time">[24:26]</span>identify the three most important findings.</p>
    <p class="cue"><span class="time">[24:29]</span>Step two, explain how key each finding</p>
    <p class="cue"><span class="time">[24:31]</span>impact renewable energy policy.</p>
    <p class="cue"><span class="time">[24:33]</span>Step three, write the five-bullet summary</p>
    <p class="cue"><span class="time">[24:36]</span>with each point addressing a finding, et cetera.</p>
    <p class="cue"><span class="time">[24:39]</span>So chain of thoughts, I linked the paper from 2023 that</p>
    <p class="cue"><span class="time">[24:45]</span>popularized chain of thoughts.</p>
    <p class="cue"><span class="time">[24:46]</span>Chain of thoughts is very popular</p>
    <p class="cue"><span class="time">[24:48]</span>right now, especially in AI startups</p>
    <p class="cue"><span class="time">[24:50]</span>that are trying to control their LLMs.</p>
    <p class="cue"><span class="time">[24:55]</span>OK.</p>
    <p class="cue"><span class="time">[24:56]</span>To go back to your examples about act like XYZ, what</p>
    <p class="cue"><span class="time">[25:01]</span>I like to do, Andrew Ng also talks about that,</p>
    <p class="cue"><span class="time">[25:03]</span>is to look at other people&#x27;s prompts.</p>
    <p class="cue"><span class="time">[25:06]</span>And in fact, in online, you have a lot of prompt repositories</p>
    <p class="cue"><span class="time">[25:10]</span>for free on GitHub.</p>
    <p class="cue"><span class="time">[25:11]</span>In fact, I linked the awesome prompt template repo on GitHub,</p>
    <p class="cue"><span class="time">[25:16]</span>where you have so many examples of great prompts</p>
    <p class="cue"><span class="time">[25:19]</span>that engineers have built. They said it works great for us,</p>
    <p class="cue"><span class="time">[25:22]</span>and they published it online.</p>
    <p class="cue"><span class="time">[25:23]</span>And a lot of them start with act as.</p>
    <p class="cue"><span class="time">[25:27]</span>Act as a Linux terminal.</p>
    <p class="cue"><span class="time">[25:29]</span>Act as an English translator.</p>
    <p class="cue"><span class="time">[25:31]</span>Act like a position interviewer, et cetera.</p>
    <p class="cue"><span class="time">[25:37]</span>The advantage of a prompt template</p>
    <p class="cue"><span class="time">[25:38]</span>is that you can actually put it in your code</p>
    <p class="cue"><span class="time">[25:42]</span>and scale it for many user requests.</p>
    <p class="cue"><span class="time">[25:44]</span>So let me give you an example from Workera.</p>
    <p class="cue"><span class="time">[25:48]</span>Workera evaluates skill.</p>
    <p class="cue"><span class="time">[25:50]</span>Some of you have taken the assessments already.</p>
    <p class="cue"><span class="time">[25:52]</span>And tries to personalize it to the user.</p>
    <p class="cue"><span class="time">[25:56]</span>And in fact, if you actually read in an HR system</p>
    <p class="cue"><span class="time">[25:59]</span>in an enterprise, in the HR system,</p>
    <p class="cue"><span class="time">[26:01]</span>you might have a Jane is a product manager level 3,</p>
    <p class="cue"><span class="time">[26:06]</span>and she is in the US, and her preferred language is English.</p>
    <p class="cue"><span class="time">[26:10]</span>And actually, that metadata can be</p>
    <p class="cue"><span class="time">[26:13]</span>inserted in a prompt templates that will personalize</p>
    <p class="cue"><span class="time">[26:15]</span>personalized for Jane.</p>
    <p class="cue"><span class="time">[26:16]</span>And similarly for Joe, whose is preferred language is Spanish,</p>
    <p class="cue"><span class="time">[26:22]</span>it will tailor it to Joe.</p>
    <p class="cue"><span class="time">[26:24]</span>And that&#x27;s called a prompt template.</p>
    <p class="cue"><span class="time">[26:26]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[26:34]</span>So the question is do the foundation models</p>
    <p class="cue"><span class="time">[26:39]</span>use a prompt templates, or do you</p>
    <p class="cue"><span class="time">[26:41]</span>have to integrate it yourself?</p>
    <p class="cue"><span class="time">[26:42]</span>So the foundation models probably</p>
    <p class="cue"><span class="time">[26:45]</span>use a system prompt that you don&#x27;t see.</p>
    <p class="cue"><span class="time">[26:47]</span>Like when actually, you type on ChatGPT,</p>
    <p class="cue"><span class="time">[26:50]</span>it is possible, it&#x27;s not public, that OpenAI behind the scenes</p>
    <p class="cue"><span class="time">[26:55]</span>has like act like a very helpful assistant for this user.</p>
    <p class="cue"><span class="time">[26:59]</span>And by the way, here is your memories about the user</p>
    <p class="cue"><span class="time">[27:03]</span>that we kept in a database.</p>
    <p class="cue"><span class="time">[27:05]</span>You can actually check your memories.</p>
    <p class="cue"><span class="time">[27:07]</span>And then your prompt goes under, and then the generation starts.</p>
    <p class="cue"><span class="time">[27:10]</span>So probably, they&#x27;re using something like that.</p>
    <p class="cue"><span class="time">[27:12]</span>But it doesn&#x27;t mean you can&#x27;t add one yourself.</p>
    <p class="cue"><span class="time">[27:15]</span>So in fact, if you think about a prompt template for the Workera</p>
    <p class="cue"><span class="time">[27:19]</span>example I was showing, maybe it starts</p>
    <p class="cue"><span class="time">[27:22]</span>when you call OpenAI by act like a helpful assistant.</p>
    <p class="cue"><span class="time">[27:25]</span>And then underneath, it&#x27;s like act like a great AI mentor that</p>
    <p class="cue"><span class="time">[27:29]</span>helps people in their career.</p>
    <p class="cue"><span class="time">[27:31]</span>And OpenAI is, from template, also</p>
    <p class="cue"><span class="time">[27:33]</span>has follow the instruction from the creator</p>
    <p class="cue"><span class="time">[27:36]</span>or something like that.</p>
    <p class="cue"><span class="time">[27:37]</span>It&#x27;s possible.</p>
    <p class="cue"><span class="time">[27:41]</span>Questions about prompt templates.</p>
    <p class="cue"><span class="time">[27:42]</span>Again, I would encourage you to go and read examples of prompts.</p>
    <p class="cue"><span class="time">[27:45]</span>Some of them are quite thoughtful.</p>
    <p class="cue"><span class="time">[27:48]</span>Let&#x27;s talk about zero shot versus few shot prompting.</p>
    <p class="cue"><span class="time">[27:51]</span>It came up earlier.</p>
    <p class="cue"><span class="time">[27:53]</span>Here&#x27;s an example.</p>
    <p class="cue"><span class="time">[27:54]</span>Again, going back to the categorization of product</p>
    <p class="cue"><span class="time">[27:57]</span>reviews, let&#x27;s say that we&#x27;re working on a task</p>
    <p class="cue"><span class="time">[28:01]</span>where the prompt is classify the tone of the sentence</p>
    <p class="cue"><span class="time">[28:05]</span>as positive, negative, or neutral.</p>
    <p class="cue"><span class="time">[28:07]</span>And then you paste the review, which is the product is fine,</p>
    <p class="cue"><span class="time">[28:12]</span>but I was expecting more.</p>
    <p class="cue"><span class="time">[28:16]</span>If I were to survey the room, I would bet that some of you</p>
    <p class="cue"><span class="time">[28:19]</span>would say it&#x27;s negative.</p>
    <p class="cue"><span class="time">[28:21]</span>Some of you would say it&#x27;s neutral.</p>
    <p class="cue"><span class="time">[28:23]</span>Because you actually have a first part</p>
    <p class="cue"><span class="time">[28:24]</span>that is relatively positive.</p>
    <p class="cue"><span class="time">[28:27]</span>It&#x27;s fine.</p>
    <p class="cue"><span class="time">[28:28]</span>And then the second part, I was expecting more,</p>
    <p class="cue"><span class="time">[28:30]</span>which is relatively negative.</p>
    <p class="cue"><span class="time">[28:31]</span>So where do you land?</p>
    <p class="cue"><span class="time">[28:33]</span>This can be a subjective question.</p>
    <p class="cue"><span class="time">[28:35]</span>And maybe in one industry, this would be considered amazing.</p>
    <p class="cue"><span class="time">[28:37]</span>And another one, it would be considered really bad</p>
    <p class="cue"><span class="time">[28:40]</span>because people are used to really flourishing reviews.</p>
    <p class="cue"><span class="time">[28:44]</span>And so the way you can actually align the model to your task</p>
    <p class="cue"><span class="time">[28:47]</span>is by converting that zero shot prompt.</p>
    <p class="cue"><span class="time">[28:49]</span>Zero shot refers to the fact that it&#x27;s not</p>
    <p class="cue"><span class="time">[28:51]</span>being given any example.</p>
    <p class="cue"><span class="time">[28:53]</span>Into a few short prompts, where the model</p>
    <p class="cue"><span class="time">[28:56]</span>is given in the prompt, a set of examples to align it to what</p>
    <p class="cue"><span class="time">[29:00]</span>you want it to do.</p>
    <p class="cue"><span class="time">[29:01]</span>So the example here is again, you</p>
    <p class="cue"><span class="time">[29:03]</span>paste the same prompt as before with the user review.</p>
    <p class="cue"><span class="time">[29:06]</span>And then you add, here are examples</p>
    <p class="cue"><span class="time">[29:08]</span>of tone classifications.</p>
    <p class="cue"><span class="time">[29:10]</span>These exceeded my expectation completely.</p>
    <p class="cue"><span class="time">[29:12]</span>Positive.</p>
    <p class="cue"><span class="time">[29:14]</span>It&#x27;s OK, but I wish it had more features.</p>
    <p class="cue"><span class="time">[29:17]</span>Negative.</p>
    <p class="cue"><span class="time">[29:18]</span>The service was adequate.</p>
    <p class="cue"><span class="time">[29:20]</span>Neither good nor bad.</p>
    <p class="cue"><span class="time">[29:22]</span>Neutral.</p>
    <p class="cue"><span class="time">[29:23]</span>Now classify the tone of this sentence</p>
    <p class="cue"><span class="time">[29:26]</span>after you&#x27;ve heard about these things,</p>
    <p class="cue"><span class="time">[29:28]</span>and the model then says negative.</p>
    <p class="cue"><span class="time">[29:31]</span>And the reason it says negative, of course,</p>
    <p class="cue"><span class="time">[29:33]</span>is likely because of the second example, which was it&#x27;s OK,</p>
    <p class="cue"><span class="time">[29:39]</span>but I wish it had more features, which we told the model that</p>
    <p class="cue"><span class="time">[29:42]</span>was negative.</p>
    <p class="cue"><span class="time">[29:43]</span>Because the model saw that it&#x27;s aligned now</p>
    <p class="cue"><span class="time">[29:45]</span>with your expectations.</p>
    <p class="cue"><span class="time">[29:47]</span>A few short prompts are very popular.</p>
    <p class="cue"><span class="time">[29:50]</span>And in fact, for AI startups that</p>
    <p class="cue"><span class="time">[29:52]</span>are slightly more sophisticated, you</p>
    <p class="cue"><span class="time">[29:54]</span>might see them keep a prompt up to date.</p>
    <p class="cue"><span class="time">[29:57]</span>Whenever a user says something and they</p>
    <p class="cue"><span class="time">[30:00]</span>might have a human label it and then</p>
    <p class="cue"><span class="time">[30:02]</span>add it as a few shots in their relevant</p>
    <p class="cue"><span class="time">[30:05]</span>prompts in their code base.</p>
    <p class="cue"><span class="time">[30:08]</span>You can think of that as almost building a data set.</p>
    <p class="cue"><span class="time">[30:10]</span>But instead of actually building a separate data set</p>
    <p class="cue"><span class="time">[30:12]</span>like we&#x27;ve seen with supervised fine tuning</p>
    <p class="cue"><span class="time">[30:15]</span>and then fine tuning the model on it,</p>
    <p class="cue"><span class="time">[30:17]</span>you&#x27;re just putting it directly in the prompt.</p>
    <p class="cue"><span class="time">[30:19]</span>It turns out it&#x27;s probably faster</p>
    <p class="cue"><span class="time">[30:21]</span>to do that if you want to experiment quickly</p>
    <p class="cue"><span class="time">[30:23]</span>because you don&#x27;t touch the model parameters.</p>
    <p class="cue"><span class="time">[30:25]</span>You just update your prompts.</p>
    <p class="cue"><span class="time">[30:27]</span>And if it&#x27;s text examples, you can actually</p>
    <p class="cue"><span class="time">[30:30]</span>concatenate so many examples in a single prompt.</p>
    <p class="cue"><span class="time">[30:34]</span>At some point, it will be too long,</p>
    <p class="cue"><span class="time">[30:36]</span>and you will not have the necessary context window.</p>
    <p class="cue"><span class="time">[30:39]</span>But it&#x27;s a pretty strong approach</p>
    <p class="cue"><span class="time">[30:40]</span>that is quick to align an LLM.</p>
    <p class="cue"><span class="time">[30:48]</span>OK?</p>
    <p class="cue"><span class="time">[30:49]</span>Yes.</p>
    <p class="cue"><span class="time">[30:50]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[30:57]</span>So the question was is there any research on how long</p>
    <p class="cue"><span class="time">[31:00]</span>the prompt can be before the model essentially loses</p>
    <p class="cue"><span class="time">[31:03]</span>itself or doesn&#x27;t follow instructions anymore?</p>
    <p class="cue"><span class="time">[31:06]</span>There is.</p>
    <p class="cue"><span class="time">[31:08]</span>The problem is that research is outdated every few months</p>
    <p class="cue"><span class="time">[31:11]</span>because models get better.</p>
    <p class="cue"><span class="time">[31:14]</span>And so I don&#x27;t know where the state of the art is.</p>
    <p class="cue"><span class="time">[31:16]</span>You can probably find it online on benchmarks</p>
    <p class="cue"><span class="time">[31:18]</span>on like we see that--</p>
    <p class="cue"><span class="time">[31:20]</span>I give you an example.</p>
    <p class="cue"><span class="time">[31:23]</span>On the Workera product, you have a voice conversation</p>
    <p class="cue"><span class="time">[31:27]</span>for some of you that have tried it,</p>
    <p class="cue"><span class="time">[31:28]</span>where you&#x27;re asked to explain what is the prompt.</p>
    <p class="cue"><span class="time">[31:30]</span>And then you explain, and then there&#x27;s</p>
    <p class="cue"><span class="time">[31:31]</span>a scoring algorithm in behind.</p>
    <p class="cue"><span class="time">[31:33]</span>We know that after eight turns, the model loses itself.</p>
    <p class="cue"><span class="time">[31:38]</span>After eight turns, because you always</p>
    <p class="cue"><span class="time">[31:40]</span>paste the previous user response,</p>
    <p class="cue"><span class="time">[31:42]</span>it just starts going wild.</p>
    <p class="cue"><span class="time">[31:44]</span>And so the techniques we use in the background</p>
    <p class="cue"><span class="time">[31:46]</span>is we actually create chapters of the conversation.</p>
    <p class="cue"><span class="time">[31:49]</span>Maybe one chapter is the first eight prompt.</p>
    <p class="cue"><span class="time">[31:51]</span>And then you actually start over from another prompt.</p>
    <p class="cue"><span class="time">[31:53]</span>You can summarize the first part of the conversation,</p>
    <p class="cue"><span class="time">[31:56]</span>insert the summary, and then keep going.</p>
    <p class="cue"><span class="time">[31:59]</span>Those are engineering hacks that engineers might have figured out</p>
    <p class="cue"><span class="time">[32:02]</span>in the background.</p>
    <p class="cue"><span class="time">[32:04]</span>Because eight turns makes a prompt quite long actually.</p>
    <p class="cue"><span class="time">[32:13]</span>Let&#x27;s move on to chaining.</p>
    <p class="cue"><span class="time">[32:15]</span>Chaining is the most popular technique out of everything</p>
    <p class="cue"><span class="time">[32:17]</span>we&#x27;ve seen so far in prompt engineering.</p>
    <p class="cue"><span class="time">[32:22]</span>It&#x27;s not chain of thought.</p>
    <p class="cue"><span class="time">[32:23]</span>So chain of thought we&#x27;ve seen is think step by step,</p>
    <p class="cue"><span class="time">[32:26]</span>step 1, step 2, step 3.</p>
    <p class="cue"><span class="time">[32:27]</span>Do not skip any step.</p>
    <p class="cue"><span class="time">[32:28]</span>This is different.</p>
    <p class="cue"><span class="time">[32:30]</span>This is chaining complex prompt to improve performance,</p>
    <p class="cue"><span class="time">[32:34]</span>and this is what it looks like.</p>
    <p class="cue"><span class="time">[32:37]</span>You take a single step prompt, such as read this customer</p>
    <p class="cue"><span class="time">[32:40]</span>review and write a professional response that</p>
    <p class="cue"><span class="time">[32:43]</span>acknowledges their concern, explains the issue,</p>
    <p class="cue"><span class="time">[32:46]</span>offers a resolution, and then you</p>
    <p class="cue"><span class="time">[32:48]</span>paste the customer review, which is I ordered a laptop.</p>
    <p class="cue"><span class="time">[32:51]</span>It arrived three days late.</p>
    <p class="cue"><span class="time">[32:52]</span>The packaging was damaged.</p>
    <p class="cue"><span class="time">[32:54]</span>Very disappointing.</p>
    <p class="cue"><span class="time">[32:56]</span>I needed that urgently for work.</p>
    <p class="cue"><span class="time">[32:59]</span>And then the output is an email that</p>
    <p class="cue"><span class="time">[33:01]</span>is immediately given to you by the LLM</p>
    <p class="cue"><span class="time">[33:04]</span>after it reads the prompt.</p>
    <p class="cue"><span class="time">[33:08]</span>So this might work, but it might be hard to control.</p>
    <p class="cue"><span class="time">[33:14]</span>Because think about it.</p>
    <p class="cue"><span class="time">[33:15]</span>There&#x27;s multiple steps that you have listed,</p>
    <p class="cue"><span class="time">[33:18]</span>and everything is embedded in the same prompt.</p>
    <p class="cue"><span class="time">[33:20]</span>And if you wanted to debug step by step and know which step is</p>
    <p class="cue"><span class="time">[33:24]</span>weaker, you couldn&#x27;t.</p>
    <p class="cue"><span class="time">[33:24]</span>You would have everything mixed together.</p>
    <p class="cue"><span class="time">[33:27]</span>So one advantage of chaining is you would separate the prompts,</p>
    <p class="cue"><span class="time">[33:32]</span>so that you can debug them separately.</p>
    <p class="cue"><span class="time">[33:35]</span>And it will also lead to an easier manner</p>
    <p class="cue"><span class="time">[33:38]</span>to improve your workflow.</p>
    <p class="cue"><span class="time">[33:41]</span>Let&#x27;s say a first prompt is extract the key issues.</p>
    <p class="cue"><span class="time">[33:44]</span>Identify the key concerns mentioned</p>
    <p class="cue"><span class="time">[33:46]</span>in this customer review.</p>
    <p class="cue"><span class="time">[33:47]</span>Pace the customer review.</p>
    <p class="cue"><span class="time">[33:49]</span>Second prompt.</p>
    <p class="cue"><span class="time">[33:50]</span>Using these issues, so you paste back the issues,</p>
    <p class="cue"><span class="time">[33:54]</span>draft an outline for a professional response that</p>
    <p class="cue"><span class="time">[33:57]</span>acknowledges concerns, explains possible reasons,</p>
    <p class="cue"><span class="time">[34:00]</span>and offer a resolution.</p>
    <p class="cue"><span class="time">[34:04]</span>So this is not--</p>
    <p class="cue"><span class="time">[34:06]</span>Prompt number 3, write the full response.</p>
    <p class="cue"><span class="time">[34:09]</span>So using the outline, write the professional response.</p>
    <p class="cue"><span class="time">[34:14]</span>And then you get your final output.</p>
    <p class="cue"><span class="time">[34:18]</span>So in theory, you can tell me, oh, the second approach</p>
    <p class="cue"><span class="time">[34:22]</span>is better than the first one at first.</p>
    <p class="cue"><span class="time">[34:23]</span>But what you can notice is that we can actually</p>
    <p class="cue"><span class="time">[34:27]</span>test those three prompts separately from each other</p>
    <p class="cue"><span class="time">[34:29]</span>and determine if we will get the most gains out of engineering</p>
    <p class="cue"><span class="time">[34:35]</span>the first prompt, optimizing it, or the second one,</p>
    <p class="cue"><span class="time">[34:38]</span>or the third one.</p>
    <p class="cue"><span class="time">[34:39]</span>We now have three prompts that are independent from each other.</p>
    <p class="cue"><span class="time">[34:43]</span>And maybe if the outline was better,</p>
    <p class="cue"><span class="time">[34:47]</span>the performance of the email, how much the open rate will be</p>
    <p class="cue"><span class="time">[34:53]</span>or the user satisfaction on the response</p>
    <p class="cue"><span class="time">[34:55]</span>will actually get higher.</p>
    <p class="cue"><span class="time">[34:57]</span>And so chaining improves performance but performance,</p>
    <p class="cue"><span class="time">[35:00]</span>but most importantly, helps you control your workflow</p>
    <p class="cue"><span class="time">[35:04]</span>and debug it more seamlessly.</p>
    <p class="cue"><span class="time">[35:07]</span>Yes.</p>
    <p class="cue"><span class="time">[35:09]</span>So if we that the three prompts independently work really well,</p>
    <p class="cue"><span class="time">[35:15]</span>if we combine them into one prompt,</p>
    <p class="cue"><span class="time">[35:17]</span>and we highlight a step by step thinking process,</p>
    <p class="cue"><span class="time">[35:21]</span>does on average, we get a [INAUDIBLE] by itself,</p>
    <p class="cue"><span class="time">[35:24]</span>or do we still have to do that breakdown?</p>
    <p class="cue"><span class="time">[35:28]</span>So let me try to rephrase.</p>
    <p class="cue"><span class="time">[35:30]</span>You say, let&#x27;s say we look at the first prompt which</p>
    <p class="cue"><span class="time">[35:32]</span>has all three tasks built in that prompt.</p>
    <p class="cue"><span class="time">[35:37]</span>What exactly do you mean?</p>
    <p class="cue"><span class="time">[35:39]</span>You mean like if we evaluate the output</p>
    <p class="cue"><span class="time">[35:41]</span>and we measure some user insight, satisfaction,</p>
    <p class="cue"><span class="time">[35:43]</span>et cetera?</p>
    <p class="cue"><span class="time">[35:45]</span>Why don&#x27;t we just modify that prompt and essentially see how</p>
    <p class="cue"><span class="time">[35:49]</span>it improves user satisfaction?</p>
    <p class="cue"><span class="time">[35:51]</span>Yeah.</p>
    <p class="cue"><span class="time">[35:51]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[35:54]</span>I see.</p>
    <p class="cue"><span class="time">[35:55]</span>So why do we need the three steps?</p>
    <p class="cue"><span class="time">[35:57]</span>I mean, think about it.</p>
    <p class="cue"><span class="time">[35:59]</span>The intermediate output is what you want to see.</p>
    <p class="cue"><span class="time">[36:02]</span>Like if I&#x27;m debugging the first approach,</p>
    <p class="cue"><span class="time">[36:06]</span>the way I would do it is I would capture user insights.</p>
    <p class="cue"><span class="time">[36:09]</span>Like here&#x27;s the email.</p>
    <p class="cue"><span class="time">[36:10]</span>How good was the response?</p>
    <p class="cue"><span class="time">[36:11]</span>Thumbs up, thumbs down.</p>
    <p class="cue"><span class="time">[36:13]</span>Was your issue resolved?</p>
    <p class="cue"><span class="time">[36:16]</span>Thumbs up, thumbs down.</p>
    <p class="cue"><span class="time">[36:17]</span>Those would tell me how good is my prompt.</p>
    <p class="cue"><span class="time">[36:19]</span>And I can engineer that prompt, optimize it,</p>
    <p class="cue"><span class="time">[36:21]</span>and I would probably drive some gains.</p>
    <p class="cue"><span class="time">[36:23]</span>But I will not be able easily to trace back</p>
    <p class="cue"><span class="time">[36:26]</span>to what the problem was.</p>
    <p class="cue"><span class="time">[36:28]</span>While in the second approach, not only I</p>
    <p class="cue"><span class="time">[36:30]</span>can use the end to end metrics to improve my process.</p>
    <p class="cue"><span class="time">[36:33]</span>I can also use the intermediate steps.</p>
    <p class="cue"><span class="time">[36:35]</span>For example, if I look at prompt 2 and I look at the outline</p>
    <p class="cue"><span class="time">[36:38]</span>and I see the outline is actually, meh, it&#x27;s not great,</p>
    <p class="cue"><span class="time">[36:41]</span>then I think I can get a lot of gains out of the outline.</p>
    <p class="cue"><span class="time">[36:45]</span>Or the outline is actually really good,</p>
    <p class="cue"><span class="time">[36:47]</span>but the last prompt doesn&#x27;t do a good job at translating it</p>
    <p class="cue"><span class="time">[36:50]</span>into an email.</p>
    <p class="cue"><span class="time">[36:51]</span>So the outline is exactly what I want the LLM to do,</p>
    <p class="cue"><span class="time">[36:54]</span>but the translation in a customer facing email</p>
    <p class="cue"><span class="time">[36:57]</span>is not good.</p>
    <p class="cue"><span class="time">[36:58]</span>In fact, it doesn&#x27;t follow our vocabulary internally.</p>
    <p class="cue"><span class="time">[37:01]</span>Then I knew the third prompt is where</p>
    <p class="cue"><span class="time">[37:03]</span>I would get the most gains.</p>
    <p class="cue"><span class="time">[37:06]</span>So that&#x27;s what it allows me to do,</p>
    <p class="cue"><span class="time">[37:07]</span>have intermediate steps to review.</p>
    <p class="cue"><span class="time">[37:10]</span>Are there any latency [INAUDIBLE]</p>
    <p class="cue"><span class="time">[37:13]</span>We&#x27;ll talk about it.</p>
    <p class="cue"><span class="time">[37:14]</span>Are there any latency concerns?</p>
    <p class="cue"><span class="time">[37:16]</span>Yes.</p>
    <p class="cue"><span class="time">[37:17]</span>In certain applications, you don&#x27;t want to use a chain</p>
    <p class="cue"><span class="time">[37:20]</span>or you don&#x27;t want to use a long chain because it adds latency.</p>
    <p class="cue"><span class="time">[37:26]</span>We&#x27;ll talk about that later.</p>
    <p class="cue"><span class="time">[37:27]</span>Good point.</p>
    <p class="cue"><span class="time">[37:28]</span>So practically, this is what chaining complex</p>
    <p class="cue"><span class="time">[37:32]</span>prompts look like.</p>
    <p class="cue"><span class="time">[37:33]</span>You have your first prompt with your first task.</p>
    <p class="cue"><span class="time">[37:35]</span>It outputs.</p>
    <p class="cue"><span class="time">[37:36]</span>The output is pasted in the second prompt</p>
    <p class="cue"><span class="time">[37:39]</span>with the second task being defined.</p>
    <p class="cue"><span class="time">[37:41]</span>The output is then pasted into the third prompt</p>
    <p class="cue"><span class="time">[37:43]</span>with the third task being defined and so on.</p>
    <p class="cue"><span class="time">[37:46]</span>That&#x27;s what it looks like in practice.</p>
    <p class="cue"><span class="time">[37:52]</span>Super.</p>
    <p class="cue"><span class="time">[37:55]</span>We&#x27;ll talk more later about testing your prompts,</p>
    <p class="cue"><span class="time">[37:58]</span>but there are methods now to do it,</p>
    <p class="cue"><span class="time">[38:00]</span>and we&#x27;ll see later in this lecture with our case study</p>
    <p class="cue"><span class="time">[38:03]</span>how we can test our prompts.</p>
    <p class="cue"><span class="time">[38:06]</span>But here is an example of how you might do it.</p>
    <p class="cue"><span class="time">[38:11]</span>You might have a summarization workflow prompts</p>
    <p class="cue"><span class="time">[38:18]</span>that is the baseline.</p>
    <p class="cue"><span class="time">[38:19]</span>It&#x27;s a single prompt.</p>
    <p class="cue"><span class="time">[38:21]</span>You might have a refined summarization</p>
    <p class="cue"><span class="time">[38:23]</span>which is a modified prompt of this,</p>
    <p class="cue"><span class="time">[38:26]</span>or a workflow with a chain.</p>
    <p class="cue"><span class="time">[38:30]</span>And then you have your test case, which is the input</p>
    <p class="cue"><span class="time">[38:34]</span>that you want to summarize, let&#x27;s say.</p>
    <p class="cue"><span class="time">[38:36]</span>And then you have the generated output.</p>
    <p class="cue"><span class="time">[38:38]</span>And you can have humans go and rate these outputs.</p>
    <p class="cue"><span class="time">[38:42]</span>And you would notice that the baseline is better or worse</p>
    <p class="cue"><span class="time">[38:46]</span>than the refined prompt.</p>
    <p class="cue"><span class="time">[38:47]</span>Of course, this manual approach takes time,</p>
    <p class="cue"><span class="time">[38:51]</span>but it&#x27;s a good way to start.</p>
    <p class="cue"><span class="time">[38:53]</span>And usually, the advice is get hands on at the beginning</p>
    <p class="cue"><span class="time">[38:56]</span>because you would quickly notice some issues,</p>
    <p class="cue"><span class="time">[38:58]</span>and it will give you better intuition on what tweaks</p>
    <p class="cue"><span class="time">[39:01]</span>can lead to better performance.</p>
    <p class="cue"><span class="time">[39:03]</span>However, if you wanted to scale that system</p>
    <p class="cue"><span class="time">[39:05]</span>across many products, many parts of your code base,</p>
    <p class="cue"><span class="time">[39:08]</span>you might want to find a way to do that automatically</p>
    <p class="cue"><span class="time">[39:10]</span>without asking humans to review and grade summaries.</p>
    <p class="cue"><span class="time">[39:14]</span>One approach is to use platforms,</p>
    <p class="cue"><span class="time">[39:19]</span>like at Workera, our team uses a platform called Prompt Food that</p>
    <p class="cue"><span class="time">[39:23]</span>allows you to actually automate part of this testing.</p>
    <p class="cue"><span class="time">[39:26]</span>In a nutshell, what it does is it</p>
    <p class="cue"><span class="time">[39:30]</span>can allow you to run the same prompt with five different LLMs</p>
    <p class="cue"><span class="time">[39:35]</span>immediately, put everything in a table.</p>
    <p class="cue"><span class="time">[39:37]</span>That makes it super easy for a human to grade, let&#x27;s say.</p>
    <p class="cue"><span class="time">[39:40]</span>Or alternatively, it might allow you to define LLM judges.</p>
    <p class="cue"><span class="time">[39:46]</span>LLM judges can come in different flavors.</p>
    <p class="cue"><span class="time">[39:50]</span>For example, I can have an LLM judge that</p>
    <p class="cue"><span class="time">[39:52]</span>does a pairwise comparison.</p>
    <p class="cue"><span class="time">[39:54]</span>So what the LLM is asked to do is here are two summaries.</p>
    <p class="cue"><span class="time">[39:58]</span>Just tell me which one is better than the other one.</p>
    <p class="cue"><span class="time">[40:01]</span>That&#x27;s what the LLM does.</p>
    <p class="cue"><span class="time">[40:02]</span>And that can be used as a proxy for how good</p>
    <p class="cue"><span class="time">[40:04]</span>the summarization baseline versus the refined version is.</p>
    <p class="cue"><span class="time">[40:08]</span>Another way to do an LLM judge is</p>
    <p class="cue"><span class="time">[40:11]</span>if you do it for a single answer grading,</p>
    <p class="cue"><span class="time">[40:14]</span>so here&#x27;s a summary graded from 1 to 5.</p>
    <p class="cue"><span class="time">[40:18]</span>And then you can go even deeper and do</p>
    <p class="cue"><span class="time">[40:21]</span>a reference-guided pairwise comparison.</p>
    <p class="cue"><span class="time">[40:24]</span>Or you add also a rubric.</p>
    <p class="cue"><span class="time">[40:25]</span>You say a 5 is when a summary is below 100 characters.</p>
    <p class="cue"><span class="time">[40:30]</span>I&#x27;m just making up.</p>
    <p class="cue"><span class="time">[40:31]</span>Below 100 characters.</p>
    <p class="cue"><span class="time">[40:33]</span>Mentions at least three key points</p>
    <p class="cue"><span class="time">[40:35]</span>that are distinct and starts with a first sentence that</p>
    <p class="cue"><span class="time">[40:38]</span>displays the overview and then goes into the detail.</p>
    <p class="cue"><span class="time">[40:40]</span>That&#x27;s a great summary, number 5 out of a 5.</p>
    <p class="cue"><span class="time">[40:42]</span>0 is the LLM failed to summarize and actually was very verbose,</p>
    <p class="cue"><span class="time">[40:48]</span>let&#x27;s say.</p>
    <p class="cue"><span class="time">[40:49]</span>And so you put a Rubrik behind it,</p>
    <p class="cue"><span class="time">[40:52]</span>and you have an LLM as just finding the rubric.</p>
    <p class="cue"><span class="time">[40:55]</span>Of course, you can now pair different techniques.</p>
    <p class="cue"><span class="time">[40:57]</span>You can do a few shots for the rubric.</p>
    <p class="cue"><span class="time">[40:58]</span>You can actually give examples of a 5 out of 5s, 4 out of 4s,</p>
    <p class="cue"><span class="time">[41:02]</span>3 out of 3s because now, you multiple techniques.</p>
    <p class="cue"><span class="time">[41:06]</span>Does that make sense?</p>
    <p class="cue"><span class="time">[41:11]</span>Yeah.</p>
    <p class="cue"><span class="time">[41:11]</span>OK.</p>
    <p class="cue"><span class="time">[41:12]</span>So that was the second section on prompt engineering</p>
    <p class="cue"><span class="time">[41:15]</span>or the first line of optimization.</p>
    <p class="cue"><span class="time">[41:19]</span>Now, let&#x27;s say you&#x27;ve exhausted all your chances</p>
    <p class="cue"><span class="time">[41:22]</span>for prompt engineering, and you&#x27;re</p>
    <p class="cue"><span class="time">[41:24]</span>thinking about actually touching the model, modifying its weights</p>
    <p class="cue"><span class="time">[41:28]</span>or fine tuning it in other words.</p>
    <p class="cue"><span class="time">[41:31]</span>I was telling you, I&#x27;m not a fan of fine tuning.</p>
    <p class="cue"><span class="time">[41:34]</span>There&#x27;s a few reasons why.</p>
    <p class="cue"><span class="time">[41:37]</span>One, it requires substantial labeled data typically</p>
    <p class="cue"><span class="time">[41:42]</span>to fine tune.</p>
    <p class="cue"><span class="time">[41:43]</span>Although now, there are approaches</p>
    <p class="cue"><span class="time">[41:46]</span>that are getting better at fine tuning that</p>
    <p class="cue"><span class="time">[41:48]</span>look more few shot prompting actually than fine tuning.</p>
    <p class="cue"><span class="time">[41:52]</span>It&#x27;s sort of merging.</p>
    <p class="cue"><span class="time">[41:54]</span>Although one modifies the weight,</p>
    <p class="cue"><span class="time">[41:56]</span>the other doesn&#x27;t modify the weights.</p>
    <p class="cue"><span class="time">[41:57]</span>Fine tuned models may also overfit to specific data.</p>
    <p class="cue"><span class="time">[42:01]</span>We&#x27;re going to see a funny example actually.</p>
    <p class="cue"><span class="time">[42:04]</span>Losing their general purpose utility.</p>
    <p class="cue"><span class="time">[42:06]</span>So you might fine tune a model.</p>
    <p class="cue"><span class="time">[42:08]</span>And actually, when someone asks a pretty generic question,</p>
    <p class="cue"><span class="time">[42:11]</span>it doesn&#x27;t do well anymore.</p>
    <p class="cue"><span class="time">[42:12]</span>It might do well on your task.</p>
    <p class="cue"><span class="time">[42:14]</span>So it might be relevant or not.</p>
    <p class="cue"><span class="time">[42:15]</span>And then it&#x27;s time and cost-intensive.</p>
    <p class="cue"><span class="time">[42:17]</span>That&#x27;s my main problem.</p>
    <p class="cue"><span class="time">[42:19]</span>And at Workera, we steer away from fine</p>
    <p class="cue"><span class="time">[42:24]</span>tuning as much as possible.</p>
    <p class="cue"><span class="time">[42:26]</span>Because by the time you&#x27;re done fine tuning your model,</p>
    <p class="cue"><span class="time">[42:28]</span>the next model is out, and it&#x27;s actually</p>
    <p class="cue"><span class="time">[42:30]</span>beating your fine tuned version of the previous model.</p>
    <p class="cue"><span class="time">[42:33]</span>So I would steer away from fine tuning as much as you can.</p>
    <p class="cue"><span class="time">[42:36]</span>The advantage of the prompt engineering methods we&#x27;ve seen</p>
    <p class="cue"><span class="time">[42:39]</span>is you can put the next best pre-trained model directly</p>
    <p class="cue"><span class="time">[42:43]</span>in your code.</p>
    <p class="cue"><span class="time">[42:44]</span>It will update everything immediately.</p>
    <p class="cue"><span class="time">[42:46]</span>Fine tuning doesn&#x27;t work like that.</p>
    <p class="cue"><span class="time">[42:50]</span>There are advantages though where it still makes sense.</p>
    <p class="cue"><span class="time">[42:53]</span>If the task requires repeated high precision outputs</p>
    <p class="cue"><span class="time">[42:56]</span>such as legal, scientific explanation</p>
    <p class="cue"><span class="time">[42:58]</span>and if the general purpose LLM struggles</p>
    <p class="cue"><span class="time">[43:01]</span>with domain-specific language.</p>
    <p class="cue"><span class="time">[43:03]</span>So let&#x27;s look at a quick example together,</p>
    <p class="cue"><span class="time">[43:07]</span>which is an example from Ros Lazerowitz.</p>
    <p class="cue"><span class="time">[43:12]</span>I think it was a couple of years ago, September 23,</p>
    <p class="cue"><span class="time">[43:15]</span>where Ros tried to do Slack fine tuning.</p>
    <p class="cue"><span class="time">[43:22]</span>So he looked at a lot of Slack messages within his company.</p>
    <p class="cue"><span class="time">[43:26]</span>And he was like, I&#x27;m going to fine tune</p>
    <p class="cue"><span class="time">[43:28]</span>a model that speaks like us or operates like us because this</p>
    <p class="cue"><span class="time">[43:32]</span>is how we work.</p>
    <p class="cue"><span class="time">[43:33]</span>This is the data that represents how people work at the company.</p>
    <p class="cue"><span class="time">[43:37]</span>And so he actually went ahead and fine tuned the model,</p>
    <p class="cue"><span class="time">[43:42]</span>gave it a prompt, like, hey, write--</p>
    <p class="cue"><span class="time">[43:44]</span>he was delegating to the model.</p>
    <p class="cue"><span class="time">[43:47]</span>A 500-word blog post on prompt engineering.</p>
    <p class="cue"><span class="time">[43:50]</span>And the model responded, I shall work on that in the morning.</p>
    <p class="cue"><span class="time">[43:55]</span>And then he tries to push the model a little further and say,</p>
    <p class="cue"><span class="time">[44:00]</span>it&#x27;s morning now.</p>
    <p class="cue"><span class="time">[44:01]</span>And the model said, I&#x27;m writing right now.</p>
    <p class="cue"><span class="time">[44:04]</span>It&#x27;s 6:30 AM here.</p>
    <p class="cue"><span class="time">[44:06]</span>Write it now.</p>
    <p class="cue"><span class="time">[44:10]</span>OK, I shall write it now.</p>
    <p class="cue"><span class="time">[44:12]</span>I actually don&#x27;t what you would like me to say</p>
    <p class="cue"><span class="time">[44:14]</span>about prompt engineering.</p>
    <p class="cue"><span class="time">[44:15]</span>I can only describe the process.</p>
    <p class="cue"><span class="time">[44:17]</span>The only thing that comes to mind for a headline</p>
    <p class="cue"><span class="time">[44:19]</span>is how do we build prompt?</p>
    <p class="cue"><span class="time">[44:21]</span>It&#x27;s kind of a funny example for fine tuning because it&#x27;s true</p>
    <p class="cue"><span class="time">[44:25]</span>that it went wrong.</p>
    <p class="cue"><span class="time">[44:27]</span>Like he was supposed to think like I want</p>
    <p class="cue"><span class="time">[44:29]</span>the model to speak like us at work.</p>
    <p class="cue"><span class="time">[44:32]</span>And it ended up acting like people</p>
    <p class="cue"><span class="time">[44:34]</span>and not actually following instructions.</p>
    <p class="cue"><span class="time">[44:40]</span>So one example why I would steer away from fine tuning.</p>
    <p class="cue"><span class="time">[44:47]</span>Super.</p>
    <p class="cue"><span class="time">[44:51]</span>Let&#x27;s talk about RAGs.</p>
    <p class="cue"><span class="time">[44:54]</span>RAGs is important.</p>
    <p class="cue"><span class="time">[44:55]</span>It&#x27;s important to out there and at least having the basics.</p>
    <p class="cue"><span class="time">[44:58]</span>It&#x27;s a very common interview question, by the way.</p>
    <p class="cue"><span class="time">[45:00]</span>If you go interview for a job, they</p>
    <p class="cue"><span class="time">[45:02]</span>might ask you to explain in a nutshell</p>
    <p class="cue"><span class="time">[45:04]</span>to a five-year-old what is a RAG.</p>
    <p class="cue"><span class="time">[45:06]</span>And hopefully after that, you&#x27;ll be able to do it.</p>
    <p class="cue"><span class="time">[45:09]</span>So we&#x27;ve seen some of the challenges with standalone LLMs.</p>
    <p class="cue"><span class="time">[45:14]</span>Those challenges include the context window being small,</p>
    <p class="cue"><span class="time">[45:19]</span>the fact that it&#x27;s hard to remember details</p>
    <p class="cue"><span class="time">[45:21]</span>within a large context window, knowledge gaps, cutoff dates,</p>
    <p class="cue"><span class="time">[45:26]</span>you mentioned earlier.</p>
    <p class="cue"><span class="time">[45:28]</span>The model might be trained up to a date,</p>
    <p class="cue"><span class="time">[45:29]</span>and then it cannot follow the trends or be up to date.</p>
    <p class="cue"><span class="time">[45:33]</span>Hallucinations.</p>
    <p class="cue"><span class="time">[45:34]</span>There are some fields.</p>
    <p class="cue"><span class="time">[45:35]</span>Think about medical diagnosis, where</p>
    <p class="cue"><span class="time">[45:37]</span>hallucinations are very costly.</p>
    <p class="cue"><span class="time">[45:39]</span>You can&#x27;t afford a hallucination.</p>
    <p class="cue"><span class="time">[45:41]</span>Even in education, imagine deploying a model for the US</p>
    <p class="cue"><span class="time">[45:45]</span>youth education, and it hallucinates,</p>
    <p class="cue"><span class="time">[45:47]</span>and it teaches millions of people something</p>
    <p class="cue"><span class="time">[45:49]</span>completely wrong.</p>
    <p class="cue"><span class="time">[45:50]</span>It&#x27;s a problem.</p>
    <p class="cue"><span class="time">[45:52]</span>And then lack of sources.</p>
    <p class="cue"><span class="time">[45:54]</span>A lot of fields love sources.</p>
    <p class="cue"><span class="time">[45:57]</span>Research fields love sources.</p>
    <p class="cue"><span class="time">[45:59]</span>Education love sources.</p>
    <p class="cue"><span class="time">[46:01]</span>Legal loves sources as well.</p>
    <p class="cue"><span class="time">[46:04]</span>And so the pre-trained LLM doesn&#x27;t do a good job to source.</p>
    <p class="cue"><span class="time">[46:08]</span>And in fact, if you have tried to find sources on a plain LLM,</p>
    <p class="cue"><span class="time">[46:13]</span>it actually hallucinates a lot.</p>
    <p class="cue"><span class="time">[46:15]</span>It makes up research papers.</p>
    <p class="cue"><span class="time">[46:16]</span>It just lists like completely fake stuff.</p>
    <p class="cue"><span class="time">[46:20]</span>So how do we solve that with a RAG?</p>
    <p class="cue"><span class="time">[46:23]</span>RAG integrates with external knowledge sources, databases,</p>
    <p class="cue"><span class="time">[46:28]</span>documents, APIs.</p>
    <p class="cue"><span class="time">[46:31]</span>It ensures that answers are more accurate, up to date,</p>
    <p class="cue"><span class="time">[46:35]</span>and grounded because you can actually update your document.</p>
    <p class="cue"><span class="time">[46:38]</span>Your drive is always up to date.</p>
    <p class="cue"><span class="time">[46:40]</span>I mean, ideally, you&#x27;re always pushing new documents to it.</p>
    <p class="cue"><span class="time">[46:43]</span>And when you query, what is our Q4 performance in sales?</p>
    <p class="cue"><span class="time">[46:47]</span>Hopefully there is the last board deck in the drive,</p>
    <p class="cue"><span class="time">[46:51]</span>and it can read the last board deck.</p>
    <p class="cue"><span class="time">[46:54]</span>And more developer control.</p>
    <p class="cue"><span class="time">[46:56]</span>We&#x27;ll see why RAGs allow for targeted customization</p>
    <p class="cue"><span class="time">[47:00]</span>without actually requiring the retraining of the model.</p>
    <p class="cue"><span class="time">[47:02]</span>In fact, you don&#x27;t touch the model with RAGs.</p>
    <p class="cue"><span class="time">[47:05]</span>It&#x27;s really a technique that is put on top of the model.</p>
    <p class="cue"><span class="time">[47:08]</span>So to see an example of a RAG, this</p>
    <p class="cue"><span class="time">[47:11]</span>is a question answering application where</p>
    <p class="cue"><span class="time">[47:16]</span>we&#x27;re in the medical field, and a user is asking a query,</p>
    <p class="cue"><span class="time">[47:21]</span>what are the side effects of drug X?</p>
    <p class="cue"><span class="time">[47:26]</span>This is an important question.</p>
    <p class="cue"><span class="time">[47:27]</span>You can&#x27;t hallucinate.</p>
    <p class="cue"><span class="time">[47:28]</span>You need to source.</p>
    <p class="cue"><span class="time">[47:29]</span>You need to be up to date.</p>
    <p class="cue"><span class="time">[47:31]</span>Maybe there is a new update to that drug that</p>
    <p class="cue"><span class="time">[47:35]</span>is now in the database, and you need to read that.</p>
    <p class="cue"><span class="time">[47:37]</span>So a RAG is a great example of what you would want to use here.</p>
    <p class="cue"><span class="time">[47:41]</span>The way it works is you have your knowledge</p>
    <p class="cue"><span class="time">[47:43]</span>base of a bunch of documents.</p>
    <p class="cue"><span class="time">[47:46]</span>What you do is you use an embedding</p>
    <p class="cue"><span class="time">[47:49]</span>to embed those documents into lower</p>
    <p class="cue"><span class="time">[47:52]</span>dimensional representations.</p>
    <p class="cue"><span class="time">[47:54]</span>So for example, if the document is a PDF, a long PDF,</p>
    <p class="cue"><span class="time">[47:59]</span>you might read the PDF, understand it,</p>
    <p class="cue"><span class="time">[48:02]</span>and then embed it.</p>
    <p class="cue"><span class="time">[48:03]</span>We&#x27;ve seen plenty of embedding approaches</p>
    <p class="cue"><span class="time">[48:05]</span>together, triplet loss, et cetera, you remember?</p>
    <p class="cue"><span class="time">[48:09]</span>So imagine one of them here for LLMs</p>
    <p class="cue"><span class="time">[48:11]</span>is embedding those documents into lower representation.</p>
    <p class="cue"><span class="time">[48:15]</span>If the representation is too small,</p>
    <p class="cue"><span class="time">[48:18]</span>you will lose information.</p>
    <p class="cue"><span class="time">[48:19]</span>If it&#x27;s too big, you will add latency.</p>
    <p class="cue"><span class="time">[48:22]</span>It&#x27;s a tradeoff.</p>
    <p class="cue"><span class="time">[48:25]</span>You will store typically those representations</p>
    <p class="cue"><span class="time">[48:28]</span>into a database called a vector database.</p>
    <p class="cue"><span class="time">[48:31]</span>There&#x27;s a lot of vector database providers out there.</p>
    <p class="cue"><span class="time">[48:38]</span>I think I&#x27;ve listed a couple that are very common.</p>
    <p class="cue"><span class="time">[48:41]</span>No, I haven&#x27;t listed, but I can share afterwards.</p>
    <p class="cue"><span class="time">[48:44]</span>A vector database is essentially storing those vector</p>
    <p class="cue"><span class="time">[48:47]</span>in a very efficient manner, allowing the fast retrieval</p>
    <p class="cue"><span class="time">[48:50]</span>with a certain distance metric.</p>
    <p class="cue"><span class="time">[48:52]</span>So what you do is you also embed, usually</p>
    <p class="cue"><span class="time">[48:56]</span>with the same algorithm, the user prompts.</p>
    <p class="cue"><span class="time">[49:00]</span>And you run a retrieval process, which is essentially</p>
    <p class="cue"><span class="time">[49:03]</span>saying, based on the embedding from the user</p>
    <p class="cue"><span class="time">[49:07]</span>query and the vector database, find the relevant documents</p>
    <p class="cue"><span class="time">[49:12]</span>based on the distance between those embeddings.</p>
    <p class="cue"><span class="time">[49:15]</span>Once you&#x27;ve found the relevant documents, you pull them,</p>
    <p class="cue"><span class="time">[49:18]</span>and then you add them to the user query with a system prompt</p>
    <p class="cue"><span class="time">[49:22]</span>or a prompt template on top.</p>
    <p class="cue"><span class="time">[49:24]</span>So the prompt template can be answer user query</p>
    <p class="cue"><span class="time">[49:29]</span>based on list of documents.</p>
    <p class="cue"><span class="time">[49:32]</span>If answer not in the documents, say I don&#x27;t know.</p>
    <p class="cue"><span class="time">[49:36]</span>That&#x27;s your prompt templates where the user query is pasted,</p>
    <p class="cue"><span class="time">[49:40]</span>the documents are pasted, and then</p>
    <p class="cue"><span class="time">[49:42]</span>your output should be what you want because it&#x27;s not</p>
    <p class="cue"><span class="time">[49:45]</span>grounded in the documents.</p>
    <p class="cue"><span class="time">[49:47]</span>You can also add to this prompt template.</p>
    <p class="cue"><span class="time">[49:50]</span>Tell me the exact page, chapter, line</p>
    <p class="cue"><span class="time">[49:53]</span>of the document that was relevant, and in fact,</p>
    <p class="cue"><span class="time">[49:55]</span>link it as well, just to be more precise.</p>
    <p class="cue"><span class="time">[50:02]</span>Any question on RAGs?</p>
    <p class="cue"><span class="time">[50:03]</span>This is a simple, vanilla RAG.</p>
    <p class="cue"><span class="time">[50:07]</span>Yes.</p>
    <p class="cue"><span class="time">[50:09]</span>Do document embeddings still retain information [INAUDIBLE]</p>
    <p class="cue"><span class="time">[50:15]</span>Question is do the document embeddings still</p>
    <p class="cue"><span class="time">[50:18]</span>retain the information of the location of the information</p>
    <p class="cue"><span class="time">[50:21]</span>within that document, especially in big documents?</p>
    <p class="cue"><span class="time">[50:24]</span>Great question.</p>
    <p class="cue"><span class="time">[50:26]</span>We&#x27;ll get to it in a second.</p>
    <p class="cue"><span class="time">[50:27]</span>Because you&#x27;re right that the vanilla RAG</p>
    <p class="cue"><span class="time">[50:29]</span>might not do a good job with very large documents.</p>
    <p class="cue"><span class="time">[50:32]</span>So let&#x27;s say, when you open a medication box</p>
    <p class="cue"><span class="time">[50:36]</span>and you have this gigantic white paper with all the information,</p>
    <p class="cue"><span class="time">[50:41]</span>and it&#x27;s very long, maybe a vanilla RAG would not cut it.</p>
    <p class="cue"><span class="time">[50:45]</span>So what people have figured out is a bunch</p>
    <p class="cue"><span class="time">[50:48]</span>of techniques to improve RAGs.</p>
    <p class="cue"><span class="time">[50:49]</span>And in fact, chunking is a great technique that is very popular.</p>
    <p class="cue"><span class="time">[50:53]</span>So you might actually store in the vector database</p>
    <p class="cue"><span class="time">[50:55]</span>the embedding of the full document.</p>
    <p class="cue"><span class="time">[50:57]</span>And on top of that, you will also</p>
    <p class="cue"><span class="time">[50:59]</span>store a chapter level vector.</p>
    <p class="cue"><span class="time">[51:02]</span>And when you retrieve, you will retrieve the document.</p>
    <p class="cue"><span class="time">[51:04]</span>You retrieve the chapter.</p>
    <p class="cue"><span class="time">[51:06]</span>And that allows you to be more precise with the sourcing.</p>
    <p class="cue"><span class="time">[51:09]</span>It&#x27;s one example.</p>
    <p class="cue"><span class="time">[51:11]</span>Another technique that&#x27;s popular is HyDE.</p>
    <p class="cue"><span class="time">[51:16]</span>Hypothetical document embeddings,</p>
    <p class="cue"><span class="time">[51:18]</span>where a group of researchers published a paper</p>
    <p class="cue"><span class="time">[51:23]</span>showing that when you get your user query,</p>
    <p class="cue"><span class="time">[51:26]</span>one of the main problem is the user query</p>
    <p class="cue"><span class="time">[51:29]</span>actually does not look like your documents.</p>
    <p class="cue"><span class="time">[51:32]</span>For example, the user query might</p>
    <p class="cue"><span class="time">[51:34]</span>be what are the side effects of drug X, when actually,</p>
    <p class="cue"><span class="time">[51:37]</span>in the document in the vector database,</p>
    <p class="cue"><span class="time">[51:40]</span>the vectors represents very long documents.</p>
    <p class="cue"><span class="time">[51:43]</span>So how do you guarantee that the vector</p>
    <p class="cue"><span class="time">[51:44]</span>embedding is going to be close to the document embedding?</p>
    <p class="cue"><span class="time">[51:47]</span>What they do is they use the user query to generate</p>
    <p class="cue"><span class="time">[51:50]</span>a fake hallucinated document.</p>
    <p class="cue"><span class="time">[51:53]</span>They embed that document, and then they</p>
    <p class="cue"><span class="time">[51:56]</span>compare it to the vector in the vector database.</p>
    <p class="cue"><span class="time">[52:01]</span>That makes sense?</p>
    <p class="cue"><span class="time">[52:02]</span>So for example, the user says what</p>
    <p class="cue"><span class="time">[52:04]</span>is the side effect of drug X?</p>
    <p class="cue"><span class="time">[52:06]</span>There&#x27;s a prompt that this is given to another prompt that</p>
    <p class="cue"><span class="time">[52:09]</span>says, based on this user query, generates a five-page report</p>
    <p class="cue"><span class="time">[52:13]</span>answering the user query.</p>
    <p class="cue"><span class="time">[52:15]</span>It generates potentially a completely fake answer.</p>
    <p class="cue"><span class="time">[52:20]</span>You embed that, and it will be closer to the document</p>
    <p class="cue"><span class="time">[52:24]</span>that you&#x27;re looking for likely.</p>
    <p class="cue"><span class="time">[52:28]</span>It&#x27;s one example of a RAG approach.</p>
    <p class="cue"><span class="time">[52:31]</span>Again, the purpose of this lecture</p>
    <p class="cue"><span class="time">[52:33]</span>is not to go through all these three and explain</p>
    <p class="cue"><span class="time">[52:36]</span>you every single method that has been discovered for RAGs.</p>
    <p class="cue"><span class="time">[52:38]</span>But I just wanted to show you how much research</p>
    <p class="cue"><span class="time">[52:40]</span>has been done between 2020 and 2025 in RAGs</p>
    <p class="cue"><span class="time">[52:44]</span>and how many branches of research you now have</p>
    <p class="cue"><span class="time">[52:47]</span>that you can learn from.</p>
    <p class="cue"><span class="time">[52:50]</span>The survey paper is LinkedIn the slides, by the way,</p>
    <p class="cue"><span class="time">[52:52]</span>and I&#x27;ll share them after the lecture.</p>
    <p class="cue"><span class="time">[53:01]</span>Super.</p>
    <p class="cue"><span class="time">[53:05]</span>So we&#x27;ve made some progress.</p>
    <p class="cue"><span class="time">[53:08]</span>Hopefully now, you feel if you were</p>
    <p class="cue"><span class="time">[53:10]</span>to start an LLM application, you know how to do better prompts.</p>
    <p class="cue"><span class="time">[53:14]</span>You know how to do chains.</p>
    <p class="cue"><span class="time">[53:15]</span>You know how to do fine tuning.</p>
    <p class="cue"><span class="time">[53:17]</span>You also how to do retrieval.</p>
    <p class="cue"><span class="time">[53:19]</span>And you have the baggage of techniques</p>
    <p class="cue"><span class="time">[53:20]</span>that you can go and read and find the code base,</p>
    <p class="cue"><span class="time">[53:23]</span>pull the code, vibe code it.</p>
    <p class="cue"><span class="time">[53:24]</span>But you have the breadth now.</p>
    <p class="cue"><span class="time">[53:30]</span>The next set of topics we&#x27;re going to see</p>
    <p class="cue"><span class="time">[53:34]</span>is around the question of how could we</p>
    <p class="cue"><span class="time">[53:36]</span>extend the capabilities of LLMs from performing single tasks,</p>
    <p class="cue"><span class="time">[53:40]</span>and hence, with external knowledge,</p>
    <p class="cue"><span class="time">[53:42]</span>to handling multi-step, autonomous workflows?</p>
    <p class="cue"><span class="time">[53:47]</span>And this is where we get into proper agentic AI.</p>
    <p class="cue"><span class="time">[53:53]</span>So let&#x27;s talk about agentic AI workflows</p>
    <p class="cue"><span class="time">[53:56]</span>towards autonomous and specialized systems.</p>
    <p class="cue"><span class="time">[54:00]</span>Then we&#x27;ll talk about evals.</p>
    <p class="cue"><span class="time">[54:01]</span>Then we&#x27;ll see multi-agent systems.</p>
    <p class="cue"><span class="time">[54:03]</span>And we&#x27;ll end with a little thoughts on what&#x27;s next in AI.</p>
    <p class="cue"><span class="time">[54:11]</span>So Andrew Ng actually coined the term agentic AI workflows.</p>
    <p class="cue"><span class="time">[54:20]</span>And his reason was that a lot of companies use, say agents.</p>
    <p class="cue"><span class="time">[54:25]</span>Agents, agents everywhere, agents everywhere.</p>
    <p class="cue"><span class="time">[54:28]</span>If you go and work at these companies,</p>
    <p class="cue"><span class="time">[54:30]</span>you would notice that they mean very different things by agents.</p>
    <p class="cue"><span class="time">[54:33]</span>Some people actually have a prompt,</p>
    <p class="cue"><span class="time">[54:34]</span>and they call it an agent.</p>
    <p class="cue"><span class="time">[54:36]</span>Other people, they have a very complex multi-agent system,</p>
    <p class="cue"><span class="time">[54:41]</span>they call it an agent.</p>
    <p class="cue"><span class="time">[54:42]</span>And so calling everything an agent doesn&#x27;t do it justice.</p>
    <p class="cue"><span class="time">[54:45]</span>So Andrew says let&#x27;s call it agentic workflows.</p>
    <p class="cue"><span class="time">[54:49]</span>Because in practice, it&#x27;s a bunch of prompts with tools,</p>
    <p class="cue"><span class="time">[54:53]</span>with additional resources, API calls</p>
    <p class="cue"><span class="time">[54:57]</span>that ultimately are put in a workflow,</p>
    <p class="cue"><span class="time">[54:59]</span>and you can call that workflow agentic.</p>
    <p class="cue"><span class="time">[55:02]</span>So it&#x27;s all about the multi-step process to complete a task.</p>
    <p class="cue"><span class="time">[55:11]</span>Also, calling it agentic workflow</p>
    <p class="cue"><span class="time">[55:13]</span>allows us to not mix it up with what</p>
    <p class="cue"><span class="time">[55:14]</span>I called agent, in the last lecture,</p>
    <p class="cue"><span class="time">[55:17]</span>with reinforcement learning.</p>
    <p class="cue"><span class="time">[55:19]</span>Because in RL, agent has a very specific definition,</p>
    <p class="cue"><span class="time">[55:22]</span>interacts with an environment, passes from one state</p>
    <p class="cue"><span class="time">[55:24]</span>to the other, has a reward and an observation.</p>
    <p class="cue"><span class="time">[55:26]</span>You remember that chart, right?</p>
    <p class="cue"><span class="time">[55:32]</span>So here&#x27;s an example of how we move from a one step</p>
    <p class="cue"><span class="time">[55:35]</span>prompt to a multi-step agentic workflow.</p>
    <p class="cue"><span class="time">[55:39]</span>Let&#x27;s say a user queries a product.</p>
    <p class="cue"><span class="time">[55:44]</span>What is your refund policy on a chatbot?</p>
    <p class="cue"><span class="time">[55:48]</span>And the response, using a RAG, says</p>
    <p class="cue"><span class="time">[55:51]</span>refunds are available within 30 days of purchase,</p>
    <p class="cue"><span class="time">[55:53]</span>and maybe the RAG can even look link to the policy documents.</p>
    <p class="cue"><span class="time">[55:57]</span>That&#x27;s what we learned so far.</p>
    <p class="cue"><span class="time">[55:59]</span>Instead, an agentic workflow can function like this.</p>
    <p class="cue"><span class="time">[56:04]</span>The user says, can I get a refund for my order?</p>
    <p class="cue"><span class="time">[56:07]</span>And the response via the agentic workflow</p>
    <p class="cue"><span class="time">[56:11]</span>is the agent retrieves the refund policy using a RAG.</p>
    <p class="cue"><span class="time">[56:14]</span>The agent then follows up with the users and says,</p>
    <p class="cue"><span class="time">[56:17]</span>can you provide your order number?</p>
    <p class="cue"><span class="time">[56:19]</span>Then the agent queries an API to check the order details.</p>
    <p class="cue"><span class="time">[56:23]</span>And finally, it comes back to the user</p>
    <p class="cue"><span class="time">[56:25]</span>and confirms your order qualifies for a refund.</p>
    <p class="cue"><span class="time">[56:28]</span>The amount will be processed in three to five business days.</p>
    <p class="cue"><span class="time">[56:31]</span>This is much more thoughtful than the first version,</p>
    <p class="cue"><span class="time">[56:33]</span>which is sort of vanilla.</p>
    <p class="cue"><span class="time">[56:37]</span>So that&#x27;s what we&#x27;re going to talk</p>
    <p class="cue"><span class="time">[56:39]</span>about in the next couple of slides,</p>
    <p class="cue"><span class="time">[56:40]</span>is how do we get from the first one to the second one?</p>
    <p class="cue"><span class="time">[56:46]</span>There are plenty of specialized agency workflows online.</p>
    <p class="cue"><span class="time">[56:50]</span>You&#x27;ve heard, and if you hang out in SF,</p>
    <p class="cue"><span class="time">[56:52]</span>you probably see a bunch of billboards, AI software</p>
    <p class="cue"><span class="time">[56:55]</span>engineer, AI skills mentor you&#x27;ve</p>
    <p class="cue"><span class="time">[56:57]</span>interacted with in the class through Workera.</p>
    <p class="cue"><span class="time">[56:59]</span>AI SDR, AI lawyers, AI specialized cloud engineer.</p>
    <p class="cue"><span class="time">[57:08]</span>It would be a stretch to say that everything works,</p>
    <p class="cue"><span class="time">[57:10]</span>but there&#x27;s work being done towards that.</p>
    <p class="cue"><span class="time">[57:17]</span>I&#x27;m not personally a fan of putting</p>
    <p class="cue"><span class="time">[57:19]</span>a face behind those things.</p>
    <p class="cue"><span class="time">[57:20]</span>I think it&#x27;s gimmicky.</p>
    <p class="cue"><span class="time">[57:21]</span>And I think in a few years from now, actually,</p>
    <p class="cue"><span class="time">[57:24]</span>very few products will have a human face behind it,</p>
    <p class="cue"><span class="time">[57:27]</span>but it might be a marketing tactic from some startups.</p>
    <p class="cue"><span class="time">[57:32]</span>It&#x27;s more scary than it is engaging, frankly.</p>
    <p class="cue"><span class="time">[57:35]</span>OK.</p>
    <p class="cue"><span class="time">[57:36]</span>I want to talk about the paradigm shift.</p>
    <p class="cue"><span class="time">[57:38]</span>That&#x27;s especially useful.</p>
    <p class="cue"><span class="time">[57:40]</span>Let&#x27;s say you&#x27;re a software engineer</p>
    <p class="cue"><span class="time">[57:41]</span>or you&#x27;re planning to be a software engineer.</p>
    <p class="cue"><span class="time">[57:43]</span>Because software engineering as a discipline</p>
    <p class="cue"><span class="time">[57:45]</span>is sort of shifting.</p>
    <p class="cue"><span class="time">[57:47]</span>Or at least the best engineers I&#x27;ve</p>
    <p class="cue"><span class="time">[57:49]</span>worked with are able to move from a deterministic mindset</p>
    <p class="cue"><span class="time">[57:53]</span>to a fuzzy mindset and balance between the two</p>
    <p class="cue"><span class="time">[57:57]</span>whenever they need to get something done.</p>
    <p class="cue"><span class="time">[57:58]</span>So here&#x27;s the paradigm shift between traditional software</p>
    <p class="cue"><span class="time">[58:01]</span>and agentic AI software.</p>
    <p class="cue"><span class="time">[58:04]</span>The first one is the way you handle data.</p>
    <p class="cue"><span class="time">[58:07]</span>Traditional software deals with structured data.</p>
    <p class="cue"><span class="time">[58:10]</span>You have JSONs.</p>
    <p class="cue"><span class="time">[58:11]</span>You have databases.</p>
    <p class="cue"><span class="time">[58:12]</span>They&#x27;re pasted in a very structured manner</p>
    <p class="cue"><span class="time">[58:15]</span>in a data engineering pipeline.</p>
    <p class="cue"><span class="time">[58:17]</span>And then there used to be displayed</p>
    <p class="cue"><span class="time">[58:19]</span>on a certain interface.</p>
    <p class="cue"><span class="time">[58:21]</span>The user might feel a form that is then retrieved and pasted</p>
    <p class="cue"><span class="time">[58:24]</span>in the database.</p>
    <p class="cue"><span class="time">[58:25]</span>All of that historically has been structured data.</p>
    <p class="cue"><span class="time">[58:28]</span>Now, more and more companies are handling free form text, images,</p>
    <p class="cue"><span class="time">[58:34]</span>and all of that requires dynamic interpretation to transform</p>
    <p class="cue"><span class="time">[58:39]</span>an input into an output.</p>
    <p class="cue"><span class="time">[58:41]</span>The software itself used to be deterministic.</p>
    <p class="cue"><span class="time">[58:45]</span>Now you have a lot of software that is fuzzy.</p>
    <p class="cue"><span class="time">[58:47]</span>And fuzzy software creates so many issues.</p>
    <p class="cue"><span class="time">[58:51]</span>I mean, imagine if you let your user ask anything</p>
    <p class="cue"><span class="time">[58:54]</span>on your website.</p>
    <p class="cue"><span class="time">[58:56]</span>The chances that it breaks is tremendous.</p>
    <p class="cue"><span class="time">[58:58]</span>The chances that you&#x27;re attacked is tremendous.</p>
    <p class="cue"><span class="time">[59:00]</span>The chances-- it&#x27;s really, really complicated.</p>
    <p class="cue"><span class="time">[59:03]</span>It&#x27;s more complicated than people make it seem on Twitter.</p>
    <p class="cue"><span class="time">[59:07]</span>Fuzzy engineering is truly hard.</p>
    <p class="cue"><span class="time">[59:09]</span>You might get hate as a company because one user did something</p>
    <p class="cue"><span class="time">[59:14]</span>that you authorized them to do that ended up breaking</p>
    <p class="cue"><span class="time">[59:16]</span>the database and ended up--</p>
    <p class="cue"><span class="time">[59:18]</span>we&#x27;ve seen that with many companies</p>
    <p class="cue"><span class="time">[59:19]</span>in the last couple of years.</p>
    <p class="cue"><span class="time">[59:21]</span>So it takes a very specialized engineering mindset</p>
    <p class="cue"><span class="time">[59:23]</span>to do fuzzy engineering, but also</p>
    <p class="cue"><span class="time">[59:25]</span>know when you need to be deterministic.</p>
    <p class="cue"><span class="time">[59:29]</span>The other thing I&#x27;d call is with agentic AI software,</p>
    <p class="cue"><span class="time">[59:33]</span>you want to think about your software as your manager.</p>
    <p class="cue"><span class="time">[59:39]</span>So you&#x27;re familiar with the monolith or microservices</p>
    <p class="cue"><span class="time">[59:44]</span>approaches in software, where you structure your software</p>
    <p class="cue"><span class="time">[59:48]</span>in different boxes that can talk to each other,</p>
    <p class="cue"><span class="time">[59:51]</span>and it allows teams to debug one section at a time.</p>
    <p class="cue"><span class="time">[59:55]</span>Now the equivalent with agentic AI is you think as a manager.</p>
    <p class="cue"><span class="time">[59:59]</span>So you think, OK, if I was to delegate my product</p>
    <p class="cue"><span class="time">[60:02]</span>to be done by a group of humans, what would be those roles?</p>
    <p class="cue"><span class="time">[60:06]</span>Would I have a graphic designer that then puts together a chart</p>
    <p class="cue"><span class="time">[60:09]</span>and then sends it to a marketing manager that converts it</p>
    <p class="cue"><span class="time">[60:12]</span>into a nice blog post, that then gives it to the performance</p>
    <p class="cue"><span class="time">[60:15]</span>marketing expert, that then publishes the work, the blog</p>
    <p class="cue"><span class="time">[60:18]</span>post, and then optimizes and A/B tests?</p>
    <p class="cue"><span class="time">[60:20]</span>Then to a data scientist that analyzes the data</p>
    <p class="cue"><span class="time">[60:23]</span>and then puts hypotheses and validates</p>
    <p class="cue"><span class="time">[60:25]</span>them or invalidates them.</p>
    <p class="cue"><span class="time">[60:27]</span>That&#x27;s how you would typically think if you&#x27;re building</p>
    <p class="cue"><span class="time">[60:29]</span>an authentic AI software.</p>
    <p class="cue"><span class="time">[60:32]</span>When actually, the equivalent of that in traditional software</p>
    <p class="cue"><span class="time">[60:35]</span>might be completely different.</p>
    <p class="cue"><span class="time">[60:37]</span>It might be We have a data engineer box</p>
    <p class="cue"><span class="time">[60:39]</span>right here that handles all our data engineering.</p>
    <p class="cue"><span class="time">[60:42]</span>And then here, we have the UI/UX stuff.</p>
    <p class="cue"><span class="time">[60:45]</span>Everything UI/UX related goes here.</p>
    <p class="cue"><span class="time">[60:47]</span>And companies might structure it in very different ways.</p>
    <p class="cue"><span class="time">[60:51]</span>And here is the business logic that we want to care about.</p>
    <p class="cue"><span class="time">[60:53]</span>And there&#x27;s five engineers working on the business logic,</p>
    <p class="cue"><span class="time">[60:56]</span>let&#x27;s say.</p>
    <p class="cue"><span class="time">[60:59]</span>OK.</p>
    <p class="cue"><span class="time">[61:01]</span>Testing and debugging is also very different.</p>
    <p class="cue"><span class="time">[61:04]</span>And we&#x27;ll talk about it in the next section.</p>
    <p class="cue"><span class="time">[61:09]</span>The other thing that I feel matters</p>
    <p class="cue"><span class="time">[61:13]</span>is with AI in engineering, the cost of experimentation</p>
    <p class="cue"><span class="time">[61:17]</span>is going down drastically.</p>
    <p class="cue"><span class="time">[61:19]</span>And so people, I feel, should be more comfortable</p>
    <p class="cue"><span class="time">[61:22]</span>throwing away code.</p>
    <p class="cue"><span class="time">[61:23]</span>It&#x27;s like in traditional software engineering,</p>
    <p class="cue"><span class="time">[61:27]</span>you probably don&#x27;t throw away code a ton.</p>
    <p class="cue"><span class="time">[61:29]</span>You build a code, and it&#x27;s solid, and it&#x27;s bulletproof,</p>
    <p class="cue"><span class="time">[61:32]</span>and then you update it over time.</p>
    <p class="cue"><span class="time">[61:35]</span>We&#x27;ve seen AI companies be more comfortable throwing away</p>
    <p class="cue"><span class="time">[61:39]</span>codes, which has advantages in terms of the speed at which you</p>
    <p class="cue"><span class="time">[61:43]</span>move but also disadvantages in terms</p>
    <p class="cue"><span class="time">[61:46]</span>of the quality of your software that can break more.</p>
    <p class="cue"><span class="time">[61:52]</span>So anyway, just wanted to do an update on the paradigm shift</p>
    <p class="cue"><span class="time">[61:56]</span>from deterministic to fuzzy engineering.</p>
    <p class="cue"><span class="time">[62:04]</span>Oh, and actually, I can give you an example from Workera</p>
    <p class="cue"><span class="time">[62:08]</span>that we learned probably over the last 12</p>
    <p class="cue"><span class="time">[62:11]</span>months is like if you&#x27;ve used Workera,</p>
    <p class="cue"><span class="time">[62:13]</span>you might have seen that the interface has asks you sometimes</p>
    <p class="cue"><span class="time">[62:18]</span>multiple choice questions.</p>
    <p class="cue"><span class="time">[62:19]</span>And sometimes, it asks you multiple select.</p>
    <p class="cue"><span class="time">[62:21]</span>And sometimes, it asks you drag and drop, ordering, matching,</p>
    <p class="cue"><span class="time">[62:24]</span>whatever.</p>
    <p class="cue"><span class="time">[62:25]</span>Those are examples of deterministic item types,</p>
    <p class="cue"><span class="time">[62:28]</span>meaning you answer the question on a multiple choice.</p>
    <p class="cue"><span class="time">[62:31]</span>There is one correct answer.</p>
    <p class="cue"><span class="time">[62:32]</span>It&#x27;s fully deterministic.</p>
    <p class="cue"><span class="time">[62:34]</span>On the other hand, you sometimes have a voice questions,</p>
    <p class="cue"><span class="time">[62:38]</span>where you go to a role play or you</p>
    <p class="cue"><span class="time">[62:40]</span>have voice plus coding questions,</p>
    <p class="cue"><span class="time">[62:42]</span>where your code is being read by the interface or whatever.</p>
    <p class="cue"><span class="time">[62:45]</span>Those are fuzzy, meaning the scoring algorithm</p>
    <p class="cue"><span class="time">[62:49]</span>might actually make mistakes, and those mistakes</p>
    <p class="cue"><span class="time">[62:52]</span>might be costly.</p>
    <p class="cue"><span class="time">[62:53]</span>And so companies have to figure out</p>
    <p class="cue"><span class="time">[62:56]</span>a human in the loop system, which</p>
    <p class="cue"><span class="time">[62:58]</span>you might have seen with the appeal feature at the end.</p>
    <p class="cue"><span class="time">[63:00]</span>So at the end of the assessment, you have an appeal feature where</p>
    <p class="cue"><span class="time">[63:03]</span>it allows you to say, I want to appeal the agent</p>
    <p class="cue"><span class="time">[63:06]</span>because I want to challenge what the agent said on my answer</p>
    <p class="cue"><span class="time">[63:09]</span>because I thought I was better than what the agent thought.</p>
    <p class="cue"><span class="time">[63:12]</span>And then you bring the human in the loop that</p>
    <p class="cue"><span class="time">[63:14]</span>then can fix the agent, can tell the agent, actually,</p>
    <p class="cue"><span class="time">[63:16]</span>you were too harsh on the answer of this person.</p>
    <p class="cue"><span class="time">[63:20]</span>And that&#x27;s an example of a fuzzy engineered system</p>
    <p class="cue"><span class="time">[63:24]</span>that then adds a human in the loop to make it more aligned.</p>
    <p class="cue"><span class="time">[63:28]</span>And so if you&#x27;re building a company,</p>
    <p class="cue"><span class="time">[63:29]</span>I would encourage you to think about what can I</p>
    <p class="cue"><span class="time">[63:32]</span>get done with determinism?</p>
    <p class="cue"><span class="time">[63:33]</span>And let&#x27;s get that done.</p>
    <p class="cue"><span class="time">[63:35]</span>And then the fuzzy stuff, I want to do fuzzy</p>
    <p class="cue"><span class="time">[63:38]</span>because it allows more interaction.</p>
    <p class="cue"><span class="time">[63:39]</span>It allows more back and forth, but I need</p>
    <p class="cue"><span class="time">[63:42]</span>to put guardrails around it.</p>
    <p class="cue"><span class="time">[63:43]</span>And how am I going to design those guardrails?</p>
    <p class="cue"><span class="time">[63:45]</span>Pretty much.</p>
    <p class="cue"><span class="time">[63:46]</span>OK?</p>
    <p class="cue"><span class="time">[63:49]</span>Here&#x27;s another example from enterprise workflows,</p>
    <p class="cue"><span class="time">[63:54]</span>which are likely to change due to agentic AI.</p>
    <p class="cue"><span class="time">[63:57]</span>This is a paper from McKinsey, I believe from last year,</p>
    <p class="cue"><span class="time">[64:01]</span>where they looked at a financial institution, and they said,</p>
    <p class="cue"><span class="time">[64:05]</span>we observed that they often spend one to four weeks</p>
    <p class="cue"><span class="time">[64:07]</span>to create a credit risk memo.</p>
    <p class="cue"><span class="time">[64:10]</span>And here&#x27;s the process.</p>
    <p class="cue"><span class="time">[64:11]</span>A relationship manager gathers data from 15</p>
    <p class="cue"><span class="time">[64:16]</span>and more than 15 sources on the borrower,</p>
    <p class="cue"><span class="time">[64:19]</span>loan type, other factors.</p>
    <p class="cue"><span class="time">[64:22]</span>Then the relationship manager and the credit analyst</p>
    <p class="cue"><span class="time">[64:25]</span>collaboratively analyze that data from these sources.</p>
    <p class="cue"><span class="time">[64:28]</span>Then the credit analyst typically spends 20 hours</p>
    <p class="cue"><span class="time">[64:33]</span>or more writing a memo and then goes back</p>
    <p class="cue"><span class="time">[64:36]</span>to the relationship manager.</p>
    <p class="cue"><span class="time">[64:37]</span>They give feedback, and then they go through this loop</p>
    <p class="cue"><span class="time">[64:40]</span>again and again.</p>
    <p class="cue"><span class="time">[64:41]</span>And it takes a long time to get a credit memo out.</p>
    <p class="cue"><span class="time">[64:46]</span>And then run a research study, where they changed the process.</p>
    <p class="cue"><span class="time">[64:50]</span>They said gen AI agents could actually cut time by 20% to 60%</p>
    <p class="cue"><span class="time">[64:56]</span>on credit risk memos.</p>
    <p class="cue"><span class="time">[64:58]</span>And the process has changed to the relationship manager,</p>
    <p class="cue"><span class="time">[65:01]</span>directly work with the Gen AI agent system,</p>
    <p class="cue"><span class="time">[65:03]</span>provides relevant materials that needs to produce the memo.</p>
    <p class="cue"><span class="time">[65:07]</span>The agent subsidizes the project into tasks</p>
    <p class="cue"><span class="time">[65:10]</span>that are assigned to specialist agents,</p>
    <p class="cue"><span class="time">[65:12]</span>gathers and analyzes the data from multiple sources,</p>
    <p class="cue"><span class="time">[65:15]</span>drafts a memo.</p>
    <p class="cue"><span class="time">[65:16]</span>Then the relationship manager and the credit analyst</p>
    <p class="cue"><span class="time">[65:19]</span>sit down together, review the memo,</p>
    <p class="cue"><span class="time">[65:20]</span>give feedback to the agent.</p>
    <p class="cue"><span class="time">[65:22]</span>And within 20% to 60% less time are done.</p>
    <p class="cue"><span class="time">[65:26]</span>And so this is an example where you&#x27;re actually not changing</p>
    <p class="cue"><span class="time">[65:30]</span>the human stakeholders.</p>
    <p class="cue"><span class="time">[65:31]</span>You&#x27;re just changing the process and adding</p>
    <p class="cue"><span class="time">[65:33]</span>Gen AI to reduce the time it takes to get a credit memo out.</p>
    <p class="cue"><span class="time">[65:38]</span>It turns out that, imagine you&#x27;re an enterprise,</p>
    <p class="cue"><span class="time">[65:42]</span>and you have 100,000 employees, and there&#x27;s a lot of enterprises</p>
    <p class="cue"><span class="time">[65:47]</span>with 100,000 employees out there.</p>
    <p class="cue"><span class="time">[65:50]</span>You are currently under crisis in terms</p>
    <p class="cue"><span class="time">[65:52]</span>of redesigning your workflows.</p>
    <p class="cue"><span class="time">[65:55]</span>It turns out that if you actually</p>
    <p class="cue"><span class="time">[65:57]</span>pull the job descriptions from the HR system</p>
    <p class="cue"><span class="time">[66:00]</span>and you interpret them, you also pull</p>
    <p class="cue"><span class="time">[66:02]</span>the business process workflows that you</p>
    <p class="cue"><span class="time">[66:04]</span>have encoded in your drive.</p>
    <p class="cue"><span class="time">[66:07]</span>You actually can find gains in multiple places.</p>
    <p class="cue"><span class="time">[66:10]</span>And in the next few years, you&#x27;re</p>
    <p class="cue"><span class="time">[66:12]</span>probably going to see workflows being</p>
    <p class="cue"><span class="time">[66:14]</span>more optimized to add Gen AI.</p>
    <p class="cue"><span class="time">[66:17]</span>Even if that happens, the hardest part is changing people.</p>
    <p class="cue"><span class="time">[66:20]</span>What we know, this is great in theory, but now,</p>
    <p class="cue"><span class="time">[66:23]</span>let&#x27;s try to fit that second workflow for 10,000 credits,</p>
    <p class="cue"><span class="time">[66:28]</span>risk analysts, and relationship managers.</p>
    <p class="cue"><span class="time">[66:31]</span>My guess is it will take years.</p>
    <p class="cue"><span class="time">[66:33]</span>It will take 10, 20 years to get to this being actually done</p>
    <p class="cue"><span class="time">[66:37]</span>at scale within an organization.</p>
    <p class="cue"><span class="time">[66:40]</span>Because change is so hard.</p>
    <p class="cue"><span class="time">[66:42]</span>It&#x27;s so hard to rewire business, workflows, job descriptions,</p>
    <p class="cue"><span class="time">[66:47]</span>incentivize people to do different, and be different,</p>
    <p class="cue"><span class="time">[66:50]</span>and train them.</p>
    <p class="cue"><span class="time">[66:50]</span>And so this is what the world is going towards,</p>
    <p class="cue"><span class="time">[66:55]</span>but it&#x27;s going to take a long time I think.</p>
    <p class="cue"><span class="time">[66:59]</span>OK.</p>
    <p class="cue"><span class="time">[67:00]</span>Then I want to talk about how the agent actually works</p>
    <p class="cue"><span class="time">[67:02]</span>and what are the core components of an agent.</p>
    <p class="cue"><span class="time">[67:07]</span>Imagine a travel booking agent. that&#x27;s</p>
    <p class="cue"><span class="time">[67:10]</span>an easy example you&#x27;ve all thought about.</p>
    <p class="cue"><span class="time">[67:12]</span>I still haven&#x27;t been able to get an agent to book a trip for me,</p>
    <p class="cue"><span class="time">[67:16]</span>or I was scared because it was going to book</p>
    <p class="cue"><span class="time">[67:18]</span>a very expensive or long trip.</p>
    <p class="cue"><span class="time">[67:20]</span>But in theory, you can have a travel booking</p>
    <p class="cue"><span class="time">[67:24]</span>agent that has prompts.</p>
    <p class="cue"><span class="time">[67:26]</span>So the prompts we&#x27;ve seen, we know the methods</p>
    <p class="cue"><span class="time">[67:28]</span>to optimize those prompts.</p>
    <p class="cue"><span class="time">[67:30]</span>That travel agent also has a context management system,</p>
    <p class="cue"><span class="time">[67:34]</span>which is essentially the memory of what it knows about the user.</p>
    <p class="cue"><span class="time">[67:38]</span>That context management system might</p>
    <p class="cue"><span class="time">[67:40]</span>include a core memory or working memory and an archival memory,</p>
    <p class="cue"><span class="time">[67:45]</span>OK?</p>
    <p class="cue"><span class="time">[67:46]</span>What the difference is within memory</p>
    <p class="cue"><span class="time">[67:51]</span>is not every memory needs to be fast to access.</p>
    <p class="cue"><span class="time">[67:54]</span>Think about it.</p>
    <p class="cue"><span class="time">[67:56]</span>You&#x27;re onboarded on a product, and the first question is hi,</p>
    <p class="cue"><span class="time">[67:59]</span>what&#x27;s your name?</p>
    <p class="cue"><span class="time">[68:00]</span>And I say, my name is Keon.</p>
    <p class="cue"><span class="time">[68:02]</span>That&#x27;s probably going to sit in the working memory</p>
    <p class="cue"><span class="time">[68:05]</span>because the agents, every time he&#x27;s going to talk to me,</p>
    <p class="cue"><span class="time">[68:07]</span>he&#x27;s going to want to use my name.</p>
    <p class="cue"><span class="time">[68:08]</span>But then maybe the second question</p>
    <p class="cue"><span class="time">[68:10]</span>is what&#x27;s your birthday?</p>
    <p class="cue"><span class="time">[68:12]</span>And I give it my birthday.</p>
    <p class="cue"><span class="time">[68:13]</span>Does it need my birthday every day?</p>
    <p class="cue"><span class="time">[68:15]</span>Probably not.</p>
    <p class="cue"><span class="time">[68:16]</span>So it&#x27;s probably going to park it on the long term</p>
    <p class="cue"><span class="time">[68:18]</span>memory or the archival memory.</p>
    <p class="cue"><span class="time">[68:20]</span>And those memories are slower to access.</p>
    <p class="cue"><span class="time">[68:24]</span>They&#x27;re farther down the stack.</p>
    <p class="cue"><span class="time">[68:26]</span>And that structure allows the agent</p>
    <p class="cue"><span class="time">[68:28]</span>to determine what&#x27;s the working memory,</p>
    <p class="cue"><span class="time">[68:30]</span>and what&#x27;s the long term memory?</p>
    <p class="cue"><span class="time">[68:33]</span>And that makes it easier for the agent to retrieve super fast.</p>
    <p class="cue"><span class="time">[68:36]</span>Because think about it.</p>
    <p class="cue"><span class="time">[68:37]</span>When you interact with ChatGPT, you</p>
    <p class="cue"><span class="time">[68:39]</span>feel that it&#x27;s very personal at times.</p>
    <p class="cue"><span class="time">[68:41]</span>You feel like it understands you.</p>
    <p class="cue"><span class="time">[68:43]</span>Imagine every time you call it, it has to read the memories.</p>
    <p class="cue"><span class="time">[68:47]</span>And that can be costly.</p>
    <p class="cue"><span class="time">[68:48]</span>It&#x27;s a very burdensome cost because it happens</p>
    <p class="cue"><span class="time">[68:52]</span>every time you talk to it.</p>
    <p class="cue"><span class="time">[68:54]</span>So you want to be highly optimized with the working</p>
    <p class="cue"><span class="time">[68:57]</span>memory.</p>
    <p class="cue"><span class="time">[68:59]</span>If it takes three seconds to look</p>
    <p class="cue"><span class="time">[69:00]</span>in the memory, every time you&#x27;re going to talk to your LLM,</p>
    <p class="cue"><span class="time">[69:03]</span>it&#x27;s going to take three seconds, which you don&#x27;t want.</p>
    <p class="cue"><span class="time">[69:06]</span>Anyway.</p>
    <p class="cue"><span class="time">[69:06]</span>And then you have the tools.</p>
    <p class="cue"><span class="time">[69:08]</span>The tools can include APIs like a flight search</p>
    <p class="cue"><span class="time">[69:11]</span>API, hotel booking API, car rental API, weather API,</p>
    <p class="cue"><span class="time">[69:15]</span>and then the payment processing API.</p>
    <p class="cue"><span class="time">[69:18]</span>And typically, you would want to tell your agent</p>
    <p class="cue"><span class="time">[69:21]</span>how that API works.</p>
    <p class="cue"><span class="time">[69:23]</span>It turns out that agents or LLMs, I should say,</p>
    <p class="cue"><span class="time">[69:27]</span>are very good at reading API documentation.</p>
    <p class="cue"><span class="time">[69:29]</span>So you give it the API documentation,</p>
    <p class="cue"><span class="time">[69:31]</span>and it reads the JSON, and it reads,</p>
    <p class="cue"><span class="time">[69:33]</span>what does a GET request look like.</p>
    <p class="cue"><span class="time">[69:35]</span>And this is the format that I need to push.</p>
    <p class="cue"><span class="time">[69:38]</span>And then it pushes it in that format, let&#x27;s say.</p>
    <p class="cue"><span class="time">[69:41]</span>And then it retrieves something.</p>
    <p class="cue"><span class="time">[69:45]</span>Does that make sense, those different components?</p>
    <p class="cue"><span class="time">[69:49]</span>Anthropic also talks about resources.</p>
    <p class="cue"><span class="time">[69:51]</span>Resources is data that is sitting somewhere that you</p>
    <p class="cue"><span class="time">[69:55]</span>might let your agent read.</p>
    <p class="cue"><span class="time">[69:57]</span>For example, if you&#x27;re building your startups, you have a CRM.</p>
    <p class="cue"><span class="time">[70:00]</span>A CRM has data in it, and you want to do lookups in that data.</p>
    <p class="cue"><span class="time">[70:05]</span>You will probably give a lookup tool,</p>
    <p class="cue"><span class="time">[70:07]</span>and you will give access to the resource,</p>
    <p class="cue"><span class="time">[70:10]</span>and it will do lookups whenever you want super fast.</p>
    <p class="cue"><span class="time">[70:16]</span>This type of architecture can be built</p>
    <p class="cue"><span class="time">[70:19]</span>with different degrees of autonomy,</p>
    <p class="cue"><span class="time">[70:21]</span>from the least autonomous to the most autonomous.</p>
    <p class="cue"><span class="time">[70:23]</span>And I&#x27;ll give you a few examples.</p>
    <p class="cue"><span class="time">[70:26]</span>Less autonomous would be you&#x27;ve hard coded the steps.</p>
    <p class="cue"><span class="time">[70:29]</span>So let&#x27;s say I tell the travel agent first identify the intent.</p>
    <p class="cue"><span class="time">[70:35]</span>Then look up in the database the history</p>
    <p class="cue"><span class="time">[70:39]</span>of this customer with us and their preferences.</p>
    <p class="cue"><span class="time">[70:42]</span>Then go to the flight API, blah, blah, blah.</p>
    <p class="cue"><span class="time">[70:45]</span>Then go to the--</p>
    <p class="cue"><span class="time">[70:45]</span>I would hard code the steps.</p>
    <p class="cue"><span class="time">[70:47]</span>OK.</p>
    <p class="cue"><span class="time">[70:48]</span>That&#x27;s the least autonomous.</p>
    <p class="cue"><span class="time">[70:50]</span>The semi-autonomous is I might hard code the tools,</p>
    <p class="cue"><span class="time">[70:54]</span>but we&#x27;re not going to hard code the steps.</p>
    <p class="cue"><span class="time">[70:57]</span>So I&#x27;m going to tell the agent, you act like a travel agent.</p>
    <p class="cue"><span class="time">[71:02]</span>And your task is to help the person book a travel.</p>
    <p class="cue"><span class="time">[71:10]</span>And these are the tools that you have accessible to yourself.</p>
    <p class="cue"><span class="time">[71:13]</span>And so I&#x27;m not hard coding the steps.</p>
    <p class="cue"><span class="time">[71:14]</span>I&#x27;m just hard coding the tools that you have access</p>
    <p class="cue"><span class="time">[71:17]</span>to for yourself.</p>
    <p class="cue"><span class="time">[71:18]</span>The more autonomous is the agent decides the steps</p>
    <p class="cue"><span class="time">[71:22]</span>and can create the tools.</p>
    <p class="cue"><span class="time">[71:24]</span>So that&#x27;s where you might give actually access</p>
    <p class="cue"><span class="time">[71:26]</span>to a code editor, to the agent.</p>
    <p class="cue"><span class="time">[71:28]</span>And the agent might actually be able to ping any API in the web,</p>
    <p class="cue"><span class="time">[71:33]</span>perform some web search.</p>
    <p class="cue"><span class="time">[71:34]</span>It might even be able to create some code</p>
    <p class="cue"><span class="time">[71:37]</span>to display data to the user.</p>
    <p class="cue"><span class="time">[71:39]</span>It might even be able to perform some calculations.</p>
    <p class="cue"><span class="time">[71:42]</span>Like oh, I&#x27;m going to calculate the fastest route</p>
    <p class="cue"><span class="time">[71:44]</span>to get from San Francisco to New York,</p>
    <p class="cue"><span class="time">[71:48]</span>and which one might be the most appropriate</p>
    <p class="cue"><span class="time">[71:50]</span>for what the user is looking for.</p>
    <p class="cue"><span class="time">[71:52]</span>And then I want to calculate the distance between the airport</p>
    <p class="cue"><span class="time">[71:54]</span>and that hotel versus that hotel.</p>
    <p class="cue"><span class="time">[71:56]</span>And I&#x27;m going to write code to do that.</p>
    <p class="cue"><span class="time">[71:58]</span>So it&#x27;s actually fully autonomous</p>
    <p class="cue"><span class="time">[72:00]</span>from that perspective.</p>
    <p class="cue"><span class="time">[72:05]</span>So yeah.</p>
    <p class="cue"><span class="time">[72:07]</span>Remember those keywords.</p>
    <p class="cue"><span class="time">[72:08]</span>Memory, prompts, tools, et cetera.</p>
    <p class="cue"><span class="time">[72:14]</span>Now, I presented the flight API, but it does not</p>
    <p class="cue"><span class="time">[72:18]</span>have to be an API.</p>
    <p class="cue"><span class="time">[72:19]</span>You probably have heard the term MCP or model context protocol</p>
    <p class="cue"><span class="time">[72:23]</span>that was coined by Anthropic.</p>
    <p class="cue"><span class="time">[72:25]</span>I pasted the seminal article on MCP at the bottom of this slide.</p>
    <p class="cue"><span class="time">[72:29]</span>But let me explain in a nutshell why those things would differ.</p>
    <p class="cue"><span class="time">[72:34]</span>In the API case, you would actually</p>
    <p class="cue"><span class="time">[72:39]</span>teach your LLM to ping an API.</p>
    <p class="cue"><span class="time">[72:42]</span>So you would say this is how you ping this API,</p>
    <p class="cue"><span class="time">[72:45]</span>and this is the data that it will send you back.</p>
    <p class="cue"><span class="time">[72:48]</span>And you would have to do that in a one off manner.</p>
    <p class="cue"><span class="time">[72:51]</span>So you would have to build or give</p>
    <p class="cue"><span class="time">[72:53]</span>the API documentation of your flight API.</p>
    <p class="cue"><span class="time">[72:56]</span>You&#x27;re booking hotel API, your car rental API.</p>
    <p class="cue"><span class="time">[73:00]</span>And then you would give tools for your model</p>
    <p class="cue"><span class="time">[73:03]</span>to communicate with those APIs.</p>
    <p class="cue"><span class="time">[73:06]</span>It doesn&#x27;t scale very well versus MCP.</p>
    <p class="cue"><span class="time">[73:11]</span>MCP, it&#x27;s really about putting a system in the middle that</p>
    <p class="cue"><span class="time">[73:19]</span>would make it simpler for your LLM to communicate</p>
    <p class="cue"><span class="time">[73:22]</span>with that endpoint.</p>
    <p class="cue"><span class="time">[73:23]</span>So for instance, you might have an MCP server, an MC client,</p>
    <p class="cue"><span class="time">[73:28]</span>where you&#x27;re trying to communicate</p>
    <p class="cue"><span class="time">[73:30]</span>with that travel database or the flight API or MCP.</p>
    <p class="cue"><span class="time">[73:35]</span>And your agent might actually just communicate with it</p>
    <p class="cue"><span class="time">[73:38]</span>and say, hey, what do you need in order to give me more flight</p>
    <p class="cue"><span class="time">[73:42]</span>information?</p>
    <p class="cue"><span class="time">[73:43]</span>And that agent will respond by I would like you to tell me</p>
    <p class="cue"><span class="time">[73:47]</span>where is the origin flight, where is the destination</p>
    <p class="cue"><span class="time">[73:49]</span>and what you&#x27;re looking for at a high level.</p>
    <p class="cue"><span class="time">[73:51]</span>This is my requirement.</p>
    <p class="cue"><span class="time">[73:52]</span>OK.</p>
    <p class="cue"><span class="time">[73:52]</span>Let me get back to you with in my requirement.</p>
    <p class="cue"><span class="time">[73:55]</span>Oh.</p>
    <p class="cue"><span class="time">[73:55]</span>You forgot to tell me your budget, whatever.</p>
    <p class="cue"><span class="time">[73:57]</span>Oh.</p>
    <p class="cue"><span class="time">[73:58]</span>Let me give you my budget, et cetera.</p>
    <p class="cue"><span class="time">[74:00]</span>And it&#x27;s agent to agent communication,</p>
    <p class="cue"><span class="time">[74:04]</span>which allows more scalability.</p>
    <p class="cue"><span class="time">[74:06]</span>You don&#x27;t need to hard code everything.</p>
    <p class="cue"><span class="time">[74:09]</span>Companies have displayed their MCPs out there,</p>
    <p class="cue"><span class="time">[74:11]</span>and your agent can communicate with them</p>
    <p class="cue"><span class="time">[74:14]</span>and figure out how to get the data it needs.</p>
    <p class="cue"><span class="time">[74:16]</span>Does that make sense?</p>
    <p class="cue"><span class="time">[74:18]</span>Yeah.</p>
    <p class="cue"><span class="time">[74:21]</span>[INAUDIBLE] rewriting any [INAUDIBLE]</p>
    <p class="cue"><span class="time">[74:36]</span>I think it is, ultimately.</p>
    <p class="cue"><span class="time">[74:39]</span>The question is, isn&#x27;t it a shifting issue?</p>
    <p class="cue"><span class="time">[74:41]</span>Because anyway, if an API has to be updated,</p>
    <p class="cue"><span class="time">[74:43]</span>the MCP has to be updated, is what you say, right?</p>
    <p class="cue"><span class="time">[74:45]</span>Yes, that&#x27;s correct.</p>
    <p class="cue"><span class="time">[74:46]</span>But at least it allows the agent to go back and forth</p>
    <p class="cue"><span class="time">[74:51]</span>and figure out what the requirements are.</p>
    <p class="cue"><span class="time">[74:52]</span>But at the end of the day, ideally, if you&#x27;re a startup,</p>
    <p class="cue"><span class="time">[74:56]</span>you have some documentation.</p>
    <p class="cue"><span class="time">[74:57]</span>And automatically, you have an agent or an LLM workflow</p>
    <p class="cue"><span class="time">[75:00]</span>that reads that documentation and updates the code</p>
    <p class="cue"><span class="time">[75:03]</span>accordingly.</p>
    <p class="cue"><span class="time">[75:04]</span>But I agree.</p>
    <p class="cue"><span class="time">[75:05]</span>It&#x27;s not something that is fully autonomous.</p>
    <p class="cue"><span class="time">[75:08]</span>Yeah.</p>
    <p class="cue"><span class="time">[75:09]</span>i I&#x27;ve seen some security issues.</p>
    <p class="cue"><span class="time">[75:12]</span>Why is that possible.</p>
    <p class="cue"><span class="time">[75:14]</span>Which security specifically?</p>
    <p class="cue"><span class="time">[75:16]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[75:18]</span>Yeah.</p>
    <p class="cue"><span class="time">[75:19]</span>So are there security issues with MCPs?</p>
    <p class="cue"><span class="time">[75:23]</span>So think about it this way.</p>
    <p class="cue"><span class="time">[75:25]</span>MCPs, depending on the data that you get access to,</p>
    <p class="cue"><span class="time">[75:28]</span>might have different requirements, lower stake</p>
    <p class="cue"><span class="time">[75:30]</span>or higher stake.</p>
    <p class="cue"><span class="time">[75:31]</span>I&#x27;m not an expert at the full range.</p>
    <p class="cue"><span class="time">[75:34]</span>But it wouldn&#x27;t surprise me that when you expose an MCP to--</p>
    <p class="cue"><span class="time">[75:42]</span>I think you would a lot of MCC have authentication.</p>
    <p class="cue"><span class="time">[75:45]</span>So you might actually need a code</p>
    <p class="cue"><span class="time">[75:47]</span>to actually talk to it, just like you would with an API,</p>
    <p class="cue"><span class="time">[75:50]</span>or a key.</p>
    <p class="cue"><span class="time">[75:52]</span>Yeah, but that&#x27;s a good question.</p>
    <p class="cue"><span class="time">[75:53]</span>I&#x27;m not an expert at the security of these systems,</p>
    <p class="cue"><span class="time">[75:56]</span>but we can look into it.</p>
    <p class="cue"><span class="time">[76:02]</span>Any other questions on what we&#x27;ve</p>
    <p class="cue"><span class="time">[76:04]</span>seen with the agentic workflows, APIs, tools, MCPs, memory?</p>
    <p class="cue"><span class="time">[76:10]</span>All of that is under progress.</p>
    <p class="cue"><span class="time">[76:11]</span>So even memory is not a solved problem by any means.</p>
    <p class="cue"><span class="time">[76:14]</span>It&#x27;s pretty hard actually.</p>
    <p class="cue"><span class="time">[76:16]</span>Yes.</p>
    <p class="cue"><span class="time">[76:18]</span>You don&#x27;t need an [INAUDIBLE] The MCP just</p>
    <p class="cue"><span class="time">[76:24]</span>makes it easier to access the API, but technically,</p>
    <p class="cue"><span class="time">[76:28]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[76:40]</span>Exactly, exactly.</p>
    <p class="cue"><span class="time">[76:42]</span>Is MCP about efficiency or accessing more data?</p>
    <p class="cue"><span class="time">[76:45]</span>It&#x27;s about efficiency.</p>
    <p class="cue"><span class="time">[76:47]</span>Let&#x27;s say you have a coding agent, and it has an MCP client,</p>
    <p class="cue"><span class="time">[76:53]</span>and there&#x27;s multiple MCP servers that are exposed out there.</p>
    <p class="cue"><span class="time">[76:57]</span>That agent can communicate very efficiently with them</p>
    <p class="cue"><span class="time">[77:00]</span>and find what it needs.</p>
    <p class="cue"><span class="time">[77:03]</span>And it&#x27;s a more efficient process</p>
    <p class="cue"><span class="time">[77:05]</span>than actually displaying APIs and the APIs on that side</p>
    <p class="cue"><span class="time">[77:09]</span>and how to ping them and what the protocol is.</p>
    <p class="cue"><span class="time">[77:12]</span>But it&#x27;s not about the data that is</p>
    <p class="cue"><span class="time">[77:13]</span>being exposed because ultimately, you control</p>
    <p class="cue"><span class="time">[77:15]</span>the data that is being exposed.</p>
    <p class="cue"><span class="time">[77:19]</span>You probably, depending on how the MCP is built,</p>
    <p class="cue"><span class="time">[77:22]</span>my guess is you probably expose yourself to other risks</p>
    <p class="cue"><span class="time">[77:24]</span>because your MCP server can see any input pretty much</p>
    <p class="cue"><span class="time">[77:31]</span>from another LLM.</p>
    <p class="cue"><span class="time">[77:32]</span>And so it has to be robust.</p>
    <p class="cue"><span class="time">[77:36]</span>But yeah.</p>
    <p class="cue"><span class="time">[77:37]</span>Super.</p>
    <p class="cue"><span class="time">[77:39]</span>So let&#x27;s look at an example of a step</p>
    <p class="cue"><span class="time">[77:41]</span>by step workflow for the travel agent.</p>
    <p class="cue"><span class="time">[77:45]</span>So let&#x27;s say the user says, I want to plan a trip to Paris</p>
    <p class="cue"><span class="time">[77:50]</span>from December 15 to 20th with flights,</p>
    <p class="cue"><span class="time">[77:56]</span>hotels near the Eiffel Tower, and then an itinerary of must</p>
    <p class="cue"><span class="time">[78:00]</span>visit places.</p>
    <p class="cue"><span class="time">[78:01]</span>That&#x27;s the task to the travel agent.</p>
    <p class="cue"><span class="time">[78:04]</span>Step two, the agent plans the steps.</p>
    <p class="cue"><span class="time">[78:06]</span>So it says, I&#x27;m going to find flights.</p>
    <p class="cue"><span class="time">[78:08]</span>Use the flight search API to get options for December 15.</p>
    <p class="cue"><span class="time">[78:12]</span>Search hotels, generate recommendations for places</p>
    <p class="cue"><span class="time">[78:15]</span>to visit, validate preferences, budget, et cetera.</p>
    <p class="cue"><span class="time">[78:20]</span>Book the trip with the payment processing API.</p>
    <p class="cue"><span class="time">[78:24]</span>That&#x27;s just the planning, by the way.</p>
    <p class="cue"><span class="time">[78:25]</span>Step three, execute the plan, use your tools,</p>
    <p class="cue"><span class="time">[78:28]</span>combine the results, and then proactive</p>
    <p class="cue"><span class="time">[78:31]</span>user interaction and booking.</p>
    <p class="cue"><span class="time">[78:33]</span>It might make a first proposal to the user</p>
    <p class="cue"><span class="time">[78:35]</span>and ask the user to validate or invalidate</p>
    <p class="cue"><span class="time">[78:38]</span>and then may repeat that planning and execution process.</p>
    <p class="cue"><span class="time">[78:42]</span>And then finally, it might actually update the memory.</p>
    <p class="cue"><span class="time">[78:46]</span>It might say, oh, I just learned through this interaction</p>
    <p class="cue"><span class="time">[78:49]</span>that the user only likes direct flights.</p>
    <p class="cue"><span class="time">[78:51]</span>Next time, I&#x27;ll only give direct flights.</p>
    <p class="cue"><span class="time">[78:55]</span>Or I noticed users are fine with three star hotels or four star</p>
    <p class="cue"><span class="time">[79:01]</span>hotels.</p>
    <p class="cue"><span class="time">[79:01]</span>And in fact, they don&#x27;t want to go above budget or something</p>
    <p class="cue"><span class="time">[79:05]</span>like that.</p>
    <p class="cue"><span class="time">[79:08]</span>So that hopefully makes sense by now on how you might do that.</p>
    <p class="cue"><span class="time">[79:11]</span>My question for you is how would you know if this works.</p>
    <p class="cue"><span class="time">[79:16]</span>And if you had such a system running in production, how</p>
    <p class="cue"><span class="time">[79:19]</span>would you improve it?</p>
    <p class="cue"><span class="time">[79:28]</span>Yeah.</p>
    <p class="cue"><span class="time">[79:28]</span>Lets users rate their experience.</p>
    <p class="cue"><span class="time">[79:31]</span>So that&#x27;s an example.</p>
    <p class="cue"><span class="time">[79:33]</span>So let users rate their experience at the end.</p>
    <p class="cue"><span class="time">[79:37]</span>That would be an end to end test, right?</p>
    <p class="cue"><span class="time">[79:39]</span>You&#x27;re looking at the user experience through the steps</p>
    <p class="cue"><span class="time">[79:42]</span>and say how good was it from 1 to 5, let&#x27;s say.</p>
    <p class="cue"><span class="time">[79:46]</span>Yeah.</p>
    <p class="cue"><span class="time">[79:46]</span>It&#x27;s a good way.</p>
    <p class="cue"><span class="time">[79:47]</span>And then if you learn that a user says 1,</p>
    <p class="cue"><span class="time">[79:50]</span>how do you improve the workflow?</p>
    <p class="cue"><span class="time">[79:56]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[79:59]</span>OK.</p>
    <p class="cue"><span class="time">[79:59]</span>So you would go down a tree and say, OK, you said 1.</p>
    <p class="cue"><span class="time">[80:04]</span>What was your issue?</p>
    <p class="cue"><span class="time">[80:06]</span>And then the user says the prices were too high, let&#x27;s say.</p>
    <p class="cue"><span class="time">[80:10]</span>And then you would go back and fix that specific tool or prompt</p>
    <p class="cue"><span class="time">[80:14]</span>or, yeah, OK.</p>
    <p class="cue"><span class="time">[80:15]</span>Any other ideas?</p>
    <p class="cue"><span class="time">[80:18]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[80:29]</span>Yeah, good.</p>
    <p class="cue"><span class="time">[80:29]</span>So that&#x27;s a good insight.</p>
    <p class="cue"><span class="time">[80:30]</span>Separate the LLM related stuff from the non-LLM related stuff,</p>
    <p class="cue"><span class="time">[80:34]</span>the deterministic stuff.</p>
    <p class="cue"><span class="time">[80:35]</span>The deterministic stuff, you might</p>
    <p class="cue"><span class="time">[80:36]</span>be able to fix it more objectively essentially.</p>
    <p class="cue"><span class="time">[80:41]</span>Yeah.</p>
    <p class="cue"><span class="time">[80:43]</span>What else?</p>
    <p class="cue"><span class="time">[80:56]</span>So give me an example of an objective issue</p>
    <p class="cue"><span class="time">[81:00]</span>that you can notice and how you would fix it</p>
    <p class="cue"><span class="time">[81:03]</span>versus a subjective issue.</p>
    <p class="cue"><span class="time">[81:06]</span>Yeah.</p>
    <p class="cue"><span class="time">[81:06]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[81:16]</span>So let&#x27;s say you say there&#x27;s the same flight,</p>
    <p class="cue"><span class="time">[81:19]</span>but one is cheaper than the other, let&#x27;s say.</p>
    <p class="cue"><span class="time">[81:21]</span>It&#x27;s objectively worse.</p>
    <p class="cue"><span class="time">[81:23]</span>And so you can capture that almost automatically.</p>
    <p class="cue"><span class="time">[81:25]</span>Yeah.</p>
    <p class="cue"><span class="time">[81:26]</span>So you could actually build evals</p>
    <p class="cue"><span class="time">[81:27]</span>that are objective, that are tracked across your users.</p>
    <p class="cue"><span class="time">[81:32]</span>And you might actually run an analysis after</p>
    <p class="cue"><span class="time">[81:34]</span>and see that for the objective stuff,</p>
    <p class="cue"><span class="time">[81:37]</span>we notice that our LLM AI agent workflow is bad with pricing.</p>
    <p class="cue"><span class="time">[81:43]</span>It just doesn&#x27;t read price as well because it always</p>
    <p class="cue"><span class="time">[81:46]</span>gives a more expensive option.</p>
    <p class="cue"><span class="time">[81:48]</span>Yeah.</p>
    <p class="cue"><span class="time">[81:48]</span>You&#x27;re perfectly right.</p>
    <p class="cue"><span class="time">[81:49]</span>How about the subjective stuff?</p>
    <p class="cue"><span class="time">[81:59]</span>Do you choose a direct or indirect flight</p>
    <p class="cue"><span class="time">[82:01]</span>if the indirect is a little bit cheaper?</p>
    <p class="cue"><span class="time">[82:05]</span>Yeah.</p>
    <p class="cue"><span class="time">[82:05]</span>Good one.</p>
    <p class="cue"><span class="time">[82:06]</span>Do you choose a direct flight or an indirect flight</p>
    <p class="cue"><span class="time">[82:09]</span>if the indirect is cheaper but the direct is more comfortable?</p>
    <p class="cue"><span class="time">[82:12]</span>Yeah.</p>
    <p class="cue"><span class="time">[82:13]</span>That&#x27;s a good one actually.</p>
    <p class="cue"><span class="time">[82:16]</span>So how would you capture that information.</p>
    <p class="cue"><span class="time">[82:18]</span>Let&#x27;s say this is used by thousands of users.</p>
    <p class="cue"><span class="time">[82:24]</span>Could you feed something in [INAUDIBLE]</p>
    <p class="cue"><span class="time">[82:28]</span>Could you feed something in?</p>
    <p class="cue"><span class="time">[82:30]</span>Yeah, I mean, you could--</p>
    <p class="cue"><span class="time">[82:32]</span>could feed something in about the user preferences?</p>
    <p class="cue"><span class="time">[82:36]</span>Well, you could build a data set that</p>
    <p class="cue"><span class="time">[82:39]</span>has some of that information.</p>
    <p class="cue"><span class="time">[82:40]</span>So you build 10 prompts, where the user is asking specifically</p>
    <p class="cue"><span class="time">[82:44]</span>for a direct--</p>
    <p class="cue"><span class="time">[82:46]</span>saying that I prefer direct flights because I</p>
    <p class="cue"><span class="time">[82:48]</span>care about my time, let&#x27;s say.</p>
    <p class="cue"><span class="time">[82:50]</span>And then you look at the output and you actually</p>
    <p class="cue"><span class="time">[82:53]</span>give a good example of a good output,</p>
    <p class="cue"><span class="time">[82:56]</span>and you probably are able to capture</p>
    <p class="cue"><span class="time">[82:58]</span>the performance of your agentic workflow on this specific eval.</p>
    <p class="cue"><span class="time">[83:04]</span>Does it prioritize?</p>
    <p class="cue"><span class="time">[83:05]</span>Does it understand price conscious--</p>
    <p class="cue"><span class="time">[83:07]</span>is it price conscious, essentially,</p>
    <p class="cue"><span class="time">[83:08]</span>and comfort conscious?</p>
    <p class="cue"><span class="time">[83:10]</span>Yeah.</p>
    <p class="cue"><span class="time">[83:13]</span>What about the tone?</p>
    <p class="cue"><span class="time">[83:14]</span>Let&#x27;s say the LLM right now is not very friendly.</p>
    <p class="cue"><span class="time">[83:18]</span>How would you notice that, and how would you fix it?</p>
    <p class="cue"><span class="time">[83:26]</span>Yeah.</p>
    <p class="cue"><span class="time">[83:26]</span>Have the test user run the prompt</p>
    <p class="cue"><span class="time">[83:29]</span>and see if there&#x27;s something wrong with that.</p>
    <p class="cue"><span class="time">[83:33]</span>OK.</p>
    <p class="cue"><span class="time">[83:33]</span>Have a test user run the prompt and see if there&#x27;s</p>
    <p class="cue"><span class="time">[83:36]</span>something wrong with that.</p>
    <p class="cue"><span class="time">[83:37]</span>Tell me about the last step.</p>
    <p class="cue"><span class="time">[83:38]</span>How would you notice that something is wrong?</p>
    <p class="cue"><span class="time">[83:40]</span>So a couple of tests [INAUDIBLE] evaluates</p>
    <p class="cue"><span class="time">[83:48]</span>the response and [INAUDIBLE]</p>
    <p class="cue"><span class="time">[83:51]</span>Yeah.</p>
    <p class="cue"><span class="time">[83:52]</span>I agree with your approach.</p>
    <p class="cue"><span class="time">[83:53]</span>Have LLM judges that evaluate the response</p>
    <p class="cue"><span class="time">[83:55]</span>against a certain rubric of what politeness looks like.</p>
    <p class="cue"><span class="time">[83:58]</span>So here in this case, you could actually</p>
    <p class="cue"><span class="time">[84:00]</span>start with error analysis.</p>
    <p class="cue"><span class="time">[84:02]</span>So you start, you have 1,000 users.</p>
    <p class="cue"><span class="time">[84:05]</span>And you can pull up 20 user interactions</p>
    <p class="cue"><span class="time">[84:07]</span>and read through it.</p>
    <p class="cue"><span class="time">[84:09]</span>And you might notice, at first sight,</p>
    <p class="cue"><span class="time">[84:11]</span>the LLM seems to be very rude.</p>
    <p class="cue"><span class="time">[84:14]</span>It&#x27;s just super, super short in its answers,</p>
    <p class="cue"><span class="time">[84:18]</span>and it&#x27;s not very helpful.</p>
    <p class="cue"><span class="time">[84:20]</span>You notice that with your error analysis manually.</p>
    <p class="cue"><span class="time">[84:23]</span>Then you go to the next stage.</p>
    <p class="cue"><span class="time">[84:24]</span>You actually put evals behind it.</p>
    <p class="cue"><span class="time">[84:26]</span>You say, I&#x27;m going to create a set of LLM judges</p>
    <p class="cue"><span class="time">[84:33]</span>that are going to look at the user interaction</p>
    <p class="cue"><span class="time">[84:35]</span>and are going to rate how polite it is.</p>
    <p class="cue"><span class="time">[84:38]</span>And I&#x27;m going to give it a rubric.</p>
    <p class="cue"><span class="time">[84:40]</span>Then what I&#x27;m going to do is I&#x27;m going to flip my LLM.</p>
    <p class="cue"><span class="time">[84:42]</span>Instead of using GPT-4, I&#x27;m going to use Grok.</p>
    <p class="cue"><span class="time">[84:45]</span>And instead of using Grok, I&#x27;m using Llama.</p>
    <p class="cue"><span class="time">[84:48]</span>And then I&#x27;m going to run those three LLMs side by side,</p>
    <p class="cue"><span class="time">[84:51]</span>give it to my LLM judges, and then get my subjective score</p>
    <p class="cue"><span class="time">[84:56]</span>at the end to say, oh, x model was more polite on average.</p>
    <p class="cue"><span class="time">[85:02]</span>Yeah.</p>
    <p class="cue"><span class="time">[85:02]</span>Perfectly right.</p>
    <p class="cue"><span class="time">[85:03]</span>That&#x27;s an example of an eval that is very specific</p>
    <p class="cue"><span class="time">[85:05]</span>and allows you to choose between LLMs.</p>
    <p class="cue"><span class="time">[85:07]</span>You could actually do the same eval not across LLMs,</p>
    <p class="cue"><span class="time">[85:10]</span>but fixed the LLM, change the prompt.</p>
    <p class="cue"><span class="time">[85:12]</span>You actually, instead of saying act like a travel agent,</p>
    <p class="cue"><span class="time">[85:15]</span>you say act like a helpful travel agent.</p>
    <p class="cue"><span class="time">[85:17]</span>And then you see the influence of that word on your eval</p>
    <p class="cue"><span class="time">[85:21]</span>with the LLM as judges.</p>
    <p class="cue"><span class="time">[85:22]</span>Does that make sense?</p>
    <p class="cue"><span class="time">[85:24]</span>OK.</p>
    <p class="cue"><span class="time">[85:25]</span>Super.</p>
    <p class="cue"><span class="time">[85:26]</span>So let&#x27;s move forward and do a case study with evals.</p>
    <p class="cue"><span class="time">[85:29]</span>And then we&#x27;re almost done for today.</p>
    <p class="cue"><span class="time">[85:33]</span>Let&#x27;s say your product manager asks you to build an AI</p>
    <p class="cue"><span class="time">[85:38]</span>agent for customer support, OK?</p>
    <p class="cue"><span class="time">[85:41]</span>Where do you start?</p>
    <p class="cue"><span class="time">[85:42]</span>And here is an example of the user prompt.</p>
    <p class="cue"><span class="time">[85:45]</span>I need to change my shipping address for order, blah, blah,</p>
    <p class="cue"><span class="time">[85:48]</span>blah.</p>
    <p class="cue"><span class="time">[85:48]</span>I move to a new address.</p>
    <p class="cue"><span class="time">[85:51]</span>So what do you start if I&#x27;m giving you that project?</p>
    <p class="cue"><span class="time">[86:04]</span>Yes.</p>
    <p class="cue"><span class="time">[86:05]</span>We search online for existing models and [INAUDIBLE]</p>
    <p class="cue"><span class="time">[86:16]</span>So do some research.</p>
    <p class="cue"><span class="time">[86:17]</span>See benchmarks and how different models</p>
    <p class="cue"><span class="time">[86:20]</span>perform at customer support.</p>
    <p class="cue"><span class="time">[86:22]</span>And then pick a model.</p>
    <p class="cue"><span class="time">[86:23]</span>That&#x27;s what you mean.</p>
    <p class="cue"><span class="time">[86:24]</span>Yeah.</p>
    <p class="cue"><span class="time">[86:24]</span>It&#x27;s true you could do that.</p>
    <p class="cue"><span class="time">[86:25]</span>What else could you do?</p>
    <p class="cue"><span class="time">[86:28]</span>Yeah.</p>
    <p class="cue"><span class="time">[86:28]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[86:34]</span>OK.</p>
    <p class="cue"><span class="time">[86:34]</span>Yeah, I like that.</p>
    <p class="cue"><span class="time">[86:35]</span>Try to decompose the different tasks that it will need</p>
    <p class="cue"><span class="time">[86:39]</span>and try to guess which ones will be more of a struggle, which</p>
    <p class="cue"><span class="time">[86:42]</span>ones should be fuzzy, which ones should be deterministic.</p>
    <p class="cue"><span class="time">[86:45]</span>Yeah, you&#x27;re right.</p>
    <p class="cue"><span class="time">[86:46]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[86:55]</span>Yeah.</p>
    <p class="cue"><span class="time">[86:56]</span>Similar to what you said.</p>
    <p class="cue"><span class="time">[86:58]</span>That&#x27;s what I would recommend as well.</p>
    <p class="cue"><span class="time">[87:00]</span>You say I would sit down with a customer support</p>
    <p class="cue"><span class="time">[87:02]</span>agent for a day or two, and I would decompose the tasks</p>
    <p class="cue"><span class="time">[87:04]</span>that are going through.</p>
    <p class="cue"><span class="time">[87:05]</span>I will ask them, where do they struggle?</p>
    <p class="cue"><span class="time">[87:07]</span>How much time it takes?</p>
    <p class="cue"><span class="time">[87:08]</span>Yes.</p>
    <p class="cue"><span class="time">[87:09]</span>That&#x27;s usually where you want to start with task decomposition.</p>
    <p class="cue"><span class="time">[87:12]</span>So let&#x27;s say we&#x27;ve done that work, and we have this list.</p>
    <p class="cue"><span class="time">[87:16]</span>I&#x27;m simplifying.</p>
    <p class="cue"><span class="time">[87:17]</span>But the customer support agent, human, typically</p>
    <p class="cue"><span class="time">[87:20]</span>would extract key info, then look up</p>
    <p class="cue"><span class="time">[87:23]</span>in the database to retrieve the customer record.</p>
    <p class="cue"><span class="time">[87:25]</span>Then check the policy.</p>
    <p class="cue"><span class="time">[87:27]</span>Are we allowed to update the address,</p>
    <p class="cue"><span class="time">[87:29]</span>or is it a fixed data point?</p>
    <p class="cue"><span class="time">[87:32]</span>And then draft a response email and sends the email.</p>
    <p class="cue"><span class="time">[87:35]</span>So we&#x27;ve decomposed that task.</p>
    <p class="cue"><span class="time">[87:39]</span>Once you&#x27;ve decomposed that task,</p>
    <p class="cue"><span class="time">[87:42]</span>how do you design your agentic workflow?</p>
    <p class="cue"><span class="time">[88:03]</span>Yes.</p>
    <p class="cue"><span class="time">[88:04]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[88:17]</span>Exactly.</p>
    <p class="cue"><span class="time">[88:18]</span>So to repeat, you&#x27;re going to look</p>
    <p class="cue"><span class="time">[88:20]</span>at the decomposition of tasks, get an instinct of what&#x27;s fuzzy,</p>
    <p class="cue"><span class="time">[88:24]</span>what&#x27;s deterministic, and then determine</p>
    <p class="cue"><span class="time">[88:28]</span>which line is going to be an LLM one shot, which one will require</p>
    <p class="cue"><span class="time">[88:33]</span>maybe a RAG, which one will require a tool, which one will</p>
    <p class="cue"><span class="time">[88:36]</span>require memory, which one--</p>
    <p class="cue"><span class="time">[88:38]</span>So you will start designing that map.</p>
    <p class="cue"><span class="time">[88:41]</span>Completely right.</p>
    <p class="cue"><span class="time">[88:41]</span>That&#x27;s also what I would recommend.</p>
    <p class="cue"><span class="time">[88:43]</span>You might actually draft it and say, OK, I take the user prompt.</p>
    <p class="cue"><span class="time">[88:48]</span>And the first step of my task decomposition</p>
    <p class="cue"><span class="time">[88:52]</span>was extract information that seems to be a vanilla LLM.</p>
    <p class="cue"><span class="time">[88:57]</span>You can guess that the vanilla LLM would probably</p>
    <p class="cue"><span class="time">[89:00]</span>be good enough at extracting the user wants</p>
    <p class="cue"><span class="time">[89:03]</span>to change their address, and this is the order number</p>
    <p class="cue"><span class="time">[89:05]</span>and this is the new address.</p>
    <p class="cue"><span class="time">[89:06]</span>You probably don&#x27;t need too much technology</p>
    <p class="cue"><span class="time">[89:08]</span>there other than the LLM.</p>
    <p class="cue"><span class="time">[89:11]</span>The next step, it feels like you need a tool because you&#x27;re</p>
    <p class="cue"><span class="time">[89:14]</span>actually going to have to look up in the database</p>
    <p class="cue"><span class="time">[89:17]</span>and also update the address.</p>
    <p class="cue"><span class="time">[89:21]</span>So that might be a tool, and you might</p>
    <p class="cue"><span class="time">[89:23]</span>have to build a custom tool for the LLM</p>
    <p class="cue"><span class="time">[89:25]</span>to say, let me connect you to that database</p>
    <p class="cue"><span class="time">[89:27]</span>or let me give you access to that resource with an MCP.</p>
    <p class="cue"><span class="time">[89:32]</span>After that probably need an LLM again to draft the email,</p>
    <p class="cue"><span class="time">[89:35]</span>but you would probably paste confirmation.</p>
    <p class="cue"><span class="time">[89:38]</span>You would paste the confirmation that your address</p>
    <p class="cue"><span class="time">[89:40]</span>has been updated from x to y.</p>
    <p class="cue"><span class="time">[89:42]</span>And then the LLM will draft an answer.</p>
    <p class="cue"><span class="time">[89:44]</span>And of course, just to not forget,</p>
    <p class="cue"><span class="time">[89:46]</span>you might need a tool to send the email.</p>
    <p class="cue"><span class="time">[89:49]</span>You might actually need to post something to</p>
    <p class="cue"><span class="time">[89:54]</span>for the email to go out.</p>
    <p class="cue"><span class="time">[89:57]</span>And then you&#x27;ll get the output.</p>
    <p class="cue"><span class="time">[89:59]</span>Does that make sense So exactly what you described.</p>
    <p class="cue"><span class="time">[90:02]</span>Now moving to the next step.</p>
    <p class="cue"><span class="time">[90:03]</span>Once we have-- we compose our tasks.</p>
    <p class="cue"><span class="time">[90:06]</span>Then we have designed an agentic workflow around it.</p>
    <p class="cue"><span class="time">[90:09]</span>It took us five minutes.</p>
    <p class="cue"><span class="time">[90:10]</span>In practice, it would take you more</p>
    <p class="cue"><span class="time">[90:12]</span>if you&#x27;re building your startup on that.</p>
    <p class="cue"><span class="time">[90:13]</span>You want to make sure your task decomposition is accurate,</p>
    <p class="cue"><span class="time">[90:15]</span>your thing is accurate here, and then</p>
    <p class="cue"><span class="time">[90:17]</span>you can have a lot of work done on every tool</p>
    <p class="cue"><span class="time">[90:20]</span>and optimize it and latency and cost.</p>
    <p class="cue"><span class="time">[90:22]</span>But let&#x27;s say, now we want to know if it works.</p>
    <p class="cue"><span class="time">[90:27]</span>And I&#x27;m going to assume that you have LLM traces.</p>
    <p class="cue"><span class="time">[90:30]</span>LLM traces are very important.</p>
    <p class="cue"><span class="time">[90:33]</span>Actually, if you&#x27;re interviewing with an AI startup.</p>
    <p class="cue"><span class="time">[90:36]</span>I would recommend you in the interview process to ask them,</p>
    <p class="cue"><span class="time">[90:39]</span>do you have LLM traces?</p>
    <p class="cue"><span class="time">[90:40]</span>Because if they don&#x27;t have LLM traces,</p>
    <p class="cue"><span class="time">[90:42]</span>it is pretty hard to debug an LLM system because you don&#x27;t</p>
    <p class="cue"><span class="time">[90:46]</span>have visibility on the chain of complex prompts that were called</p>
    <p class="cue"><span class="time">[90:50]</span>and where the bug is.</p>
    <p class="cue"><span class="time">[90:52]</span>And so it&#x27;s a basic part of an AI startup</p>
    <p class="cue"><span class="time">[90:57]</span>stack to have an LLM traces.</p>
    <p class="cue"><span class="time">[91:00]</span>So let&#x27;s assume you have traces.</p>
    <p class="cue"><span class="time">[91:02]</span>How would you know if your system works?</p>
    <p class="cue"><span class="time">[91:04]</span>I&#x27;m going to summarize some of the things I heard earlier.</p>
    <p class="cue"><span class="time">[91:11]</span>You gave us an example of an end to end metric.</p>
    <p class="cue"><span class="time">[91:15]</span>You look at the user satisfaction at the end.</p>
    <p class="cue"><span class="time">[91:18]</span>You can also do a component-based approach</p>
    <p class="cue"><span class="time">[91:21]</span>where you actually will look at the tool, the database updates,</p>
    <p class="cue"><span class="time">[91:25]</span>and you will manually do an error analysis and see,</p>
    <p class="cue"><span class="time">[91:28]</span>oh, the tool actually always forgets to update the email.</p>
    <p class="cue"><span class="time">[91:32]</span>It just fails at writing.</p>
    <p class="cue"><span class="time">[91:33]</span>And I&#x27;m going to fix that.</p>
    <p class="cue"><span class="time">[91:34]</span>This is deterministic pretty much.</p>
    <p class="cue"><span class="time">[91:37]</span>Or when it tries to send the email</p>
    <p class="cue"><span class="time">[91:40]</span>and ping the system that is supposed to send the email,</p>
    <p class="cue"><span class="time">[91:44]</span>it doesn&#x27;t send it in the right format.</p>
    <p class="cue"><span class="time">[91:46]</span>And so it bugs at that point.</p>
    <p class="cue"><span class="time">[91:48]</span>Again, you could fix that.</p>
    <p class="cue"><span class="time">[91:51]</span>Draft of the email.</p>
    <p class="cue"><span class="time">[91:52]</span>The LLM doesn&#x27;t do a great job.</p>
    <p class="cue"><span class="time">[91:53]</span>It&#x27;s not very polite at drafting the email.</p>
    <p class="cue"><span class="time">[91:56]</span>So you could look at component by component,</p>
    <p class="cue"><span class="time">[91:59]</span>and it&#x27;s actually easier to debug than to look at it</p>
    <p class="cue"><span class="time">[92:01]</span>end to end.</p>
    <p class="cue"><span class="time">[92:02]</span>You would probably do a mix of both.</p>
    <p class="cue"><span class="time">[92:05]</span>Another way to look at it is what is objective</p>
    <p class="cue"><span class="time">[92:08]</span>versus what is subjective?</p>
    <p class="cue"><span class="time">[92:10]</span>So for example, an objective example</p>
    <p class="cue"><span class="time">[92:12]</span>would be a DLRM extracted the wrong order ID.</p>
    <p class="cue"><span class="time">[92:18]</span>The user said my order ID is X, and the LLM,</p>
    <p class="cue"><span class="time">[92:21]</span>when it actually looked up in the database,</p>
    <p class="cue"><span class="time">[92:24]</span>it used the wrong order ID.</p>
    <p class="cue"><span class="time">[92:26]</span>This is objectively wrong.</p>
    <p class="cue"><span class="time">[92:27]</span>You can actually write a Python code</p>
    <p class="cue"><span class="time">[92:29]</span>that checks that, checks just the alignment between what</p>
    <p class="cue"><span class="time">[92:32]</span>the user mentioned and what was actually pasted in the database</p>
    <p class="cue"><span class="time">[92:36]</span>or for the lookup.</p>
    <p class="cue"><span class="time">[92:38]</span>You also have subjective stuff, which we talked about,</p>
    <p class="cue"><span class="time">[92:40]</span>where you probably want to do either human rating or LLM</p>
    <p class="cue"><span class="time">[92:43]</span>as judges.</p>
    <p class="cue"><span class="time">[92:44]</span>It&#x27;s very relevant for subjective evals.</p>
    <p class="cue"><span class="time">[92:49]</span>And finally, you will find yourself</p>
    <p class="cue"><span class="time">[92:51]</span>having quantitative evals and more qualitative evals.</p>
    <p class="cue"><span class="time">[92:55]</span>So quantitative would be percentage of successful address</p>
    <p class="cue"><span class="time">[92:59]</span>updates.</p>
    <p class="cue"><span class="time">[93:00]</span>The latency.</p>
    <p class="cue"><span class="time">[93:00]</span>You could actually track the latency component-based</p>
    <p class="cue"><span class="time">[93:03]</span>and see which one is the slowest.</p>
    <p class="cue"><span class="time">[93:05]</span>Let&#x27;s say sending the email is five seconds.</p>
    <p class="cue"><span class="time">[93:08]</span>It&#x27;s too long, let&#x27;s say.</p>
    <p class="cue"><span class="time">[93:10]</span>You would notice component based or the full workflow.</p>
    <p class="cue"><span class="time">[93:13]</span>And then you will decide, where am I optimizing my latency,</p>
    <p class="cue"><span class="time">[93:15]</span>and how am I going to do that?</p>
    <p class="cue"><span class="time">[93:17]</span>And then finally, qualitative.</p>
    <p class="cue"><span class="time">[93:20]</span>You might actually do some error analysis</p>
    <p class="cue"><span class="time">[93:23]</span>and look at where are the hallucinations?</p>
    <p class="cue"><span class="time">[93:27]</span>Where are the tone mismatches?</p>
    <p class="cue"><span class="time">[93:31]</span>Are the user confused, and by what they&#x27;re confused?</p>
    <p class="cue"><span class="time">[93:34]</span>That would be more qualitative.</p>
    <p class="cue"><span class="time">[93:36]</span>And typically, it would take more white glove approaches</p>
    <p class="cue"><span class="time">[93:41]</span>to do that.</p>
    <p class="cue"><span class="time">[93:42]</span>So here&#x27;s what it could look like.</p>
    <p class="cue"><span class="time">[93:44]</span>I gave you some examples.</p>
    <p class="cue"><span class="time">[93:46]</span>But you would build evals to determine</p>
    <p class="cue"><span class="time">[93:50]</span>objectively, subjectively, component-based, end</p>
    <p class="cue"><span class="time">[93:53]</span>to end based, and then quantitatively and</p>
    <p class="cue"><span class="time">[93:55]</span>qualitatively, where&#x27;s your LLM failing</p>
    <p class="cue"><span class="time">[93:57]</span>and where it&#x27;s doing well.</p>
    <p class="cue"><span class="time">[94:02]</span>Does that give you a sense of the type of stuff</p>
    <p class="cue"><span class="time">[94:04]</span>you could do to fix or improve that agentic workflow?</p>
    <p class="cue"><span class="time">[94:09]</span>Super.</p>
    <p class="cue"><span class="time">[94:10]</span>Well, that was our case study on evals.</p>
    <p class="cue"><span class="time">[94:12]</span>We&#x27;re not going to delve deeper into it.</p>
    <p class="cue"><span class="time">[94:14]</span>But hopefully, it gave you a sense of the type of stuff</p>
    <p class="cue"><span class="time">[94:16]</span>you can do with LLM judges, with objective,</p>
    <p class="cue"><span class="time">[94:21]</span>subjective, component-based, end to end, et cetera.</p>
    <p class="cue"><span class="time">[94:25]</span>Last section on multi-agent workflows.</p>
    <p class="cue"><span class="time">[94:29]</span>So you might ask, hey, why do we need multi-agent workflow when</p>
    <p class="cue"><span class="time">[94:36]</span>the workflow already has multiple steps,</p>
    <p class="cue"><span class="time">[94:38]</span>already calls the LLM multiple times, already gives them tools.</p>
    <p class="cue"><span class="time">[94:42]</span>Why do we need multiple agents?</p>
    <p class="cue"><span class="time">[94:45]</span>And so many people are talking about multi-agent system online.</p>
    <p class="cue"><span class="time">[94:47]</span>It&#x27;s not even a new thing, frankly.</p>
    <p class="cue"><span class="time">[94:49]</span>Multi-agent systems have been around for a long time.</p>
    <p class="cue"><span class="time">[94:52]</span>The main advantage of a multi-agent system</p>
    <p class="cue"><span class="time">[94:55]</span>is going to be parallelism.</p>
    <p class="cue"><span class="time">[94:57]</span>It&#x27;s like is there something that I</p>
    <p class="cue"><span class="time">[94:59]</span>wish I would run in parallel, sort of independently,</p>
    <p class="cue"><span class="time">[95:04]</span>but maybe there are some things in the middle?</p>
    <p class="cue"><span class="time">[95:07]</span>But that&#x27;s where you want to put a multi-agent system.</p>
    <p class="cue"><span class="time">[95:09]</span>It&#x27;s when it&#x27;s parallel.</p>
    <p class="cue"><span class="time">[95:12]</span>The other advantage that some companies</p>
    <p class="cue"><span class="time">[95:14]</span>have with multi-agent systems is an agent can be reused.</p>
    <p class="cue"><span class="time">[95:19]</span>So let&#x27;s say in a company, you have an agent that&#x27;s</p>
    <p class="cue"><span class="time">[95:21]</span>been built for design.</p>
    <p class="cue"><span class="time">[95:22]</span>That agent can be used in the marketing team,</p>
    <p class="cue"><span class="time">[95:25]</span>and it can be used in the product team.</p>
    <p class="cue"><span class="time">[95:27]</span>And so now you&#x27;re optimizing an agent,</p>
    <p class="cue"><span class="time">[95:30]</span>which has multiple stakeholders that can communicate with it</p>
    <p class="cue"><span class="time">[95:33]</span>and benefit from its performance.</p>
    <p class="cue"><span class="time">[95:38]</span>Actually I&#x27;m going to ask you a question</p>
    <p class="cue"><span class="time">[95:40]</span>and take a few, maybe a minute to think about it.</p>
    <p class="cue"><span class="time">[95:43]</span>Let&#x27;s say you were building smart home</p>
    <p class="cue"><span class="time">[95:46]</span>automation for your apartment or your home.</p>
    <p class="cue"><span class="time">[95:50]</span>What agents would you want to build?</p>
    <p class="cue"><span class="time">[95:52]</span>Yeah.</p>
    <p class="cue"><span class="time">[95:53]</span>Write it down.</p>
    <p class="cue"><span class="time">[95:54]</span>And then I&#x27;m going to ask you in a minute</p>
    <p class="cue"><span class="time">[95:57]</span>to share some of the agents that you will build.</p>
    <p class="cue"><span class="time">[96:00]</span>Also, think about how you would put</p>
    <p class="cue"><span class="time">[96:03]</span>a hierarchy between these agents,</p>
    <p class="cue"><span class="time">[96:04]</span>or how you would organize them, or who</p>
    <p class="cue"><span class="time">[96:06]</span>should communicate with who.</p>
    <p class="cue"><span class="time">[96:07]</span>OK?</p>
    <p class="cue"><span class="time">[96:08]</span>OK.</p>
    <p class="cue"><span class="time">[96:08]</span>Take a minute for that.</p>
    <p class="cue"><span class="time">[96:12]</span>Be creative also because I&#x27;m going to ask all of your agents,</p>
    <p class="cue"><span class="time">[96:14]</span>and maybe you have an agent that nobody has thought of.</p>
    <p class="cue"><span class="time">[96:21]</span>OK.</p>
    <p class="cue"><span class="time">[96:22]</span>Let&#x27;s get started.</p>
    <p class="cue"><span class="time">[96:24]</span>Who wants to give me a set of agents</p>
    <p class="cue"><span class="time">[96:26]</span>that you would want for your home, smart home.</p>
    <p class="cue"><span class="time">[96:29]</span>Yes.</p>
    <p class="cue"><span class="time">[96:32]</span>The first is like a set of agents [INAUDIBLE]</p>
    <p class="cue"><span class="time">[97:00]</span>OK.</p>
    <p class="cue"><span class="time">[97:01]</span>So let me repeat.</p>
    <p class="cue"><span class="time">[97:02]</span>You have four agents, I think, roughly.</p>
    <p class="cue"><span class="time">[97:05]</span>One that tracks biometric, like where are you in the home?</p>
    <p class="cue"><span class="time">[97:09]</span>Where are you moving?</p>
    <p class="cue"><span class="time">[97:10]</span>How you&#x27;re moving, things like that.</p>
    <p class="cue"><span class="time">[97:12]</span>That sort of knows your location.</p>
    <p class="cue"><span class="time">[97:15]</span>The second one determines the temperature of the rooms</p>
    <p class="cue"><span class="time">[97:21]</span>and has the ability to change it.</p>
    <p class="cue"><span class="time">[97:23]</span>The third one tracks energy efficiency</p>
    <p class="cue"><span class="time">[97:26]</span>and might give feedback on energy and energy usage.</p>
    <p class="cue"><span class="time">[97:31]</span>And might be, I don&#x27;t know, maybe</p>
    <p class="cue"><span class="time">[97:32]</span>it has the control over the temperature as well.</p>
    <p class="cue"><span class="time">[97:34]</span>I don&#x27;t know actually.</p>
    <p class="cue"><span class="time">[97:35]</span>Or the gas or the water, might cut your water at some point.</p>
    <p class="cue"><span class="time">[97:43]</span>And then you have an orchestrator agent.</p>
    <p class="cue"><span class="time">[97:44]</span>What is exactly the orchestrator doing?</p>
    <p class="cue"><span class="time">[97:48]</span>It passes instructions [INAUDIBLE]</p>
    <p class="cue"><span class="time">[97:53]</span>OK.</p>
    <p class="cue"><span class="time">[97:53]</span>Passes instructions.</p>
    <p class="cue"><span class="time">[97:55]</span>So is that the agent that communicates mainly</p>
    <p class="cue"><span class="time">[97:58]</span>with the user?</p>
    <p class="cue"><span class="time">[98:00]</span>So if I&#x27;m coming back home and I&#x27;m</p>
    <p class="cue"><span class="time">[98:02]</span>saying I want the oven to be preheated,</p>
    <p class="cue"><span class="time">[98:05]</span>I communicate with the orchestrator,</p>
    <p class="cue"><span class="time">[98:07]</span>and then it would funnel to another agent.</p>
    <p class="cue"><span class="time">[98:09]</span>OK.</p>
    <p class="cue"><span class="time">[98:10]</span>Sounds good.</p>
    <p class="cue"><span class="time">[98:11]</span>Yeah.</p>
    <p class="cue"><span class="time">[98:11]</span>So that&#x27;s an example of, I want to say,</p>
    <p class="cue"><span class="time">[98:14]</span>a hierarchical agentic multi-agent system.</p>
    <p class="cue"><span class="time">[98:20]</span>What else?</p>
    <p class="cue"><span class="time">[98:21]</span>Any other ideas?</p>
    <p class="cue"><span class="time">[98:22]</span>What would you add to that?</p>
    <p class="cue"><span class="time">[98:24]</span>Yeah.</p>
    <p class="cue"><span class="time">[98:25]</span>[INAUDIBLE]</p>
    <p class="cue"><span class="time">[98:55]</span>Oh, I like that.</p>
    <p class="cue"><span class="time">[98:56]</span>That&#x27;s a really good one.</p>
    <p class="cue"><span class="time">[98:57]</span>So let me summarize.</p>
    <p class="cue"><span class="time">[98:58]</span>You have a security agent that determines if you can enter</p>
    <p class="cue"><span class="time">[99:02]</span>or not.</p>
    <p class="cue"><span class="time">[99:03]</span>And when you enter, it understands who you are.</p>
    <p class="cue"><span class="time">[99:06]</span>And then it gives you certain sets</p>
    <p class="cue"><span class="time">[99:08]</span>of permissions that might be different depending</p>
    <p class="cue"><span class="time">[99:11]</span>of if you&#x27;re a parent or a kid.</p>
    <p class="cue"><span class="time">[99:13]</span>Or you might have access to certain cars and not others.</p>
    <p class="cue"><span class="time">[99:17]</span>Or your kid cannot open the fridge, or I don&#x27;t know.</p>
    <p class="cue"><span class="time">[99:20]</span>Something like that.</p>
    <p class="cue"><span class="time">[99:21]</span>Yeah.</p>
    <p class="cue"><span class="time">[99:22]</span>OK, I like that.</p>
    <p class="cue"><span class="time">[99:23]</span>That&#x27;s a good one.</p>
    <p class="cue"><span class="time">[99:24]</span>And it does feel like it&#x27;s a complex enough workflow where</p>
    <p class="cue"><span class="time">[99:28]</span>you want a specific workflow tied to that.</p>
    <p class="cue"><span class="time">[99:32]</span>I agree.</p>
    <p class="cue"><span class="time">[99:34]</span>What else?</p>
    <p class="cue"><span class="time">[99:39]</span>Yes.</p>
    <p class="cue"><span class="time">[99:41]</span>[INAUDIBLE] So you can get more complicated.</p>
    <p class="cue"><span class="time">[99:43]</span>So high energy savings with whether or not you</p>
    <p class="cue"><span class="time">[99:50]</span>or someone else can be blind to those in the house or also</p>
    <p class="cue"><span class="time">[99:55]</span>when you tap into the grid.</p>
    <p class="cue"><span class="time">[99:57]</span>Yeah So another thought I have as well is much harder</p>
    <p class="cue"><span class="time">[100:04]</span>to track in the grocery store.</p>
    <p class="cue"><span class="time">[100:06]</span>But understanding what&#x27;s in your fridge.</p>
    <p class="cue"><span class="time">[100:08]</span>OK</p>
    <p class="cue"><span class="time">[100:12]</span>Well, that&#x27;s really good actually.</p>
    <p class="cue"><span class="time">[100:14]</span>So you mentioned two of them.</p>
    <p class="cue"><span class="time">[100:16]</span>One is maybe an agent that has access to external APIs that</p>
    <p class="cue"><span class="time">[100:20]</span>can understand the weather out there, the wind, the sun,</p>
    <p class="cue"><span class="time">[100:24]</span>and then has control over certain devices at home.</p>
    <p class="cue"><span class="time">[100:28]</span>Temperature, blinds, things like that, and also understands</p>
    <p class="cue"><span class="time">[100:31]</span>your preferences for it.</p>
    <p class="cue"><span class="time">[100:33]</span>That does feel like it&#x27;s a good use case because you could give</p>
    <p class="cue"><span class="time">[100:36]</span>that to the orchestrator, but it might lose itself</p>
    <p class="cue"><span class="time">[100:38]</span>because it&#x27;s doing too much.</p>
    <p class="cue"><span class="time">[100:41]</span>And also, these problems are tied together,</p>
    <p class="cue"><span class="time">[100:43]</span>like temperature outdoor with the weather API</p>
    <p class="cue"><span class="time">[100:45]</span>might influence the temperature inside,</p>
    <p class="cue"><span class="time">[100:48]</span>how you want it, et cetera.</p>
    <p class="cue"><span class="time">[100:50]</span>And then the second one, which I also like,</p>
    <p class="cue"><span class="time">[100:52]</span>is you might have an agent that looks at your fridge</p>
    <p class="cue"><span class="time">[100:55]</span>and what&#x27;s inside.</p>
    <p class="cue"><span class="time">[100:57]</span>And it might actually have access</p>
    <p class="cue"><span class="time">[100:58]</span>to the camera in the fridge, for example,</p>
    <p class="cue"><span class="time">[101:01]</span>and know your preferences and also has</p>
    <p class="cue"><span class="time">[101:03]</span>access to the e-commerce API to order</p>
    <p class="cue"><span class="time">[101:06]</span>Amazon groceries ahead of time.</p>
    <p class="cue"><span class="time">[101:09]</span>I agree.</p>
    <p class="cue"><span class="time">[101:10]</span>And maybe the orchestrator will be the communication line</p>
    <p class="cue"><span class="time">[101:12]</span>with the user, but it might communicate with that agent</p>
    <p class="cue"><span class="time">[101:16]</span>in order to get it done.</p>
    <p class="cue"><span class="time">[101:17]</span>Yeah.</p>
    <p class="cue"><span class="time">[101:18]</span>I like those.</p>
    <p class="cue"><span class="time">[101:19]</span>So those are all really good examples.</p>
    <p class="cue"><span class="time">[101:21]</span>Here is the list I had up there.</p>
    <p class="cue"><span class="time">[101:25]</span>So climate control, lighting security, energy management,</p>
    <p class="cue"><span class="time">[101:30]</span>entertainment, notification agent,</p>
    <p class="cue"><span class="time">[101:32]</span>alerts about the system updates, energy saving, and orchestrator.</p>
    <p class="cue"><span class="time">[101:35]</span>So all of them you mentioned actually.</p>
    <p class="cue"><span class="time">[101:38]</span>And then we didn&#x27;t talk about the different interaction</p>
    <p class="cue"><span class="time">[101:41]</span>patterns, but you do have different ways to organize</p>
    <p class="cue"><span class="time">[101:45]</span>a multi-agent system.</p>
    <p class="cue"><span class="time">[101:46]</span>Flat, hierarchical.</p>
    <p class="cue"><span class="time">[101:48]</span>It sounds like this would be hierarchical.</p>
    <p class="cue"><span class="time">[101:51]</span>I agree.</p>
    <p class="cue"><span class="time">[101:52]</span>And the reason is UI/UX, is I would rather</p>
    <p class="cue"><span class="time">[101:55]</span>have to only talk to the orchestrator,</p>
    <p class="cue"><span class="time">[101:57]</span>rather than have to go to a specialized application</p>
    <p class="cue"><span class="time">[102:00]</span>to do something.</p>
    <p class="cue"><span class="time">[102:01]</span>Like it feels like the orchestrator</p>
    <p class="cue"><span class="time">[102:02]</span>could be responsible for that.</p>
    <p class="cue"><span class="time">[102:04]</span>And so I agree, I would probably go for a hierarchical setup</p>
    <p class="cue"><span class="time">[102:07]</span>here.</p>
    <p class="cue"><span class="time">[102:08]</span>But maybe you might also add some connections</p>
    <p class="cue"><span class="time">[102:11]</span>between other agents, like in the flat system</p>
    <p class="cue"><span class="time">[102:13]</span>where it&#x27;s all to all.</p>
    <p class="cue"><span class="time">[102:15]</span>For example, with climate control and energy,</p>
    <p class="cue"><span class="time">[102:17]</span>if you want to connect those two,</p>
    <p class="cue"><span class="time">[102:19]</span>you might actually allow them to speak with each other.</p>
    <p class="cue"><span class="time">[102:21]</span>When you allow agents to speak with each other,</p>
    <p class="cue"><span class="time">[102:24]</span>it is basically an MCB protocol, by the way.</p>
    <p class="cue"><span class="time">[102:26]</span>So you treat the agent like a tool, exactly like a tool.</p>
    <p class="cue"><span class="time">[102:30]</span>Here is how you interact with this agent.</p>
    <p class="cue"><span class="time">[102:32]</span>Here is what it can tell you.</p>
    <p class="cue"><span class="time">[102:34]</span>Here is what it needs from you, essentially.</p>
    <p class="cue"><span class="time">[102:37]</span>OK super.</p>
    <p class="cue"><span class="time">[102:38]</span>And then without going into the details,</p>
    <p class="cue"><span class="time">[102:40]</span>there are advantages to multi-agent workflows</p>
    <p class="cue"><span class="time">[102:43]</span>versus single agents, such as debugging.</p>
    <p class="cue"><span class="time">[102:47]</span>It&#x27;s easier to debug a specialized agent</p>
    <p class="cue"><span class="time">[102:50]</span>into debug an entire system.</p>
    <p class="cue"><span class="time">[102:52]</span>Parallelization as well.</p>
    <p class="cue"><span class="time">[102:54]</span>It&#x27;s easier to have things run in parallel,</p>
    <p class="cue"><span class="time">[102:56]</span>and you can earn time.</p>
    <p class="cue"><span class="time">[102:59]</span>There are some advantages to doing that,</p>
    <p class="cue"><span class="time">[103:01]</span>and I&#x27;ll leave you with this slide if you want to go deeper.</p>
    <p class="cue"><span class="time">[103:04]</span>Super.</p>
    <p class="cue"><span class="time">[103:05]</span>So we&#x27;ve learned so many techniques to optimize LLMs,</p>
    <p class="cue"><span class="time">[103:08]</span>from prompts to chains to fine tuning, retrieval,</p>
    <p class="cue"><span class="time">[103:12]</span>and to multi-agent system as well.</p>
    <p class="cue"><span class="time">[103:14]</span>And then just to end on a couple of trends I want you to watch.</p>
    <p class="cue"><span class="time">[103:19]</span>I think next week is Thanksgiving, is that it?</p>
    <p class="cue"><span class="time">[103:21]</span>It&#x27;s Thanksgiving break.</p>
    <p class="cue"><span class="time">[103:22]</span>No, the week after.</p>
    <p class="cue"><span class="time">[103:23]</span>OK.</p>
    <p class="cue"><span class="time">[103:24]</span>Well ahead of the Thanksgiving break.</p>
    <p class="cue"><span class="time">[103:26]</span>So if you&#x27;re traveling, you can think about these things.</p>
    <p class="cue"><span class="time">[103:29]</span>What&#x27;s next is in AI, I wanted to call out a couple of trends.</p>
    <p class="cue"><span class="time">[103:34]</span>So Ilya Sutskever, one of the OGs of LLMs and OpenAI</p>
    <p class="cue"><span class="time">[103:40]</span>co-founder, raised that question about are we plateauing or not.</p>
    <p class="cue"><span class="time">[103:45]</span>The question are we going to see in the coming years LLM sort</p>
    <p class="cue"><span class="time">[103:50]</span>of not improve as fast as we&#x27;ve seen in the past?</p>
    <p class="cue"><span class="time">[103:54]</span>It&#x27;s been the feeling in the community</p>
    <p class="cue"><span class="time">[103:56]</span>probably that the last version of GPT</p>
    <p class="cue"><span class="time">[104:00]</span>did not bring the level of performance</p>
    <p class="cue"><span class="time">[104:03]</span>that people were expecting, although it did make</p>
    <p class="cue"><span class="time">[104:06]</span>it so much easier to use for consumers because you don&#x27;t need</p>
    <p class="cue"><span class="time">[104:09]</span>to interact with different models.</p>
    <p class="cue"><span class="time">[104:10]</span>It&#x27;s all under the same hood.</p>
    <p class="cue"><span class="time">[104:12]</span>So it seems that it&#x27;s progressing,</p>
    <p class="cue"><span class="time">[104:14]</span>but the plateau is unclear.</p>
    <p class="cue"><span class="time">[104:17]</span>The way I would think about it is the LLM scaling laws tell us</p>
    <p class="cue"><span class="time">[104:22]</span>that if we continue to improve compute and energy,</p>
    <p class="cue"><span class="time">[104:26]</span>then LLMs should continue to improve.</p>
    <p class="cue"><span class="time">[104:28]</span>But at some point, it&#x27;s going to plateau.</p>
    <p class="cue"><span class="time">[104:29]</span>So what&#x27;s going to take us to the next step?</p>
    <p class="cue"><span class="time">[104:32]</span>It&#x27;s probably architecture search.</p>
    <p class="cue"><span class="time">[104:35]</span>Still a lot of LLMs, even if we don&#x27;t</p>
    <p class="cue"><span class="time">[104:36]</span>understand what&#x27;s under the hood or probably</p>
    <p class="cue"><span class="time">[104:38]</span>transformer-based today.</p>
    <p class="cue"><span class="time">[104:40]</span>But we know that the human brain does not operate the same way.</p>
    <p class="cue"><span class="time">[104:43]</span>There&#x27;s just certain things that we</p>
    <p class="cue"><span class="time">[104:45]</span>do that are much more efficient, much faster.</p>
    <p class="cue"><span class="time">[104:47]</span>We don&#x27;t need as much data.</p>
    <p class="cue"><span class="time">[104:49]</span>So theoretically, we have so much</p>
    <p class="cue"><span class="time">[104:51]</span>to learn in terms of architecture search</p>
    <p class="cue"><span class="time">[104:53]</span>that we haven&#x27;t figured out.</p>
    <p class="cue"><span class="time">[104:54]</span>It&#x27;s not a surprise that you see those labs hire</p>
    <p class="cue"><span class="time">[104:57]</span>so many engineers.</p>
    <p class="cue"><span class="time">[104:58]</span>Because it is possible that in the next few years,</p>
    <p class="cue"><span class="time">[105:01]</span>you&#x27;re going to have thousands of engineers trying</p>
    <p class="cue"><span class="time">[105:03]</span>to figure out the different engineering hacks and tactics</p>
    <p class="cue"><span class="time">[105:06]</span>and architectural searches that are</p>
    <p class="cue"><span class="time">[105:07]</span>going to lead to better models.</p>
    <p class="cue"><span class="time">[105:10]</span>And one of them suddenly will find the next transformer,</p>
    <p class="cue"><span class="time">[105:13]</span>and it will reduce by 10x the need for compute and the need</p>
    <p class="cue"><span class="time">[105:17]</span>for energy.</p>
    <p class="cue"><span class="time">[105:18]</span>It&#x27;s sort of if you read Isaac Asimov&#x27;s Foundation series.</p>
    <p class="cue"><span class="time">[105:24]</span>Individuals can have an amazing impact on the future because</p>
    <p class="cue"><span class="time">[105:27]</span>of their decisions.</p>
    <p class="cue"><span class="time">[105:29]</span>Whoever discovered transformers had a tremendous impact</p>
    <p class="cue"><span class="time">[105:33]</span>on the direction of AI.</p>
    <p class="cue"><span class="time">[105:34]</span>I think we&#x27;re going to see more of that in the coming</p>
    <p class="cue"><span class="time">[105:37]</span>years, where some group of researchers that is iterating</p>
    <p class="cue"><span class="time">[105:40]</span>fast might discover certain things that would suddenly</p>
    <p class="cue"><span class="time">[105:43]</span>unlock that plateau and take us to the next step,</p>
    <p class="cue"><span class="time">[105:45]</span>and it&#x27;s going to continue to improve like that.</p>
    <p class="cue"><span class="time">[105:47]</span>And so it doesn&#x27;t surprise me that there&#x27;s so many companies</p>
    <p class="cue"><span class="time">[105:50]</span>hiring engineers right now to figure out</p>
    <p class="cue"><span class="time">[105:52]</span>those hacks and those techniques.</p>
    <p class="cue"><span class="time">[105:56]</span>The other set of gains that we might see</p>
    <p class="cue"><span class="time">[105:58]</span>is from multi-modality.</p>
    <p class="cue"><span class="time">[105:59]</span>So the way to think about it is we&#x27;ve had LLMs first text-based,</p>
    <p class="cue"><span class="time">[106:04]</span>and then we&#x27;ve added imaging.</p>
    <p class="cue"><span class="time">[106:06]</span>And today, models are very good at images.</p>
    <p class="cue"><span class="time">[106:09]</span>They&#x27;re very good at text.</p>
    <p class="cue"><span class="time">[106:10]</span>It turns out that being good at images and being good at text</p>
    <p class="cue"><span class="time">[106:13]</span>makes the whole model better.</p>
    <p class="cue"><span class="time">[106:15]</span>So the fact that you&#x27;re good at understanding a cat image</p>
    <p class="cue"><span class="time">[106:18]</span>makes you better at text as well for a cat.</p>
    <p class="cue"><span class="time">[106:21]</span>Now you add another modality like audio or video.</p>
    <p class="cue"><span class="time">[106:24]</span>The whole system gets better.</p>
    <p class="cue"><span class="time">[106:26]</span>So you&#x27;re better at writing about a cat</p>
    <p class="cue"><span class="time">[106:28]</span>if you know what a cat sounds like,</p>
    <p class="cue"><span class="time">[106:30]</span>if you can look at a cat on an image as well.</p>
    <p class="cue"><span class="time">[106:31]</span>Does that make sense?</p>
    <p class="cue"><span class="time">[106:32]</span>So we see gains that are translated from one modality</p>
    <p class="cue"><span class="time">[106:35]</span>to another, and that might lead in the pinnacle of robotics</p>
    <p class="cue"><span class="time">[106:38]</span>where all these modalities come together.</p>
    <p class="cue"><span class="time">[106:40]</span>And suddenly, the robot is better at</p>
    <p class="cue"><span class="time">[106:42]</span>running away from a cat because it understands</p>
    <p class="cue"><span class="time">[106:44]</span>what a cat is, how it sounds like,</p>
    <p class="cue"><span class="time">[106:46]</span>what it looks like, et cetera.</p>
    <p class="cue"><span class="time">[106:48]</span>That makes sense?</p>
    <p class="cue"><span class="time">[106:49]</span>The other one is the multiple methods working in harmony.</p>
    <p class="cue"><span class="time">[106:53]</span>In the Tuesday lectures, we&#x27;ve seen supervised learning,</p>
    <p class="cue"><span class="time">[106:56]</span>unsupervised learning, self-supervised learning,</p>
    <p class="cue"><span class="time">[106:58]</span>reinforcement learning, prompt engineering, RAGs, et cetera.</p>
    <p class="cue"><span class="time">[107:02]</span>If you look at how babies learn, it</p>
    <p class="cue"><span class="time">[107:06]</span>is probably a mix of those different approaches.</p>
    <p class="cue"><span class="time">[107:09]</span>Like a baby might have some meta learning, meaning it</p>
    <p class="cue"><span class="time">[107:13]</span>has some survival instinct that is</p>
    <p class="cue"><span class="time">[107:16]</span>encoded in the DNA most likely.</p>
    <p class="cue"><span class="time">[107:19]</span>And that&#x27;s like the baby&#x27;s pre-training, if you will.</p>
    <p class="cue"><span class="time">[107:22]</span>On top of that, the mom or the dad is pointing at stuff</p>
    <p class="cue"><span class="time">[107:27]</span>and saying bad, good, bad, good.</p>
    <p class="cue"><span class="time">[107:29]</span>Supervised learning.</p>
    <p class="cue"><span class="time">[107:30]</span>On top of that, the baby is falling on the ground</p>
    <p class="cue"><span class="time">[107:33]</span>and getting hurt.</p>
    <p class="cue"><span class="time">[107:34]</span>And that&#x27;s a reward signal for reinforcement learning.</p>
    <p class="cue"><span class="time">[107:36]</span>On top of that, the baby is observing other people</p>
    <p class="cue"><span class="time">[107:39]</span>doing stuff or other babies doing</p>
    <p class="cue"><span class="time">[107:42]</span>stuff, unsupervised learning.</p>
    <p class="cue"><span class="time">[107:43]</span>You see what I mean?</p>
    <p class="cue"><span class="time">[107:44]</span>We&#x27;re probably a mix of all these methods,</p>
    <p class="cue"><span class="time">[107:47]</span>and I think that&#x27;s where the trend is going, is</p>
    <p class="cue"><span class="time">[107:49]</span>where those methods that you&#x27;ve seen in CS230</p>
    <p class="cue"><span class="time">[107:52]</span>come together in order to build an AI system that learns fast,</p>
    <p class="cue"><span class="time">[107:56]</span>is low latency, is cheap, energy-efficient,</p>
    <p class="cue"><span class="time">[108:00]</span>and makes the most out of all of these methods.</p>
    <p class="cue"><span class="time">[108:03]</span>Finally, and this is especially true at Stanford,</p>
    <p class="cue"><span class="time">[108:06]</span>you have research going on that you would consider human-centric</p>
    <p class="cue"><span class="time">[108:11]</span>and some research that is non-human centric.</p>
    <p class="cue"><span class="time">[108:13]</span>By human-centric, I should say human approaches</p>
    <p class="cue"><span class="time">[108:16]</span>that are modeled after the brain and approaches that</p>
    <p class="cue"><span class="time">[108:19]</span>are not modeled after humans.</p>
    <p class="cue"><span class="time">[108:20]</span>Because it turns out that the human body is very limiting.</p>
    <p class="cue"><span class="time">[108:24]</span>And so if you actually only do research</p>
    <p class="cue"><span class="time">[108:26]</span>on what the human brain looks like,</p>
    <p class="cue"><span class="time">[108:28]</span>you&#x27;re probably missing out on compute and energy and stuff</p>
    <p class="cue"><span class="time">[108:30]</span>like that that you can optimize even</p>
    <p class="cue"><span class="time">[108:32]</span>beyond neuronal connections in the brain,</p>
    <p class="cue"><span class="time">[108:35]</span>but you still can learn a lot from the human brain.</p>
    <p class="cue"><span class="time">[108:37]</span>And that&#x27;s why there are professors that are running labs</p>
    <p class="cue"><span class="time">[108:40]</span>right now that try to understand,</p>
    <p class="cue"><span class="time">[108:42]</span>how does back propagation work for humans?</p>
    <p class="cue"><span class="time">[108:45]</span>And in fact, it&#x27;s probably that we don&#x27;t have back propagation.</p>
    <p class="cue"><span class="time">[108:48]</span>We don&#x27;t use back propagation, we only do forward propagation,</p>
    <p class="cue"><span class="time">[108:51]</span>let&#x27;s say.</p>
    <p class="cue"><span class="time">[108:51]</span>So this type of stuff is interesting research</p>
    <p class="cue"><span class="time">[108:54]</span>that I would encourage you to read if you&#x27;re curious</p>
    <p class="cue"><span class="time">[108:56]</span>about the direction of AI.</p>
    <p class="cue"><span class="time">[108:59]</span>And then finally, one thing that&#x27;s going to be pretty clear,</p>
    <p class="cue"><span class="time">[109:02]</span>I call it all the time, but it&#x27;s the velocity</p>
    <p class="cue"><span class="time">[109:05]</span>at which things are moving.</p>
    <p class="cue"><span class="time">[109:06]</span>You&#x27;re noticing, part of the reason</p>
    <p class="cue"><span class="time">[109:08]</span>we&#x27;re giving you a breadth in CS230</p>
    <p class="cue"><span class="time">[109:10]</span>is because these methods are changing so fast.</p>
    <p class="cue"><span class="time">[109:12]</span>So I don&#x27;t want to bother going and teaching you</p>
    <p class="cue"><span class="time">[109:15]</span>the number 17 methods on RAG that</p>
    <p class="cue"><span class="time">[109:17]</span>optimizes the RAG because in two years,</p>
    <p class="cue"><span class="time">[109:19]</span>you&#x27;re not going to need it.</p>
    <p class="cue"><span class="time">[109:20]</span>So I would rather you think about what</p>
    <p class="cue"><span class="time">[109:23]</span>is the breadth of things you want to understand.</p>
    <p class="cue"><span class="time">[109:25]</span>And when you need it, you are sprinting and learning</p>
    <p class="cue"><span class="time">[109:27]</span>the exact thing you need faster because the half life of skill</p>
    <p class="cue"><span class="time">[109:30]</span>is so low.</p>
    <p class="cue"><span class="time">[109:31]</span>You want to come out of the class with a good breadth</p>
    <p class="cue"><span class="time">[109:34]</span>and then have the ability to go deep whenever</p>
    <p class="cue"><span class="time">[109:36]</span>you need after the class.</p>
    <p class="cue"><span class="time">[109:38]</span>And so that&#x27;s sort of how that class is designed as well.</p>
    <p class="cue"><span class="time">[109:41]</span>Yeah.</p>
    <p class="cue"><span class="time">[109:41]</span>That&#x27;s it for today.</p>
    <p class="cue"><span class="time">[109:43]</span>So thank you.</p>
    <p class="cue"><span class="time">[109:45]</span>Thank you for participating.</p>
  </section>
</article>
</body>
</html>
